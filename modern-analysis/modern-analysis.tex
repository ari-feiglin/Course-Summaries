\input pdfToolbox

\setlayout{horizontal margin=2cm, vertical margin=2cm}
\parindent=0pt
\parskip=3pt plus 2pt minus 2pt

\input preamble

\footline={}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\headline={\pageborder{rgb{.5 1 .5}}{rgb{0 .4 0}}{5}}

\color rgb{.1 .8 0}

{\def\boxshadowcolor{rgb{.3 .8 .3}}
\bppbox{rgb{.5 1 .5}}{rgb{0 .4 0}}{rgb{.1 .4 0}}

    \centerline{\setfontandscale{bf}{20pt}Modern Analysis }
    \smallskip
    \centerline{\setfont{it}Lectures by Shimon Brooks \setfont{rm}({\tt brookss@math.biu.ac.il})}
    \centerline{\setfont{it}Summary by Ari Feiglin \setfont{rm}({\tt ari.feiglin@gmail.com})}

\eppbox

\bigskip

\bppbox{rgb{.5 1 .5}}{rgb{0 .4 0}}{rgb{.1 .4 0}}
    \section*{Contents}
    
    \tableofcontents
\eppbox

}

\vfill\break

\color{black}

\pageno=1
\newif\ifpageodd
\pageoddtrue
\headline={%
    \hbox to \hsize{\color{black}%
        \ifpageodd\hfil{\it\currsubsection\quad\bf\folio}\global\pageoddfalse%
        \else{\bf\folio\quad\it\currsubsection}\hfil\global\pageoddtrue\fi%
    }%
}

\section{Introduction}

\subsection*{The Riemann Integral and its Faults}

Recall the definition of the Riemann integral: given a function $f(x)$ on an interval $[a,b]$ we take a partition of this interval and representatives from each partition, $x_i$.
Then the Riemann sum of this function over this partition is $\sum f(x_i)\Delta x_i$.
Then if this sum converges to a value as $\sup\Delta x_i$ converges to $0$, this function is {\it Riemann integrable} and has an integral represented by $\int_a^b f(x)\,dx$.
Previously we have shown that a function is Riemann integrable if and only if it is almost always continuous, in particular all continuous functions are continuous.

But take for example ${\bb Q}$'s indicator function
$$ \chi_{{\bb Q}}(x) \coloneqq \cases{1 & $x\in{\bb Q}$\cr 0 & $x\notin{\bb Q}$} . $$
This function is nowhere continuous and thus is not Riemann integrable.
But we argue that it {\it should} be integrable.

Any theory if an integral should have the following two basic properties:
\benum
    \item {\it monotonicity\/}: if $f(x)\leq g(x)$ for every $x$ in the domain then $\int f(x)\,dx\leq\int g(x)\,dx$.
    \item {\it linearity\/}: $\int(\alpha f(x)+\beta g(x))\,dx=\alpha\int f(x)\,dx+\beta\int g(x)\,dx$.
\eenum

Let $\set{q_n}_{n=1}^\infty$ be an enumeration of the rationals and $\epsilon>0$.
Let us define $E_n\coloneqq\parens{q_n-\frac\epsilon{2^{n+1}},q_n+\frac\epsilon{2^{n+1}}}$, then we should think that
$$ \int\sum_{n=1}^\infty\chi_{E_n}(x)\,dx = \sum_{n=1}^\infty\int\chi_{E_n}(x)\,dx = \sum_{n=1}^\infty\frac\epsilon{2^n} = \epsilon \eqnum $$
Now $\chi_{\bb Q}(x)\leq\sum_{n=1}^\infty\chi_{E_n}(x)$ for all $x$ and so $\int\chi_{\bb Q}(x)\,dx\leq\epsilon$ for every $\epsilon>0$ and so we should think that $\int\chi_{\bb Q}(x)\,dx=0$.

Now obviously $\chi_{\bb Q}$ is not Riemann-integrable, and so there is an issue with the above argument.
In fact there are two: firstly in $(1)$ we assumed that $\int\sum_{n=1}^\infty\chi_{E_n}=\sum_{n=1}^\infty\int\chi_{E_n}$, which only holds if the sum converges uniformly.
Secondly, $\sum_{n=1}^\infty\chi_{E_n}(x)$ takes on infinite values (for every rational number, the sum is infinite) and so it is not even Riemann integrable.

So we want a theory of integration which allows for two things: 1) the ability to deal with convergence of an integral without necessarily needing uniform convergence, 2) the ability to deal with functions
which are not Riemann-integrable.
Lebesgue's theory of integration is based on the following observation: partitioning the domain of the function will necessarily require some form of continuity, so instead try partitioning the {\it range}
of the function.
So given the partition $y_0<\cdots<y_n$ we can imagine some Lebesgue sum of this partition to be
$$ \sum_{i=0}^n y_i\cdot\abs{E_i},\qquad E_i=\set{x\in[a,b]}[y_i\leq f(x)\leq y_{i+1}] $$
where $\abs S$ is some notion of the ``width'' of the set $S$, {\it which we have not yet defined} (it is not the cardinality of the set).
For an interval this should be the length of the interval, but for arbitrary sets it becomes harder to understand how we should approach defining it.
And in order to define the integral of $\chi_{\bb Q}$, it is necessary to define this width for arbitrary sets, or at least for a larger family of sets than just intervals, since computing the Lebesgue
sums of $\chi_{\bb Q}$ will involve terms containing $\abs{{\bb Q}}$.

This ``Lebesgue sum'' will not be precisely how we define Lebesgue integration, but it does give us a starting point: how do we define the ``width'' of a set $E\subseteq{\bb R}$.

\vfill\break

\section{Lebesgue Integration}

\subsection{The Lebesgue Measure}

We would like a function $m$ which measures the width of arbitrary sets $E\subseteq{\bb R}$.
Such a function would ideally satisfy the following properties:
{\def\enumstyle#1{$\m@th\bf(m#1)$}
\benum
    \item $m$ is a function $m\colon\powsetof{\bb R}\longto[0,\infty]$,
    \item for every interval $I$, $m(I)$ is the length of $I$,
    \item the measure of a set is preserved under movement, ie. $m(E+\alpha)=m(E)$ for every $\alpha\in{\bb R}$ where $E+\alpha=\set{x+\alpha}[x\in E]$,
    \item if $\set{E_n}_{n=1}^\infty$ is a sequence of disjoint sets then $m\parens{\bigdcup_{n=1}^\infty E_n}=\sum_{n=1}^\infty m(E_n)$.
        This is called {\it $\sigma$-additivity}.
\eenum}

\bdefn[title=The Outer Measure]

    Let $E\subseteq{\bb R}$, then we define $E$'s {\emphcolor outer measure} to be
    $$ m^*(E) \coloneqq \infof{\sum_{n=1}^\infty\abs{I_n}}[E\subseteq\bigcup_{n=1}^\infty I_n\hbox{ where $I_n$ are all open intervals}] $$

\edefn

This set is nonempty since ${\bb R}$ can be covered by open intervals (eg. $\set{(n,n+2)}_{n\in{\bb Q}}$) and therefore so can every subset.
Obviously we have that $m^*(\varnothing)=0$ since we can take arbitrarily small arbitrary intervals.
Notice that for every $\epsilon>0$, we showed in the previous section there exists open intervals $\set{E_n}_{n=1}^\infty$ such that ${\bb Q}\subseteq\bigcup_{n=1}^\infty E_n$ and
$\sum_{n=1}^\infty\abs{E_n}=\epsilon$.
Thus we have that $m^*({\bb Q})\leq\epsilon$ for every $\epsilon>0$ and so $m^*({\bb Q})=0$ as well.

Notice that we can also take a finite set of $I_n$s, as we can add infinitely many $I_n$s of arbitrarily small width (eg. add $I_n$s of length $\frac\epsilon{2^n}$) and this will add $\epsilon$ to the
sum, and so the infimum remains the same.
Thus we have that
$$ m^*(E) = \infof{\sum_{n=1}^\infty\abs{I_n}}[E\subseteq\bigcup_{j\in J}I_j\hbox{ where $I_n$ are all open intervals and $J$ is countable}] $$

Now, does the outer measure satisfy the conditions $\rm m1$ through $\rm m4$?
\benum
    \item $m^*$ is indeed a function from $\powsetof{\bb R}$ to $[0,\infty]$,
    \item $m^*(I)=\abs I$ for all intervals $I$ (proven below).
    \item $m^*(E+\alpha)=m^*(E)$ as there is a width-preserving bijection between collections of intervals covering $E$ and $E+\alpha$ (in particular $I\mapsto I+\alpha$).
\eenum

But $m^*$ is not $\sigma$-additive, and we can only ensure $\sigma$-subadditivity:

\bthrm

    Let $\set{E_n}_{n=1}^\infty$ be a sequence of (not necessarily disjoint) subsets of ${\bb R}$, then
    $$ m^*\parens{\bigcup_{n=1}^\infty E_n} \leq \sum_{n=1}^\infty m^*(E_n) $$

\ethrm

\Proof for every $E_n$, let us take a cover for $E_n$ of open intervals $\set{I_k^{(n)}}_{k=1}^\infty$ such that $m^*(E_n)\geq\sum_{k=1}^\infty\abs{I_k^{(n)}}+\frac\epsilon{2^n}$.
Then we have that
$$ \sum_{n=1}^\infty m^*(E_n) \geq \sum_{n=1}^\infty\parens{\sum_{k=1}^\infty\abs{I_k^{(n)}}+\frac\epsilon{2^n}} = \sum_{n,k=1}^\infty\abs{I_k^{(n)}}+\epsilon $$
Since $\set{I_k^{(n)}}_{n,k=1}^\infty$ is a cover of $\bigcup_{n=1}^\infty E_n$, we have that
$$ \sum_{n=1}^\infty m^*(E_n) \geq \sum_{n,k=1}^\infty\abs{I_k^{(n)}}+\epsilon \geq m^*\parens{\bigcup_{n=1}^\infty E_n}+\epsilon $$
Since $\epsilon>0$ is arbitrary, we get the desired inequality (by taking $\epsilon\to0$, the above inequality is preserved).
\qed

Of course this does not prove that $m^*$ is not $\sigma$-additive, we have simply proven a weaker condition.

This helps us show that $m^*(I)=\abs I$ for all intervals $I$.
For open intervals this is trivial, and we have that $m^*(E\cup\set a)\leq m^*(E)+m^*(\set a)=m^*(E)$ (the measure of a singleton is obviously zero) and $m^*(E\cup\set a)\geq m^*(E)$ by monotonicity.
All intervals are obtained by adding a finite number of points to an open interval, so for example $m^*([a,b])=m^*\bigl((a,b)\cup\set{a,b}\bigr)=m^*((a,b))=b-a$ as required.

\bprop[title=The Vitali Set]

    There exists no function which satisfies properties $\rm m1$ through $\rm m4$.

\eprop

\Proof let us define an equivalence relation on ${\bb R}$ as follows: $x\sim y\iff x-y\in{\bb Q}$.
Notice that the equivalence classes of this relation are of the form $x+{\bb Q}$ for some $x\in{\bb R}$ and thus they are all countable and dense.
For every equivalence class choose a single representative in $[0,1]$ to form the set $E\subseteq[0,1]$.
Notice then that
$$ {\bb R} = \bigdcup_{q\in{\bb Q}}(E+q) = E+{\bb Q} = \set{x+q}[x\in E,q\in{\bb Q}] $$
this union is disjoint since if $x\in E+q\cap E+p$ then $x=x_1+q$ and $x=x_2+p$ so $x\sim x_1\sim x_2$ but we put only a single representative of each equivalence class into $E$.
For every $y\in[0,1]$, there exists an $x\in E$ such that $x\sim y$ so $x-y\in{\bb Q}\cap[-1,1]$, and so if $y\in E+q$ for some $q\in[-1,1]$.
Thus
$$ [0,1] \subseteq \bigdcup_{q\in{\bb Q}\cap[-1,1]}E+q = E + {\bb Q}\cap[-1,1] \subseteq [-1,2] $$
If $m$ is a function which satisfies the four properties above, it is also monotonic (which can be derived from $\sigma$-additivity: if $A\subseteq B$ then $m(B)=m(A)+m(B\setminus A)\geq m(A)$), and so
$$ m([0,1]) = 1 \leq \sum_{q\in{\bb Q}\cap[-1,1]}m(E) \leq 3 $$
Since ${\bb Q}\cap[-1,1]$ is infinite, we must have that $m(E)=0$ as otherwise the sum is infinite.
But then the sum is $0$ and not greater than $1$, which is a contradiction.
So the {\it Vitali set\/} $\bigcup_{q\in{\bb Q}\cap[-1,1]}E+q$ cannot be measurable.
\qed

So we must weaken one of the conditions.
$m^*$ is already an example of a function which satisfies $\rm m1$ through $\rm m3$ so they are not contradictory (also notice that this means $m^*$ cannot be $\sigma$-additive).
But $\sigma$-additivity is extremely important to Lebesgue's theory of integration, so we will instead weaken $\rm m1$ to be
$$ \hbox{$({\bf m1})$\kern.25cm $m$ is a function ${\cal L}({\bb R})\longto[0,\infty]$} $$
where ${\cal L}({\bb R})$ is the set of all Lebesgue-measurable sets of ${\bb R}$:

\bdefn[title=Carath\'eodory]

    A set $E\subseteq{\bb R}$ is called {\emphcolor Lebesgue measurable} (or just {\it measurable}) if for every $A\subseteq{\bb R}$,
    $$ m^*(A)=m^*(A\cap E)+m^*(A\cap E^c) $$

\edefn

Notice that by subadditivity $m^*(A)\leq m^*(A\cap E)+m^*(A\cap E^c)$, to show that $E$ is Lebesgue measurable it is sufficient to show the other direction ($\geq$).
This implies that all sets $E$ with zero outer measure are Lebesgue measurable: $m^*(A\cap E)+m^*(A\cap E^c)=m^*(A\cap E^c)\leq m^*(A)$ as required ($m^*(A\cap E)\leq m^*(E)=0$).
Further notice that $E$ is measurable if and only if $E^c$ is by symmetry of the definition.

\bthrm

    Every open interval of the form $(a,\infty)$ is measurable.

\ethrm

\Proof let $A$ be a subset of ${\bb R}$.
Let us define
$$ A^+ \coloneqq A\cap(a,\infty),\qquad A^- \coloneqq A\cap(a,\infty)^c = A\cap(-\infty,a] $$
We must show that $m^*(A^+)+m^*(A^-)\leq m^*(A)$.
Let $\epsilon>0$ and let $\set{I_n}_{n=1}^\infty$ be a cover of $A$ consisting of open intervals where $\sum_{n=1}^\infty\abs{I_n}\leq m^*(A)+\epsilon$.
Then for every $n$, define $I_n^+=I_n\cap(a,\infty)$ and $I_n^-=I_n\cap(a,\infty)^c$, so $\set{I_n^+}$ is a cover for $A^+$ and $\set{I_n^-}$ is a cover for $A^-$.
And since these are intervals we have $\abs{I_n}=\abs{I_n^+}+\abs{I_n^-}$.
So we have
$$ m^*(A) \geq \sum_{n=1}^\infty\abs{I_n}-\epsilon = \sum_{n=1}^\infty\abs{I_n^+} + \sum_{n=1}^\infty\abs{I_n^-} + \epsilon \geq m^*(A^+) + m^*(A^-) + \epsilon $$
And since $\epsilon>0$ is arbitrary, we get $m^*(A)\geq m^*(A^+)+m^*(A^-)$ as required.
\qed

\bprop

    The set of all measurable sets is invariant under movement, meaning if $E$ is measurable so too is $E+\alpha$.

\eprop

\Proof let $A\subseteq{\bb R}$ then notice that $x-\alpha\in A\cap(E+\alpha)-\alpha\iff x\in A\cap(E+\alpha)\iff x\in A,E+\alpha\iff x-\alpha\in A-\alpha,E$.
So $A\cap(E+\alpha)-\alpha=(A-\alpha)\cap E$, and so we get
\multlines{
    m^*(A\cap(E+\alpha)) + m^*(A\cap(E+\alpha)^c) = m^*(A\cap(E+\alpha)-\alpha) + m^*(A\cap(E+\alpha)^c-\alpha)\cr
    &= m^*((A-\alpha)\cap E) + m^*((A-\alpha)\cap E^c) = m^*(A-\alpha) = m^*(A)
}
as required.
\qed

\blemm

    The finite union of measurable sets is measurable.
    And if $\set{E_k}_{k=1}^n$ are disjoint and measurable, then
    $$ m^*\parens{\bigdcup_{k=1}^nE_k} = \sum_{k=1}^n m^*(E_k) $$

\elemm

\Proof it is sufficient to prove this for two measurable sets and then to proceed inductively for arbitrary $n$.
So suppose $E,F$ are measurable, we must show that $E\cup F$ is.
Let $A\subseteq{\bb R}$, then
\multlines{
    m^*(A\cap(E\cup F)) + m^*(A\cap(E\cup F)^c) = m^*((A\cap E)\cup(A\cap F)) + m^*(A\cap E^c\cap F^c)\cr
    &= m^*((A\cap E)\dcup(A\cap F\cap E^c)) + m^*(A\cap E^c\cap F^c)\leq m^*(A\cap E) + m^*(A\cap E^c\cap F) + m^*(A\cap E^c\cap F)\cr
    &= m^*(A\cap E) + m^*(A\cap E^c) = m^*(A)
}
The final equality is due to $F$ being measurable, and so it satisfies Carath\'eodory's definition for $A\cap E^c$.

And we similarly prove additivity by induction on $n$.
For two disjoint measurable sets $E,F$, we have by Carath\'eodory on $E$:
$$ m^*(E\dcup F) = m^*((E\dcup F)\cap E) + m^*((E\dcup F)\cap E^c) = m^*(E) + m^*(F) $$
\qed

Since the complement of a set is measurable, and the empty set is measurable, this proposition tells us that ${\cal L}({\bb R})$, the set of all Lebesgue measurable sets, is an algebra of sets
(non-empty, closed under complements and unions/intersections).
Intersections are of course measurable since $\bigcap_{k=1}^nE_k=\parens{\bigcap_{k=1}^nE_k^c}^c$, and so are differences since $E\setminus F=E\cap F^c$.
Notice that since $m^*(E)=m^*(E\cap F)+m^*(E\cap F^c)$, we have
$$ m^*(E\setminus F) = m^*(E\cap F^c) = m^*(E) - m^*(E\cap F) $$
But stronger than this, ${\cal L}({\bb R})$ is in fact a $\sigma$-algebra (to be defined later).

\blemm

    Suppose $E_1,\dots,E_n$ are measurable and disjoint, then for every $A\subseteq{\bb R}$,
    $$ m^*\parens{A\cap\bigdcup_{k=1}^n E_k} = \sum_{k=1}^n m^*(A\cap E_k) $$

\elemm

\Proof We prove this by induction on $n$; for $n=1$ this is trivial.
If this holds for $n$, then using the inductive assumption for $E_1,\dots,E_{n-1},E_n\dcup E_{n+1}$
$$ m^*\parens{A\cap\bigdcup_{k=1}^{n+1}E_k} = \sum_{k=1}^{n-1}m^*(A\cap E_k) + m^*(A\cap(E_n\dcup E_{n+1})) $$
Now,
\multlines{
    m^*(A\cap(E_n\dcup E_{n+1})) = m^*(A\cap(E_n\dcup E_{n+1})\cap E_n) = m^*(A\cap(E_n\dcup E_{n+1})\cap E_n^c)\cr
    &= m^*(A\cap E_n) + m^*(A\cap E_{n+1})
}
and so we get that indeed
$$ m^*\parens{A\cap\bigdcup_{k=1}^{n+1}E_k} = \sum_{k=1}^{n+1}m^*(A\cap E_k) \qed $$

\bthrm

    Let $\set{E_n}_{n=1}^\infty$ be Lebesgue measurable, then $\bigcup_{n=1}^\infty E_n$ is also Lebesgue measurable (equivalently ${\cal L}({\bb R})$ is a $\sigma$-algebra).
    Furthermore if the sets are disjoint, then we have $\sigma$-additivity:
    $$ m^*\parens{\bigdcup_{n=1}^\infty E_n} = \sum_{n=1}^\infty m^*(E_n) $$

\ethrm

\Proof we can assume from the outset that $\set{E_n}$ are disjoint as we can define $F_n\coloneqq E_n\setminus\bigcup_{k=1}^{n-1}E_k$.
This is measurable by the previous lemmas, and $\bigcup_{n=1}^\infty E_n=\bigdcup_{n=1}^\infty F_n$.
Now define
$$ E \coloneqq \bigdcup_{n=1}^\infty E_n,\qquad G_n\coloneqq\bigdcup_{k=1}^nE_k $$
Let $A\subseteq{\bb R}$, and by $G_n$'s measurability we have that
$$ m^*(A) = m^*(A\cap G_n) + m^*(A\cap G_n^c) \geq m^*(A\cap G_n) + m^*(A\cap E^c) $$
By the above lemma this means $m^*(A) \geq \sum_{k=1}^nm^*(A\cap E_k) + m^*(A\cap E^c)$, and this inequality is preserved by taking the limit $n\to\infty$ so
$$ m^*(A) \geq \sum_{k=1}^\infty m^*(A\cap E_k) + m^*(A\cap E^c) \eqnum $$
By subadditivity, we have that $m^*(A\cap E)=m^*\parens{\bigdcup_{k=1}^\infty(A\cap E_k)}\leq\sum_{k=1}^\infty m^*(A\cap E_k)$, so
$$ m^*(A) \geq m^*(A\cap E) + m^*(A\cap E^c) $$
so $E$ is indeed measurable, as required.
If we let $A=E=\bigdcup_{n=1}^\infty E_n$, then we get that $A\cap E_k=E_k$ and so by ({\bf1}) we get that
$$ m^*(E) \geq \sum_{k=1}^\infty m^*(E_k) $$
and $\leq$ is given by subadditivity so we have equality.
\qed

Notice that the Lebesgue outer measure defines a pseudometric on $\powsetof{\bb R}$ by $d(A,B)\coloneqq m^*(A\symdiff B)$.

\bthrm

    $E\subseteq{\bb R}$ is Lebesgue measurable if and only if forall $\epsilon>0$ there exists a countable union of open intervals $\bigcup_{n=1}^\infty I_n$ such that
    $d\parens{\bigcup_{n=1}^\infty I_n,E}<\epsilon$.

\ethrm

\Proof suppose $E$ is measurable, then for every $\epsilon>0$ there exists a cover $E\subseteq\bigcup I_n$ of open intervals such that $m^*(E)+\epsilon>m^*\parens{\bigcup I_n}$.
Now
$$ d\parens{\bigcup I_n,E} = m^*\parens{\bigcup I_n\setminus E} = m^*\parens{\bigcup I_n} - m^*(E) < \epsilon $$
since all the sets in play are measurable, as required.
Now suppose that the condition holds, we must prove that $E$ is measurable.
We can assume without loss of generality that $E\subseteq\bigcup I_n$ (as we can cover the symmetric difference with open intervals).
Now let us take a sequence of such covers $U_k$ such that $m^*(U_k\setminus E)<\frac1k$, and define $U=\bigcap U_k$.
And $m^*(U\setminus E)\leq m^*(U_k\setminus E)<\frac1k$ so $m^*(U\setminus E)=0$, and this means that $U\setminus E$ is measurable.
Since $U_k$ are all measurable, so is $U$ and since $E=U\setminus(U\setminus E)$, $E$ is measurable.
\qed

In fact what we have shown is that every measurable set $E$ is of the form $G\setminus N$, where $G$ is a countable intersection of open sets (a $G_\delta$ set), and $N$ is a set of zero measure.
This theorem implies that every open interval is Lebesgue measurable, as just define $I_n=I$.
Recall that ${\bb R}$ is a second-countable topological space, meaning it has a countable basis, namely the basis $\set{(p,q)}[p<q\in{\bb Q}]$.
This means that every open set in ${\bb R}$ is the countable union of open intervals, and therefore every open set is contained in ${\cal L}({\bb R})$.
And so closed sets, which are complements of open sets, are also measurable.
And so too are $G_\delta$ sets as the countable intersection of measurable sets, and so sets of the form $G\setminus N$ where $G$ is $G_\delta$ and $m^*(N)=0$ are measurable.
So we have proven

\bprop

    $E$ is measurable if and only if there exists a $G_\delta$ set $G$ and a zero-measure set $N$ such that $E=G\setminus N$.

\eprop

\subsection{General Measure Spaces, Briefly}

\bdefn

    Let $X$ be a set, then a non-empty collection $\Sigma\subseteq\powsetof X$ is called a {\emphcolor $\sigma$-algebra} if it satisfies
    \benum
        \item $S\in\Sigma\iff S^c\in\Sigma$
        \item if $\set{S_n}_{n=1}^\infty\subseteq\Sigma$ then $\bigcup_{n=1}^\infty S_n\in\Sigma$
    \eenum
    By $(1)$ and $(2)$ we get that $\sigma$-algebras are also closed under intersections, and so $\varnothing=S\cap S^c\in\Sigma$ and $X=\varnothing^c\in\Sigma$.

    If $X$ is a set and $\Sigma$ a $\sigma$-algebra over $X$, then $(X,\Sigma)$ is called a {\emphcolor measurable space}.
    And a {\emphcolor measure space} is a triplet $(X,\Sigma,\mu)$ where $\mu$ is a $\sigma$-algebra over $X$, and $\mu$ is a {\emphcolor measure} over $\Sigma$:
    \benum
        \item $\mu\colon\Sigma\longto[0,\infty]$,
        \item $\mu$ is $\sigma$-additive: if $\set{S_n}_{n=1}^\infty\subseteq\Sigma$ are disjoint $\mu\parens{\bigdcup_{n=1}^\infty S_n}=\sum_{n=1}^\infty\mu(S_n)$
        \item $\mu(\varnothing)=0$.
    \eenum

\edefn

\bexam

    Let $m$ be the {\emphcolor Lebesgue measure} over ${\bb R}$, the restriction of $m^*$ to the collection of Lebesgue measurable sets: $m\coloneqq m^*\bigr|_{{\cal L}({\bb R})}$.
    Then $({\bb R},{\cal L}({\bb R}),m)$ is a measure space.

\eexam

Measures are obviously monotonic: if $E,F\in\Sigma$ and $E\subseteq F$ then $\mu(F)=\mu((F\setminus E)\dcup E)=\mu(F\setminus E)+\mu(E)\geq\mu(E)$ (since recall that $\sigma$-algebras are closed under
differences, as they are just the intersections of the complement).
And measures are subadditive:

\bthrm

    Let $(X,\Sigma,\mu)$ be a measure space, then for any $\set{A_n}_{n=1}^\infty\subseteq\Sigma$ (not necessarily disjoint):
    $$ \mu\parens{\bigcup_{n=1}^\infty A_n}\leq\sum_{n=1}^\infty\mu(A_n) $$

\ethrm

\Proof define $B_n\coloneqq A_n\setminus\bigcup_{k=1}^{n-1}A_k$, these are all disjoint and $\bigdcup_{n=1}^\infty B_n=\bigcup_{n=1}^\infty A_n$.
And since $B_n\subseteq A_n$, $\mu(B_n)\leq\mu(A_n)$.
Thus
$$ \mu\parens{\bigcup_{n=1}^\infty A_n} = \mu\parens{\bigdcup_{n=1}^\infty B_n} = \sum_{n=1}^\infty \mu(B_n) \leq \sum_{n=1}^\infty\mu(A_n) \qed $$

One of the most important properties of measure spaces is {\it continuity from below} and {\it continuity from above}:

\bthrm[title=Continuity of Measures, name=contofmeasures]

    Let $(X,\Sigma,\mu)$ be a measure space, then
    \benum
        \item {\emphcolor Continuity from below}: if $E_1\subseteq E_2\subseteq\cdots$ is an increasing sequence in $\Sigma$, then
            $$ \mu\parens{\bigcup_{n=1}^\infty E_n} = \lim_{n\to\infty}\mu(E_n) $$
        \item {\emphcolor Continuity from above}: if $E_1\supseteq E_2\supseteq\cdots$ is a decreasing sequence in $\Sigma$ such that $\mu(E_1)<\infty$, then
            $$ \mu\parens{\bigcap_{n=1}^\infty E_n} = \lim_{n\to\infty}\mu(E_n) $$
    \eenum

\ethrm

\Proof notice that the limits in both cases exist since the sequences are monotonic.
\benum
    \item Let $E\coloneqq\bigcup_{n=1}^\infty E_n$, then $E\supseteq E_n$ so $\mu(E)\geq\mu(E_n)$ and so $\mu(E)\geq\lim_{n\to\infty}\mu(E_n)$.
        Define $F_n\coloneqq E_n\setminus E_{n-1}$, so that $F_n$ are disjoint and $\bigdcup_{k=1}^nF_k=E_n$ for all $n$, and so $\bigdcup_{k=1}^\infty F_k=E$, so
        $$ \mu(E) = \sum_{k=1}^\infty \mu(F_k) = \lim_{n\to\infty}\sum_{k=1}^n\mu(F_k) = \lim_{n\to\infty}\mu\parens{\bigdcup_{k=1}^nF_k}=\lim_{n\to\infty}\mu(E_n) $$
        as required.
    \item Define $E\coloneqq\bigcap_{n=1}^\infty E_n$, $F_n\coloneqq E_1\setminus E_n$, $F\coloneqq\bigcup_{n=1}^\infty F_n$.
        Thus $E=E_1\setminus F$, and so by above
        $$ \mu(E) = \mu(E_1) - \mu(F) = \mu(E_1) - \lim_{n\to\infty}\mu(F_n) = \mu(E_1) - \lim_{n\to\infty}\bigl(\mu(E_1)-\mu(E_n)\bigr) = \lim_{n\to\infty}\mu(E_n) $$
        \qed
\eenum

\subsection{Measurable Functions}

\bthrm

    Let $(X,\Sigma)$ be a measureable space, and $f\colon X\longto\overline{\bb R}\ (={\bb R}\cup\set{\pm\infty})$ be an extended real function.
    Then the following are equivalent:
    \benum
        \item for every $\alpha\in{\bb R}$, $\set{x\in X}[f(x)>\alpha]\in\Sigma$,
        \item for every $\alpha\in{\bb R}$, $\set{x\in X}[f(x)\geq\alpha]\in\Sigma$,
        \item for every $\alpha\in{\bb R}$, $\set{x\in X}[f(x)<\alpha]\in\Sigma$,
        \item for every $\alpha\in{\bb R}$, $\set{x\in X}[f(x)\leq\alpha]\in\Sigma$.
    \eenum

\ethrm

\Proof notice that $(1)\iff(4)$ and $(2)\iff(3)$ are trivial since $\set{x\in X}[f(x)>\alpha]^c=\set{x\in X}[f(x)\leq\alpha]$ and similar, and $S$ is measurable if and only if $S^c$ is.
Now we prove $(1)\iff(2)$, notice that
$$ \set{x\in X}[f(x)\geq\alpha] = \bigcap_{n=1}^\infty\set{x\in X}[f(x)>\alpha-\frac1n] $$
so if $(1)$ then the right side is the countable intersection of measurable sets and is therefore measurable, so $(1)\implies(2)$.
And
$$ \set{x\in X}[f(x)>\alpha] = \bigcup_{n=1}^\infty\set{x\in X}[f(x)\geq\alpha+\frac1n] $$
so anlogously $(2)\implies(1)$.
Similarly for $(3)\iff(4)$.
\qed

\bdefn

    Let $(X,\Sigma)$ be a measurable space and $f\colon X\longto\overline{\bb R}$ an extended real function.
    If any of the above equivalent conditions hold, then $f$ is a {\emphcolor $\Sigma$-measurable function} (if $\Sigma$ is understood, just measurable).

\edefn

Notice that constant functions $f\colon x\mapsto c$ are measurable: for $\alpha\geq c$, $\set{x\in X}[f(x)>\alpha]=\varnothing$ which is measurable.
And for $\alpha<c$, $\set{x\in X}[f(x)>\alpha]=X$ which is measurable.

\bcoro

    Let $f$ be an extended real function, then
    \benum
        \item if $f$ is measurable, for every $x_0\in\overline{\bb R}$, $f^{-1}(x_0)\in\Sigma$,
        \item if $f$ is measurable, for every interval $I\subseteq\overline{\bb R}$, $f^{-1}(I)\in\Sigma$,
        \item if $f\colon{\bb R}\longto{\bb R}$ is continuous, then $f$ is Lebesgue measurable (ie. measurable in $({\bb R},{\cal L}({\bb R}))$).
    \eenum

\ecoro

\Proof
\benum
    \item Notice that
        $$ f^{-1}(x_0) = \set{x\in X}[f(x)\geq x_0]\cap\set{x\in X}[f(x)\leq x_0] $$
        which is the intersection of measurable sets.
    \item For an interval of the form $I=[a,b)$,
        $$ f^{-1}(I) = \set{x\in X}[f(x)\geq a]\cap\set{x\in X}[f(x)<b] $$
        which is the intersection of measurable sets.
        All other intervals are done similarly.
    \item Let $\alpha\in{\bb R}$, then $E=(\alpha,\infty)$ is open and so $f^{-1}(E)$ is open and thus Lebesgue measurable.
        And $f^{-1}(E)=\set{x\in{\bb R}}[f(x)>\alpha]\in{\cal L}({\bb R})$ as required.
        \qed
\eenum

\bthrm

    Let $(X,\Sigma)$ be a measurable space, $f,g\colon X\longto{\bb R}$ and $c\in{\bb R}$.
    Then $f\pm g,c\cdot f,f\cdot g$ are measurable.

\ethrm

\benum
    \item Let $\alpha\in{\bb R}$, then $f(x)+g(x)<\alpha$ if and only if $f(x)<\alpha-g(x)$ if and only if there exists a $\beta\in{\bb Q}$ such that $f(x)<\beta<\alpha-g(x)$.
        So
        $$ \set{x\in X}[f(x)+g(x)<\alpha] = \bigcup_{\beta\in{\bb Q}}\bigl(\set{x\in X}[f(x)<\beta]\cap\set{x\in X}[g(x)<\alpha-\beta]\bigr) $$
        which is the countable union of the intersection of measurable sets, which is measurable.
        For $f-g$, this is due to $(2)$ which states that $-g$ is measurable.
    \item Notice that for $\alpha\in{\bb R}$, if $c>0$ then $\set{x\in X}[c\cdot f(x)<\alpha]=\set{x\in X}[f(x)<\frac\alpha c]$ which is measurable.
        If $c<0$ then $\set{x\in X}[c\cdot f(x)<\alpha]=\set{x\in X}[f(x)>\frac\alpha c]$.
        If $c=0$, then $c\cdot f=0$, and constant functions are measurable always.
        This combined with $(1)$ show us that all linear combinations of measurable functions are measurable.
    \item First we will prove that $f^2$ is measurable.
        Notice that for $\alpha\geq0$, the set $\set{x\in X}[f(x)^2\geq\alpha]=\set{x\in X}[f(x)\geq\sqrt\alpha]$ is measurable.
        And for $\alpha<0$, $\set{x\in X}[f(x)\geq\alpha]=X$ is measurable.
        And
        $$ f\cdot g = \frac14\parens{(f+g)^2 - (f-g)^2} $$
        We just showed that $f\pm g$ are measurable, and so too are $(f\pm g)^2$ and any of their linear combinations, so $f\cdot g$ is measurable.
        \qed
\eenum

Notice that for $f,g\colon X\longto\overline{\bb R}$, $f(x)+g(x)$ is undefined when $f(x)=\infty$ and $g(x)=-\infty$ or vice versa.
We generally take that $\pm\infty\cdot0\coloneqq0$, but $f(x)\cdot g(x)$ is not necessarily defined when $f(x)=\pm\infty$ and $g(x)=0$ or vice versa.
But if we define $f\pm g$ and $f\cdot g$ to be any arbitrary constant (eg. $0$) at these problematic points, we can similarly show that $f\pm g$ and $f\cdot g$ are measurable.

\bthrm

    Let $(X,\Sigma)$ be a measurable space and $\set{f_n}_{n=1}^\infty$ a sequence of extended real measurable functions.
    Then $\sup_nf_n(x),\inf_nf_n(x),\limsup f_n(x),\liminf f_n(x)$, and $\lim f_n(x)$ if it exists are measurable.

\ethrm

\Proof first we prove it for $f(x)=\sup_nf_n(x)$.
Let $\alpha\in{\bb R}$, then $f(x)\leq\alpha$ if and only if $f_n(x)\leq\alpha$ for all $\alpha$, so
$$ \set{x\in X}[f(x)\leq\alpha] = \bigcap_{n=1}^\infty\set{x\in X}[f_n(x)\leq\alpha] $$
which is the countable intersection of measurable sets.
Similar for $g(x)=\inf_nf_n(x)$.

Now define $h(x)=\limsup_nf_n(x)$, then $h(x)=\inf_k\sup_{n\geq k}f_n(x)$.
Let us define $g_k(x)=\sup_{n\geq k}f_n(x)$, so $h(x)=\inf_kg_k(x)$.
Since $g_k$ is the supremum of a sequence of measurable functions, it is measurable.
And so $h$ is the infimum of measurable functions, meaning it too is measurable.
We use an analogous proof for the case $\liminf_nf_n(x)=\sup_k\inf_{n\geq k}f_n(x)$.
If $\lim_nf_n(x)$ exists, then it is just equal to $\limsup_nf_n(x)=\liminf_nf_n(x)$.
\qed

\subsection{The Lebesgue Integral}

\bdefn

    Let $(X,\Sigma,\mu)$ be a measure space, and $A\in\Sigma$ be measurable.
    Then we define the {\emphcolor Lebesgue integral} of $\chi_A$ to be
    $$ \int_X\chi_A\,d\mu = \mu(A) $$

    And if the measurable function $\phi\colon X\longto[0,\infty)$ is {\emphcolor simple}, meaning it takes on only a finite number of values $a_1,\dots,a_n$, then define $A_i=\phi^{-1}\set{a_i}$ such that
    $\phi=\sum_{i=1}^na_i\chi_{A_i}$ where $A_i$ are disjoint, define its Lebesgue integral to be
    $$ \int_X\phi\,d\mu = \sum_{i=1}^na_i\mu(A_i) $$

    If $f$ is a function whose Lebesgue integral is defined, and $E\in\Sigma$ is measurable, then $f$'s Lebesgue integral over $E$ is defined to be
    $$ \int_Ef\,d\mu = \int_Xf\cdot\chi_E\,d\mu $$
\edefn

\bprop

    For $\phi,\psi$ simple,
    \benum
        \item $\int_X(\phi+\psi)=\int_X\phi+\int_X\psi$,
        \item if $c\geq0$ then $\int_Xc\phi=c\int_X\phi$,
        \item if $E$ and $F$ are disjoint measurable sets then $\int_{E\dcup F}\phi=\int_E\phi+\int_F\phi$,
        \item if $\phi\leq\psi$ (pointwise, meaning $\phi(x)\leq\psi(x)$ for every $x\in X$), then $0\leq\int_X\phi\leq\int_X\psi$,
        \item if $m\leq\phi\leq M$ and $E$ is measurable, then $m\mu(E)\leq\int_E\phi\leq M\mu(E)$.
    \eenum

\eprop

\Proof\benum
    \item Firstly, notice that if $\phi=\sum_{i=1}^na_i\chi_{A_i}$ where $A_i$ are not necessarily disjoint, still $\int_X\phi=\sum_{i=1}^na_i\mu(A_i)$.
        This is since $a\chi_A+b\chi_B=a\chi_{A\setminus B}+b\chi_{B\setminus A}+(a+b)\chi_{A\cap B}$ and so the integral is $a\mu(A\setminus B)+b\mu(B\setminus A)+(a+b)\mu(A\cap B)=a\mu(A)+b\mu(B)$.
        Then $(1)$ is a direct result of this: write $\phi$ and $\psi$ as linear combinations of characteristic functions.
    \item This is direct from definition: $c\phi=\sum ca_i\chi_{A_i}$ so its integral is $c\sum a_i\mu(A_i)$.
    \item This is since $\chi_{E\dcup F}=\chi_E+\chi_F$ and so
        $$ \int_{E\dcup F}\phi = \int(\phi\chi_E+\phi\chi_F) = \int\phi\chi_E + \int\phi\chi_F = \int_E\phi + \int_F\phi $$
    \item Notice that integrals are non-negative by definition.
        And then $\psi=\phi+(\psi-\phi)$, and $\psi-\phi$ is still simple, so $\int\psi=\int\phi+\int(\psi-\phi)\geq\int\phi$ as required.
    \item This is due to $\int_E c=\int_Xc\chi_E=c\mu(E)$.
        \qed
\eenum

\bdefn

    Let $f\colon X\longto[0,\infty]$ be measurable, then define its {\emphcolor Lebesgue integral}
    $$ \int_X f\,d\mu = \sup_{\stackmath{0\leq\phi\leq f\cr\phi\hbox{\setscale{7pt} simple}}}\int_X\phi\,d\mu $$

\edefn

Notice that we define the integral of a nonnegative function using the supremum of the set of simple functions bound by $f$.
Why not use the infimum of the simple functions which bound $f$? ie, why not have
$$ \int_X f\,d\mu \buildrel?\over= \inf_{\stackmath{\phi\geq f\cr\phi\hbox{\setscale{7pt} simple}}}\int_X\phi\,d\mu $$
Take for example $f(x)=e^{-x^2}$ which has a finite (Riemann) integral, we would like its Lebesgue integral to be finite as well.
But every simple function $\phi$ which bounds it must have an infinite integral: it must have a minimum value $m$, and this minimum value $m$ cannot be $0$ since $f$ is never zero.
And so $\int\phi\geq\int m=\infty$ for every $\phi$ which bounds $f$, so by this definition $\int f=\infty$, which is not ideal.

Note that if $f$ itself is simple, then every $\phi\leq f$ has an integral $\int\phi\leq\int f$ by the above theorem.
And since $f\leq f$, $\int f$ is in the set over which we take the supremum, so this definition of the integral does not contradict the previous definition.

\bthrm

    For $f,g$ measurable and nonnegative,
    \benum
        \item if $0\leq f\leq g$ then $0\leq\int_Xf\leq\int_Xg$,
        \item if $E\subseteq F$ are measurable then $\int_Ef\leq\int_Ff$,
        \item if $f=0$ almost always on $E$ then $\int_Xf=0$,
        \item if $\mu(E)=0$ then $\int_Ef=0$,
        \item if $m\leq f\leq M$ on $E$ then $m\mu(E)\leq\int_Xf\leq M\mu(E)$.
    \eenum

\ethrm

\Proof\benum
    \item This is since simple functions $\phi\leq f$ are also bound by $g$.
    \item This is since $\int_Ef=\int_Xf\cdot\chi_E$ and $f\cdot\chi_E\leq f\cdot\chi_F$, so this is a direct result of $(1)$.
    \item Let $E_1=f^{-1}\set0$ and $E_2=E\setminus E_1$.
        Then for $\phi\leq f$, $\phi$ must be zero on $E_1$ and so $\phi=\epsilon\chi_{E_2}$.
        So $\int\phi=\epsilon\mu(E_2)=0$ since $f$ is zero almost everywhere, meaning $\mu(E_2)=0$.
    \item This is since $f\cdot\chi_E$ is zero almost everywhere.
    \item This is since $\int_Ec=c\mu(E)$ still.
        \qed
\eenum

\bthrm[title=The Monotone Convergence Theorem, name=monothrm]

    Let $f_n\colon X\longto[0,\infty]$ be a monotonically increasing sequence of measurable functions (meaning $0\leq f_1(x)\leq f_2(x)\leq\cdots$ for every $x\in X$), define $f=\lim_{n\to\infty}f_n(x)$.
    Then
    $$ \int_Xf\,d\mu = \lim_{n\to\infty}\int_Xf_n\,d\mu $$
    meaning we can swap the integral and limit, if the sequence is increasing.

\ethrm

At this point in time, the lecturer drew a tree on the board to make some point about Lebesgue basing his theory of integration off of this theorem.
It was a nice tree, I didn't really listen too much to his explanation of why he drew the tree, but the tree itself was nice.

\Proof Notice that $f_n\leq f$ since $f_n$ is increasing, so $\int_Xf_n\leq\int_Xf$, and so $\lim\int_Xf_n\leq\int_Xf$.
So all that remains to show is the other direction: $\lim\int_Xf_n\geq\int_Xf$.
By definition, this is equivalent to
$$ \sup_{0\leq\phi\leq f}\int_X\phi \leq \lim_{n\to\infty}\int_Xf_n $$
Let $0\leq\phi\leq f$, set $\alpha\in(0,1)$, and define $E_n=\set{x\in X}[f_n(x)\geq\alpha\phi(x)]$.
Then $\set{E_n}$ is increasing (since $f_n$ is), and since if $x\in X$ then $f(x)>\alpha\phi(x)$ so there is an $n$ such that $f_n(x)\geq\alpha\phi(x)$, since $\alpha<1$.
Meaning there is an $n$ such that $x\in E_n$, so $\bigcup E_n=X$.

Now, suppose $\phi=\sum_ia_i\chi_{A_i}$, then since $E_n\cap A_i$ is increasing for every $n$, $\lim_n\mu(E_n\cap A_i)=\mu(A_i)$ since the union of $E_n$ is $X$.
So
$$ \lim\int_{E_n}\phi = \lim_n\sum_ia_i\chi_{A_i}\chi_{E_n} = \lim_n\sum_ia_i\mu(A_i\cap E_n) = \sum_ia_i\cdot\lim_n\mu(E_n\cap A_i) = \sum_ia_i\cdot\mu(A_i) = \int_X\phi $$
So we have that $f_n(x)\geq\alpha\phi(x)$ on $E_n$, so $\int_Xf_n\geq\int_{E_n}f_n\geq\int_{E_n}\alpha\phi=\alpha\int_{E_n}\phi$.
Taking the limit gives us $\lim_n\int_Xf_n\geq\alpha\int_X\phi$.
Since this is true for all $\alpha<1$, it is true for $\alpha=1$, so $\lim_n\int_Xf_n\geq\int_X\phi$, so taking the supremum over all $\phi\leq f$ gives $\lim_n\int_Xf_n\geq\int_Xf$ as required.
\qed

\bexam

    Let $f_n=\chi_{(n,\infty)}$, then $f_n$ is monotonically decreasing to $0$.
    But $\int f_n=\infty$ which does not converge to $\int0=0$.
    So the monotone convergence theorem does not hold in the case that the sequence is monotonically decreasing.

\eexam

\bthrm[title=Fatou's Lemma, name=fatou]

    Let $f_n\colon X\longto[0,\infty]$ be measurable, then
    $$ \int_X(\liminf f_n)\,d\mu \leq \liminf\int_X f_n $$

\ethrm

\Proof Recall that $\liminf f_n(x)=\lim_n\inf_{k>n}f_k(x)$, which is the limit of an increasing sequence.
So by \refmath{monothrm},
$$ \int_X\liminf f_n\,d\mu = \lim_n\int_X\inf_{k>n}f_k\,d\mu = \liminf_n\int_X\inf_{k\geq n}f_k\,d\mu \leq \liminf_n\int_X f_n\,d\mu \qed $$

\blemm

    For every nonnegative measurable function $f\colon X\longto[0,\infty]$ there exists a sequence of nonnegative simple functions $\set{\phi_n}_{n=1}^\infty$ which increases pointwise to $f$.
    And so by the monotone convergence theorem, $\int_Xf\,d\mu=\lim_{n\to\infty}\int_X\phi_n\,d\mu$.

\elemm

\Proof define $A_{n,k}=f^{-1}\bracks{\frac k{2^n},\frac{k+1}{2^n}}$, then define $\phi_n(A_{n,k})=\frac k{2^n}$.
For $x\in A_{n,k}\cap A_{n,k+1}$ we can set $\phi_n(x)=\frac{k+1}{2^n}$.
We define this for $0\leq k\leq 2^{2n}$.
This obviously converges to $f$ pointwise and is increasing.
\qed

\bthrm

    \benum
        \item if $f,g\colon X\longto[0,\infty]$ are measurable then
            $$ \int_X(f+g)\,d\mu = \int_Xf\,d\mu + \int_Xg\,d\mu $$
        \item if $f_n\colon X\longto[0,\infty]$ is a countable sequence of nonnegative measurable functions then
            $$ \int_X\parens{\sum_nf_n}\,d\mu = \sum_n\int_Xf_n\,d\mu $$
        \item if $E=\bigdcup_nE_n$ are all measurable then
            $$ \int_Ef\,d\mu = \sum_n\int_{E_n}f\,d\mu $$
        \item for every $E\in\Sigma$, define $\nu_f(E)=\int_Ef\,d\mu$.
            Then $\nu_f$ is a measure on $(X,\Sigma)$.
    \eenum

\ethrm

\Proof\benum
    \item By above let $\phi_n$ be a sequence of simple functions which increase to $f$ and $\psi_n$ be to $g$.
        Then $\phi_n+\psi_n$ increases to $f+g$ and so by the monotone convergence theorem
        $$ \int_X(f+g) = \lim_n\int_X(\phi_n+\psi_n) = \lim_n\int_X\phi_n+\int_X\psi_n = \int_Xf + \int_Xg $$
    \item Define $S_n=\sum_{k=1}^nf_k$, then $S_n$ increases to $\sum_nf_n$ so by the monotone convergence theorem and $(1)$,
        $$ \int_X\sum_nf_n = \lim_n\int_XS_n = \lim_n\sum_{k=1}^n\int_Xf_k = \sum_n\int_Xf_n $$
    \item Define $f_n=f\cdot\chi_{E_n}$ so that $f\cdot\chi_E=\sum_nf_n$, then this follows from $(2)$.
    \item This is a direct result of $(3)$.
        \qed
\eenum

\bdefn

    We say that a trait occurs {\emphcolor almost everywhere} (concisely, ae) if the set of all points where it doesn't occur has measure zero.

\edefn

So for example $\chi_{\bb Q}=0$ ae since it is not zero only on ${\bb Q}$ which has measure zero.

\bthrm

    Let $f,g\colon X\longto[0,\infty]$ be measurable.
    \benum
        \item if $f(x)=g(x)$ almost everywhere, then $\int_Xf=\int_Xg$.
        \item $\int_Xf=0$ if and only if $f=0$ almost everywhere.
        \item if $\int_Xf<\infty$ then $f<\infty$ almost everywhere.
    \eenum

\ethrm

\benum
    \item Let $E=\set{x\in X}[f(x)\neq g(x)]$ then $\mu(E)=0$ and so $\int_Ef=0$ by a previous theorem, and $f(x)=g(x)$ for $x\in E^c$,
        $$ \int_Xf = \int_Ef + \int_{E^c}f = \int_{E^c}g = \int_Xg $$
    \item If $f=0$ almost everywhere then by above its integral is zero.
        Otherwise define $E_n=\set{x\in X}[f(x)>\frac1n]$ then
        $$ 0 = \int_Xf \geq \int_{E_n}f \geq \int_{E_n}\frac1n = \frac1n\mu(E_n) $$
        so $\mu(E_n)=0$.
        And $f(x)>0$ if and only if $x\in E_n$ for some $n$, thus $E=\set{x\in X}[f(x)>0]=\bigcup_nE_n$ and so $\mu(E)=\lim_n\mu(E_n)=0$ by continuity of $\mu$.
    \item Set $E=\set{x\in X}[f(x)=\infty]$, then
        $$ \infty > \int_Xf \geq \int_Ef = \infty\mu(E) $$
        So $\mu(E)$ must be zero.
        \qed
\eenum

\bdefn

    Let $f\colon X\longto[-\infty,\infty]$ be measurable, then define
    $$ f^+(x) \coloneqq \cases{f(x) & $f(x)\geq0$\cr 0 & $f(x)<0$},\qquad f^-(x) \coloneqq \cases{0 & $f(x)\geq0$\cr -f(x) & $f(x)<0$} $$
    so that $f(x)=f^+(x)-f^-(x)$ for all $x\in X$.
    Notice that $f^+(x)=\maxof{f(x),0}$ and $f^-(x)=\maxof{-f(x),0}$ so that $f^+$ and $f^-$ are measurable.

\edefn

\bdefn

    Let $f\colon X\longto[-\infty,\infty]$ be measurable, then $f$ is {\emphcolor Lebesgue integrable} if
    $$ \int_Xf^+\,d\mu < \infty \quad\hbox{and}\quad \int_Xf^-\,d\mu < \infty $$
    and if so, define
    $$ \int_Xf\,d\mu \coloneqq \int_Xf^+\,d\mu - \int_Xf^-\,d\mu $$

\edefn

Notice that $\abs f=f^++f^-$ so that
$$ \int_X\abs f\,d\mu \coloneqq \int_Xf^+\,d\mu + \int_Xf^-\,d\mu $$
And in particular $f$ is integrable if and only if $\abs f$ is.
It is also direct from the triangle inequality that $\abs{\int_Xf}\leq\int_X\abs f$.

\bthrm

    Let $f,g\colon X\longto\overline{\bb R}$ be integrable, then
    \benum
        \item if $h\colon X\longto\overline{\bb R}$ is measurable and satisfies $\abs{h(x)}\leq\abs{f(x)}$ almost everywhere, then $h$ is integrable.
        \item $f$ is integrable on every measurable set, and
            $$ \int_{A\dcup B}f\,d\mu = \int_Af\,d\mu + \int_Bf\,d\mu $$
        \item $\abs{f(x)}<\infty$ almost everywhere,
        \item if $\mu(E)=0$ then $\int_Ef\,d\mu=0$,
        \item $c\cdot f$ is integrable and $\int_X(cf)\,d\mu=c\int_Xf\,d\mu$,
        \item $f+g$ is integrable and satisfies $\int_X(f+g)\,d\mu=\int_Xf\,d\mu+\int_Xg\,d\mu$,
        \item if $f(x)\leq g(x)$ almost everywhere then $\int_Xf\,d\mu\leq\int_Xg\,d\mu$.
    \eenum

\ethrm

For $(1)$: $\abs h$ is then integrable and so therefore is $h$.
$(5)$ results in $f+g=(f+g)^+-(f+g)^-=f^+-f^-+g^+-g^-$ and $\abs{f+g}=(f+g)^++(f+g)^-=f^++f^-+g^++g^-$.
So $(f+g)^+=f^++g^+$ and $(f+g)^-=f^-+g^-$ are integrable.
The rest of the statements are proven utilizing properties of nonnegative measurable functions.
\qed

\bthrm[title=Dominated Convergence Theorem, name=domconv]

    Let $f_n\colon X\longto\overline{\bb R}$ be a sequence of measurable functions which converge pointwise to $f$.
    Now suppose there exists an integrable function $g$ such that $\abs{f_n(x)}\leq g(x)$ for every $x\in X$ and $n\in{\bb N}$.
    Then
    $$ \int_Xf\,d\mu = \lim_{n\to\infty}\int_Xf_n\,d\mu $$

\ethrm

\Proof since $\abs{f_n}\leq g$, $f_n$ is integrable by the previous theorem.
Furthermore $\abs f=\lim_n\abs{f_n}\leq g$, so $f$ is also integrable.
Now, we know $-g\leq f_n\leq g$ so $f_n+g\geq0$ and $g-f_n\geq0$.
By Fatou:
$$ \int_X(f+g) = \int_X\lim_n(f_n+g) \leq \liminf_n\int_X(f_n+g) = \liminf_n\int_Xf_n + \int_Xg $$
So $\int_Xf\leq\liminf_n\int_Xf_n$.
And by Fatou on $g-f_n$,
$$ \int_X(g-f) = \int_X\lim_n(g-f_n) \leq \liminf_n\int_X(g-f_n) = \int_Xg + \liminf_n-\int_Xf_n = \int_Xg - \limsup_n\int_Xf_n $$
So we have
$$ \limsup_n\int_Xf_n \leq \int_Xf \leq \liminf_n\int_Xf_n $$
so $\int_Xf=\lim_n\int_Xf_n$ as required.
\qed

\bthrm[title=Bounded Convergence Theorem, name=boundconv]

    Let $E\subseteq X$ be measurable such that $\mu(E)<\infty$, and let us define measurable functions $f_n\colon E\longto{\bb R}$ which converge to a function $f$ and there exists an $M>0$ such that
    $\abs{f_n(x)}\leq M$ for every $x\in E$.
    Then
    $$ \int_Ef\,d\mu = \lim_{n\to\infty}\int_Xf_n\,d\mu $$

\ethrm

\Proof define $g(x)=M\chi_E$ then $\abs{f_n\chi_E}\leq g$ and $g(x)$ is integrable, so the result follows from the dominated convergence theorem.
\qed

\bthrm[title=Equivalence of Riemann and Lebesgue Integrals, name=rlequiv]

    Let $f\colon[a,b]\longto{\bb R}$ be bound.
    Then $f$ is Riemann-integrable if and only if $f$ is continuous almost everywhere.
    In such a case, $f$ is Lebesgue integrable and the two integrals agree.

\ethrm

\Proof we will utilize Darboux's theorem: for every sequence of partitions $P_n\to0$ of $[a,b]$,
$$ \displaylines{
    \overline S(f,P_n)\longto\overline{\int}(f) = \inf_P(\overline S(P))\cr
    \underline S(f,P_n)\longto\underline{\int}(f) = \sup_P(\underline S(P))
} $$
Let $P_n$ be a partition of $[a,b]$ into $2^n$ intervals $I_{n,k}$ of equal length, then every upper/lower Riemann sum is just the integral of a simple function,
$$ \eqalign{
    \overline S(f,P_n) &= \int_{[a,b]}\phi_n\cr
    \underline S(f,P_n) &= \int_{[a,b]}\psi_n
} $$
where $\phi_n$ is the supremum of $f$ on each of the intervals $I_{n,k}$ and $\psi_n$ is the infimum (meaning $\phi_n(x_0)=\sup_{x\in I_{n,k}}f(x)$ for $x_0\in I_{n,k}$).
So $\psi_n\leq\phi_n$, $\phi_{n+1}\leq\phi_n$, and $\psi_n\leq\psi_{n+1}$.
So by the convergence theorems, their integrals converge to the integral of their limits.
Now, the limits are
$$ \displaylines{
    \lim_{n\to\infty}\phi_n(x_0) = \lim_{n\to\infty}\sup_{x\in I_{n,k}}f(x) = \maxof{f(x_0),\limsup_{x\to x_0}f(x)}\cr
    \lim_{n\to\infty}\psi_n(x_0) = \lim_{n\to\infty}\inf_{x\in I_{n,k}}f(x) = \minof{f(x_0),\limsup_{x\to x_0}f(x)}
} $$
we denote the limit of $\phi_n$ by $f^U$ and of $\psi_n$ by $f^L$.
Since all these functions are bound, by the bounded convergence theorem
$$ \eqalign{
    \overline{\int}_a^b f&=\lim_{n\to\infty}\phi_n=\int_a^bf^U\cr
    \underline{\int}_a^b f&=\lim_{n\to\infty}\psi_n=\int_a^bf^L
} $$
Thus we get that $f$ is Riemann integrable if and only if the upper and lower integrals are equal, which is if and only if $\int_a^bf^U-f^L=0$.
Since $f^U\geq f^L$, this means that $f$ is Riemann integrable if and only if $f^U=f^L$ almost everywhere.
This means that for almost every $x_0$, $\maxof{f(x_0),\limsup_{x\to x_0} f(x)}=\minof{f(x_0),\liminf_{x\to x_0} f(x)}$ which happens if and only if $\limsup f(x)=\liminf f(x)=f(x_0)$ since if $f(x_0)$ is
the maximum then $\liminf f(x)=f(x_0)$ and so $\limsup f(x)\geq f(x_0)$ so there is equality.
This is equivalent to saying that $f$ is continuous at $x_0$.
Thus we have that $f$ is Riemann integrable if and only if $f$ is continuous almost everywhere.

Now if $f$ is Riemann integrable on $[a,b]$ then $f(x)=f^U(x)=\lim_{n\to\infty}\phi_n(x)$ almost everywhere and denoting the Riemann integral by $R\int$, using the monotone convergence theorem
$$ \int f = \lim_{n\to\infty}\int\phi_n = \lim_{n\to\infty}R\int\phi_n = \lim_{n\to\infty}\overline S(f,P_n) = R\int f $$
since the Riemann and Lebesgue integrals of $\phi_n$ coincide as they are both integrals of simple functions of the form $\sum a_i\chi_{I_i}$ where $I_i$ is an interval; both integrals give
$\sum a_i\abs{I_i}$.
\qed

\subsection{Product Spaces and Fubini-Tonelli's Theorem}

\bdefn

    Suppose $(X,\Sigma_1,\mu),(Y,\Sigma_2,\nu)$ are two measure spaces.
    We define {\emphcolor product space} $(X\times Y,\Sigma,\mu\times\nu)$ as follows: for a {\it measurable rectangle} $A\times B\subseteq X\times Y$ where $A\in\Sigma_1$ and $B\in\Sigma_2$ define
    $$ \abs{A\times B} = \mu(A)\nu(B) $$
    Define the outer measure similar to in ${\bb R}$:
    $$ w^*(E) \coloneqq \infof{\sum_{n=1}^\infty\abs{R_n}}[\hbox{$R_n$ are measurable rectangles such that $E\subseteq\bigcup_{n=1}^\infty R_n$}] $$
    We say that a set $E\subseteq X\times Y$ is {\emphcolor $w$-measurable} if for every $A\subseteq X\times Y$, $w^*(A)=w^*(A\cap E)+w^*(A\cap E^c)$.
    The set of all $w$-measurable sets forms a $\sigma$-algebra $\Sigma$ (using a similar proof for ${\bb R}$) and so taking $w=\mu\times\nu$ to be the restriction of $w^*$ to $\Sigma$, we get the
    product space $(X,\Sigma,w)$.

\edefn

\bdefn

    A measure space $(X,\Sigma,\mu)$ is {\emphcolor $\sigma$-finite} if there exists a countable subset $\set{X_n}_{n=1}^\infty\subseteq\Sigma$ such that $\mu(X_n)<\infty$ and $X=\bigcup_{n=1}^\infty X_n$.
    And it is {\emphcolor complete} if for every $\mu(E)=0$ if $F\subseteq E$ then $F\in\Sigma$ as well.

\edefn

We will always assume that for product measures, both spaces are $\sigma$-finite (the product space itself is then $\sigma$-finite and complete as well).
The following are a few traits of product measures which are provable in a manner similar to ${\bb R}$:
\benum
    \item If $w^*(E)=0$ then $E$ is $w$-measurable.
    \item The countable union of measurable rectangles ($R_\sigma$ sets) and the countable intersection of $R_\sigma$ sets ($R_{\sigma\delta}$ sets) are all measurable.
    \item For every measurable set $E$ with finite measure, there exists $G\in R_{\sigma\delta}$ and $w(F)=0$ such that $E=G\setminus F$.
\eenum

\bthrm[title=Fubini's Theorem, name=fubini]

    Suppose $f\colon X\times Y\longto\overline{\bb R}$ is $w$-integrable.
    Then
    \benum
        \item the function $f_x\colon Y\longto\overline{\bb R}$ defined by $f_x(y)=f(x,y)$ is $\nu$-integrable for $\mu$-almost every $x$,
        \item the function $f_y(x)=f(x,y)$ is $\mu$-integrable for $\nu$-almost every $y$,
        \item the function $x\mapsto\int_Yf_x\,d\nu$ is $\mu$-integrable,
        \item the function $y\mapsto\int_Xf_y\,d\mu$ is $\nu$-integrable,
        \item
            $$ \int_Y\bracks{\int_Xf_y\,d\mu}\,d\nu = \int_{X\times Y}f\,dw = \int_X\bracks{\int_Yf_x\,d\nu}\,d\mu $$
    \eenum

\ethrm

\bthrm[title=Tonelli's Theorem, name=tonelli]

    Let $f\colon X\times Y\longto[0,\infty]$ be non-negative and $w$-measurable.
    Then
    \benum
        \item $f_x$ is $\nu$-measurable for $\mu$-almost every $x$,
        \item $f_y$ is $\mu$-measurable for $\nu$-almost every $y$,
        \item the function $x\mapsto\int_Yf_x\,d\nu$ is $\mu$-measurable,
        \item the function $y\mapsto\int_Xf_y\,d\mu$ is $\nu$-measurable,
        \item
            $$ \int_Y\bracks{\int_Xf_y\,d\mu}\,d\nu = \int_{X\times Y}f\,dw = \int_X\bracks{\int_Yf_x\,d\nu}\,d\mu $$
    \eenum

\ethrm

Combining these together, we get the following:

\bthrm[title=Fubini-Tonelli, name=fubinitonelli]

    Let $f\colon X\times Y\longto\overline{\bb R}$ be measurable, then
    $$ \int_Y\bracks{\int_X\abs{f_y}\,d\mu}\,d\nu = \int_{X\times Y}\abs f\,dw = \int_X\bracks{\int_Y\abs{f_x}\,d\nu}\,d\mu $$
    and if any of these are finite,
    $$ \int_Y\bracks{\int_Xf_y\,d\mu}\,d\nu = \int_{X\times Y}f\,dw = \int_X\bracks{\int_Yf_x\,d\nu}\,d\mu $$

\ethrm

\Proof the equality of the absolute values is due to Tonelli's theorem, since $\abs f$ is nonnegative and $\abs f_x=\abs{f_x}$.
If the terms are finite, then $f$ is integrable (since $f$ is integrable if and only if $\abs f$ is )and so the second set of equalities follows from Fubini's theorem.
\qed

\bdefn

    Let $f\colon X\longto\overline{\bb R}$ be a function, then its {\emphcolor support} is ${\rm supp}(f)\coloneqq\set{x\in X}[f(x)\neq0]$.
    Define $C_0({\bb R})$ to be the set of continuous real functions with compact support.

\edefn

\bthrm

    Let $f\colon{\bb R}\longto\overline{\bb R}$ be Lebesgue integrable.
    Then for every $\epsilon>0$ there exists a $g\in C_0({\bb R})$ such that $\int_{\bb R}\abs{f-g}\,dx<\epsilon$.

\ethrm

\Proof in steps.
\benum
    \item If $f=\chi_{(a,b)}$ then add to the edges of $f$ linear segments which go from $(a-\epsilon,0)$ to $(a,1)$ and $(b,1)$ to $(b+\epsilon,0)$ to form $g$.
        Then $g-f$ are just two triangles of height $1$ and width $\epsilon$ which has an integral of $\epsilon$.
    \item If $f=\chi_{\cal U}$ for $\cal U$ open then ${\cal U}=\bigdcup_{n=1}^\infty(a_n,b_n)$ a countable disjoint union of open intervals.
        Then $\chi_{\cal U}=\sum_{n=1}^\infty\chi(a_n,b_n)$, and using $(1)$ we can approximate each $\chi(a_n,b_n)$ by a continuous $g_n$ whose difference in integral is $\frac\epsilon{2^n}$.
        Then the total difference is bound by $\sum_{n=1}^\infty\frac\epsilon{2^n}=\epsilon$.
    \item If $f=\chi_E$ for $E$ measurable and bound, then there exists an open $E\subseteq\cal U$ such that $m({\cal U}\setminus E)<\frac\epsilon2$.
        So using $(2)$ approximate $\chi_E$ by $g$ for $\frac\epsilon2$.
        Then
        $$ \int\abs{g-f} \leq \int\abs{g-\chi_{\cal U}} + \int\abs{\chi_{\cal U}-\chi_E} < \frac\epsilon2 + \frac\epsilon2 = \epsilon $$
    \item If $f$ is a simple function with compact support, then $f$ is the finite linear combination of functions in $(3)$ (since compact implies bound), and it follows.
    \item If $f$ is integrable with compact support, then $f$ can be approximated by a simple function $\phi$ with the same support such that $\int\abs{f-\phi}<\frac\epsilon2$.
        We will approximate $\phi$ by $g$ up to $\frac\epsilon2$, so
        $$ \int\abs{f-g} \leq \int\abs{f-\phi} + \int\abs{\phi-g} < \frac\epsilon2 + \frac\epsilon2 = \epsilon $$
    \item If $f$ is a general integrable function, then define $f_n=f\cdot\chi_{[-n,n]}$.
        Then $\abs{f_n-f}\leq\abs{f_n}+\abs f$ which is integrable so by the dominated convergence theorem $\int\abs{f_n-f}\longto0$.
        So take an $n$ where $\int\abs{f_n-f}<\frac\epsilon2$ and approximate $f_n$ by $g$ up to $\frac\epsilon2$, so
        $$ \int\abs{f-g} \leq \int\abs{f-f_n} + \int\abs{f_n-g} < \epsilon \qed $$
\eenum

\bthrm

    Let $f\colon{\bb R}\longto\overline{\bb R}$ be Lebesgue integrable.
    Then
    $$ \lim_{n\to\infty}\int_{\bb R}f(x)\sin(nx) = 0 $$

\ethrm

\Proof first let us assume that $f$ is continuously differentiable and supported in the closed interval $[a,b]$.
We use integration by parts (since Lebesgue and Riemann integration are the same for continuous functions).
Notice that by assumption $f(a)=f(b)=0$ (or we can extend the bounds outside the support) so this just becomes
$$ \lim_{n\to\infty}\abs{\int_{\bb R}f(x)\sin(nx)} = \lim_{n\to\infty}\abs{\int_{\bb R}f'(x)\frac{\cos(nx)}n} $$
Now $\abs{f'}$ is bound by $\norm{f'}_\infty=\sup_{x\in[a,b]}\abs{f'}$ which exists since $f'$ is continuous, and so
$$ \leq \norm{f'}_\infty\cdot\lim_{n\to\infty}\int_a^b\frac1n = \norm{f'}_\infty(b-a)\cdot0 = 0 $$
We then approximate $f$ by continuously differentiable $g$ up to $\frac\epsilon2$.
Then we can take an $n$ such that we have $\abs{\int_{\bb R}g(x)\sin(nx)}<\frac\epsilon2$ so
$$ \abs{\int_{\bb R}f(x)\sin(nx)} \leq \abs{\int_{\bb R}g(x)\sin(nx)} + \abs{\int_{\bb R}(f-g)\sin(nx)} \leq \frac\epsilon2 + \abs{\int_{\bb R}f-g} < \epsilon $$
so the limit is zero, as required.
\qed

\vfill\break
\section{Functional Analysis}

\subsection{$L^p$-spaces}

\bdefn

    Let $(X,\mu)$ be a measure space, define the equivalence relation $\sim$ on functions $f\colon X\longto\overline{\bb R}$ by $f\sim g$ if $f=g$ almost everywhere.
    Then $L^1(X,\mu)$ is the quotient space of integrable functions $X\longto\overline{\bb R}$ with respect to this relation.

    Define for $p>0$
    $$ L^p(X,\mu) = \set{f\colon X\longto\overline{\bb R}}[\abs f^p\in L^1(X,\mu)]/{\sim} $$
    again the space is quotiented by $\sim$.

    Define the $L^p$-norm (we have not yet proven that it is a norm, and it isn't for all $p$):
    $$ \norm f_p \coloneqq \parens{\int_X\abs f^p}^{1/p} $$

\edefn

$L^p(X,\mu)$ is a vector space: since if $f,g\in L^p(X,\mu)$ then
$$ \int_X\abs{f+g}^p\,d\mu \leq \int_X\bigl(2\max{\abs f,\abs g}\bigr)^p \leq 2^p\int_X\bigl(\abs f^p+\abs g^p) < \infty $$
and obviously $\alpha f\in L^p(X,\mu)$.

Notice that the $L^1$-norm is indeed a norm: $\norm f_1=0$ if and only if $\int \abs f=0$ which is if and only if $f=0$ almost everywhere (so $f\sim0$).
Obviously $\norm{\alpha f}_1=\abs\alpha\norm f_1$, and
$$ \norm{f+g} = \int\abs{f+g} \leq \int\abs f + \int\abs g = \norm f + \norm g $$
So it satisfies the triangle inequality.

Notice that we showed before that $C_0({\bb R})$ is dense in $L^p({\bb R})$.
We know from calculus that $C[a,b]$ (the space of continuous functions on $[a,b]$) is complete relative to the norm $\norm f_\infty\coloneqq\max_{x\in[a,b]}\abs{f(x)}$.
Recall the definition of completeness:

\bdefn

    A normed space $(X,\norm\bullet)$ is {\emphcolor complete} if every Cauchy sequence relative to the norm $\norm\bullet$ converges relative to the norm $\norm\bullet$.

\edefn

We will show later that $L^p(X,\mu)$ are complete for $p\geq1$.

\bdefn

    Let $(X,\mu)$ be a measure space, and $f\colon X\longto\overline{\bb R}$ measurable, then define
    $$ \norm f_\infty \coloneqq \infof{M\in{\bb R}}[\abs{f(x)}\leq M\hbox{ almost everywhere}] $$
    and define the $L^\infty$ space:
    $$ L^\infty(X,\mu) = \set{f\colon X\longto\overline{\bb R}\hbox{ measurable}}[\norm f_\infty<\infty] $$

\edefn

\blemm

    For every $a,b\geq0$ and $0<\lambda<1$ we have $a^\lambda b^{1-\lambda}\leq\lambda a+(1-\lambda b)$ with equality if and only if $a=b$.

\elemm

\Proof this is equivalent to
$$ \parens{\frac ab}^\lambda \leq \lambda\frac ab + (1-\lambda) $$
Define $t=\frac ab$, so we must prove $\phi(t)=\lambda t-t^\lambda+(1-\lambda)\geq0$ for every $t\geq0$.
Differentiating gives $\phi'(t)=\lambda-\lambda t^{\lambda-1}=\lambda(1-t^{\lambda-1})$.
This is zero when $t=1$, $\phi'<0$ when $t<1$, and $\phi'>0$ when $t>1$.
So the minimum is obtained when $t=1$, ie. $a=b$.
But $\phi(1)=0$ so $\phi'\geq0$ with equality when $a=b$.
\qed

\bthrm[title=H\"older's Inequality, name=holder]

    Let $1\leq p\leq\infty$ such that $\frac1p+\frac1q=1$ and $f\in L^p(X,\mu),g\in L^q(X,\mu)$ then $fg\in L^1(X,\mu)$ and
    $$ \norm{fg}_1 \leq \norm f_p\norm g_q $$

\ethrm

\Proof define $\lambda=\frac1p$ so $1-\lambda=\frac1q$, $a=\abs{f(x)}^p$ and $b=\abs{g(x)}^q$.
So we have that
$$ \abs{fg} \leq \frac1p\abs{f(x)}^p + \frac1q\abs{g(x)}^q $$
for every $x\in X$.
First let us assume $\norm f_p=1=\norm g_q$, so we have that
$$ \norm{fg}_1 = \int\abs{f(x)g(x)} \leq \frac1p\int\abs f + \frac1q\int\abs g = \frac1p\norm f_p^p + \frac1q\norm f_q^q = \frac1p + \frac1q = 1 = \norm f_p\norm g_q $$
Now otherwise, define $f'=\frac f{\norm f_p}$ and $g'=\frac g{\norm g_q}$ so we have shown that
$$ 1 \geq \norm{f'g'}_1 = \frac1{\norm f_p\cdot\norm g_q}\norm{fg}_1 \implies \norm{fg}_1 \leq \norm f_p\norm g_q \qed $$

\bthrm[title=Minkoswki's Inequality, name=minkowski]

    Let $f,g\in L^p(X,\mu)$ then
    $$ \norm{f+g}_p \leq \norm f_p + \norm g_q $$

\ethrm

\Proof let $\frac1p+\frac1q=1$, meaning $q=\frac p{p-1}$ then
\multlines{
    \norm{f+g}_p^p = \int\abs{f+g}^p = \int\abs{f+g}^{p-1}\abs{f+g} \leq \int\abs{f+g}^{p-1}\abs f + \int\abs{f+g}^{p-1}\abs g\cr
    &= \norm{\abs{f+g}^{p-1}\abs f}_1 + \norm{\abs{f+g}^{p-1}\abs g}_1
}
Notice that $p+q=pq$ and so $\parens{\abs{f+g}^{p-1}}^q=\abs{f+g}^{pq-q}=\abs{f+g}^p$, meaning $\abs{f+g}^{p-1}\in L^q(X,\mu)$, so by H\"older:
$$ \leq \norm{\abs{f+g}^{p-1}}_q\norm f_p + \norm{\abs{f+g}^{p-1}}_q\norm g_p $$
Now
$$ \norm{\abs{f+g}^{p-1}}_q = \parens{\int_X\abs{f+g}^p}^{1/q} = \norm{f+g}_p^{p/q} $$
So we have shown that
$$ \norm{f+g}_p^{p-p/q} \leq \norm f_p + \norm g_p $$
but $p-p/q=1$ so we have $\norm{f+g}_p\leq\norm f_p+\norm g_p$ as required.
\qed

This means that for $p\geq1$, $\norm{\bullet}_p$ is indeed a norm on $L^p(X,\mu)$.
Minkowski's inequality proves the triangle inequality, if $\norm f_p=0$ implies $\int_X\abs f^p=0$ and since $\abs f^p\geq0$ this means $\abs f=0$ almost everywhere so it is zero in $L^p(X,\mu)$, and the
norm is trivially nonnegative.

Now we want to prove that $L^p(X,\mu)$ is complete.

\blemm

    Let $(X,\norm\bullet)$ be a normed vector space.
    Then $X$ is complete if and only if every series which converges absolutely also converges.
    Meaning if $\sum_{n=1}^\infty\norm{x_n}$ converges, so too does $\sum_{n=1}^\infty x_n$.

\elemm

\Proof suppose that absolute convergence implies convergence.
Let $\set{x_n}_{n=1}^\infty$ be a Cauchy sequence.
Define $n_k$ to be the index such that for every $n>n_k$, $\norm{x_{n_k}-x_n}<\frac1{2^k}$, and so let $n>n_k,n_{k+1}$:
$$ \norm{x_{n_k} - x_{n_{k+1}}} \leq \norm{x_{n_k} - x_n} + \norm{x_n - x_{n_{k+1}}} < \frac1{2^k} + \frac1{2^{k+1}} = \frac3{2^{k+1}} $$
and so $\sum\norm{x_{n_k}-x_{n_{k+1}}}$ converges, meaning $\sum(x_{n_k}-x_{n_{k+1}})$ converges to a value.
Notice that
$$ x_{n_k} = x_{n_1} + \sum_{k=1}^\infty\bigl(x_{n_k} - x_{n_{k+1}}\bigr) $$
and so $x_{n_k}$ converges to some $x_0\in X$, ie. $x_{n_k}\xvarrightarrow{k\to\infty}x_0$.
So $\set{x_n}_{n=1}^\infty$ is a Cauchy sequence with a convergent subsequence, which we knows means that $x_n$ itself is convergent.

For the converse, all we must do is show that $\sum x_n$ is Cauchy.
Notice that for $N>M$,
$$ \norm{\sum_{n=1}^N x_n - \sum_{n=M}^M x_n} = \norm{\sum_{n=M+1}^Nx_n} \leq \sum_{n=M+1}^N\norm{x_n} \leq \sum_{n=M+1}^\infty\norm{x_n} $$
and since $\sum\norm{x_n}$ is convergent, its tail converges to zero.
Thus for any $\epsilon>0$ we can find a $n_0$ such that for every $N>M>n_0$ the above expression is less than $\epsilon$ and we have the desired.
\qed

\bthrm

    The normed vector spaces $L^p(X,\mu)$ are complete for $p\geq1$.

\ethrm

\Proof let $\sum_{n=1}^\infty f_n$ be a series that converges absolutely where $f_n\in L^p$.
Let us define
$$ g(x) = \sum_{n=1}^\infty\abs{f_n(x)} $$
which exists for every $x\in X$ (in a general sense, it can be $\infty$).
Let us define the partial sums
$$ g_N(x) = \sum_{n=1}^N\abs{f_n(x)} $$
So we have that
$$ \norm{g_N}_p \leq \sum_{n=1}^N\norm{f_n}_p \leq \sum_{n=1}^\infty\norm{f_n}_p = M < \infty $$
since $\sum f_n$ converges absolutely.
And $g_N$ monotonically increase to $g$, and so $\abs{g_N}^p$ does to $\abs g^p$ as well, meaning by the monotone convergence theorem
$$ \int_X\abs g^p = \lim_{N\to\infty}\int_X\abs{g_N}^p = \lim_{N\to\infty}\norm{g_N}_p^p \leq M^p $$
This means that $g\in L^p(X,\mu)$, and in particular $g(x)<\infty$ almost everywhere.
Thus $\sum_{n=1}^\infty f_n(x)$ converges absolutely almost everywhere (as a series of real numbers), and thus converges almost everywhere to $f(x)=\sum_{n=1}^\infty f_n(x)$.
Since $\abs{f(x)}\leq g(x)$ we have that $f\in L^p(X,\mu)$.

Now we need to show that in $L^p(X,\mu)$, $\sum_{n=1}^N f_n\longto f$.
Let us define $S_N=\sum_{n=1}^N f_n$, then also $\abs{S_N}\leq g$ so $\abs{f-S_N}\leq\abs f+\abs{S_N}\leq\abs f+g$ which is integrable.
So by the dominated convergence theorem since $f-S_N\longto0$,
$$ \lim_{N\to\infty}\norm{f-S_N}^p = \lim_{N\to\infty}\int_X\abs{f-S_N}^p = \int_X\lim_{N\to\infty}\abs{f-S_N}^p = \int_X0 = 0 \qed $$

\bthrm

    Let $\set{f_n}_{n=1}^\infty$ be a convergent sequence of functions in $L^p(X,\mu)$.
    Then there exists a subsequence $\set{f_{n_k}}_{k=1}^\infty$ which converges pointwise almost everywhere.

\ethrm

\Proof let $n_k$ be an index such that for every $n>n_k$, $\norm{f_n-f_{n_k}}_p<2^{-k}$ and so as before $\sum\norm{f_{n_{k+1}}-f_{n_k}}$ is convergent.
Now we showed in the above proof that we can define $f(x)=f_{n_1}+\sum_{k=1}^\infty\bigl(f_{n_{k+1}}-f_{n_k}\bigr)$ and this converges pointwise almost everywhere.
Noticing once again that $f_{n_k}=f_{n_1}+\sum_{i=1}^{k-1}\bigl(f_{n_{i+1}}-f_{n_i}\bigr)$, this means $f_{n_k}$ converges pointwise almost everywhere to $f$ as required.
\qed

\bdefn

    Let $(X,\norm\bullet_X)$ and $(Y,\norm\bullet_Y)$ be two normed vector spaces.
    Further let $T\colon X\longto Y$ be a linear transform.
    Define the {\emphcolor operator norm} to be
    $$ \norm T_{\rm op}\coloneqq\sup_{0\neq x\in X}\frac{\norm{Tx}_Y}{\norm x_X} $$

\edefn

Notice that if $\norm x_X=\alpha$ then
$$ \norm{T\frac x\alpha}_Y = \frac{\norm{Tx}_Y}{\norm x_X} $$
and thus
$$ \norm T_{\rm op} = \sup_{\norm x_X=1}\norm{Tx}_Y $$

\bthrm

    Let $(X,\norm\bullet_X)$ and $(Y,\norm\bullet_Y)$ be two normed vector spaces, and $T\colon X\longto Y$ a linear transform.
    Then the following are equivalent:
    \benum
        \item $T$ is bound: $\norm T_{\rm op}<\infty$,
        \item $T$ is uniformly continuous on $X$,
        \item $T$ is continuous at a single point $x_0\in X$,
        \item $T$ is continuous at $0\in X$.
    \eenum

\ethrm

\Proof $(1)\implies(2)$: we know that $\norm T\geq\frac{\norm{Tx_1-Tx_2}_Y}{\norm{x_1-x_2}_X}$ so $\norm{Tx_1-Tx_2}_Y\leq\norm T_{\rm op}\norm{x_1-x_2}_X=M\norm{x_1-x_2}_X$ where $M=\norm T_{\rm op}$.
Thus for every $\epsilon>0$ take $x_1,x_2\in X$ such that $\norm{x_1-x_2}<\frac\epsilon M$ and then $\norm{Tx_1-Tx_2}_Y\leq\epsilon$, so $T$ is uniformly continuous.
$(2)\implies(3)$: trivial.
$(3)\implies(4)$: let $x_n\to0$ then $x_n+x_0\to x_0$ and so $T(x_n+x_0)\to Tx_n+Tx_0\to Tx_0$ thus $Tx_n\to0$.
Meaning $T$ is continuous at $0$.
$(4)\implies(1)$: since $T$ is continuous at $0$, so there exists a $\delta>0$ such that $\norm x<\delta$ implies $\norm{Tx}<1$.
So for $z\in X$ define $x\coloneqq\frac{\delta z}{2\norm z}$ so that $\norm x<\delta$ and thus $\norm{Tx}=\frac\delta{2\norm z}\norm{Tz}<1$, meaning $\frac{\norm{Tz}}{\norm z}<\frac2\delta$.
Thus $\norm T_{\rm op}\leq\frac2\delta$ as required.
\qed

For example, let $f\in L^p(X,\mu)$ and $\frac1p+\frac1q=1$, define
$$ T_f\colon L^q(X,\mu)\longto{\bb R},\qquad T_fg = \int_X fg\,d\mu $$
This is obviously a linear transform.
By H\"older,
$$ \abs{T_fg} \leq \norm f_p\norm g_q $$
which means that $\norm{T_f}\leq\norm f_p$.
Now let us take $g={\rm sign}f\cdot\abs f^{p-1}$ and notice that $\abs g^q=\abs f^{q(p-1)}=\abs f^p$ so $g\in L^q(X,\mu)$ and
$$ T_fg = \int_X\abs f^p = \norm f_p^p $$
and since $\norm g_q^q=\norm f_p^p$, we have that $\norm g_q\norm f_p=\norm f_p^{p/q}\norm f_p=\norm f_p^{p/q+1}=\norm f_p^p$
$$ T_fg = \norm f_p^p = \norm g_q\norm f_p $$
And thus our previous inequality is strict,
$$ \norm{T_f}_{\rm op} = \norm f_p $$

\subsection{Hilbert Spaces}

\bdefn

    A {\emphcolor Hilbert space} is a complete inner product space (complete relative to the induced norm $\norm f=\sqrt{\iprod{f,f}}$.

\edefn

Recall the Cauchy-Schwarz inequality (whose proof can be found in my summary of Linear Algebra 2): $\abs{\iprod{f,g}}\leq\norm f\norm g$ in an inner product space.

\bprop[title=The Parallelogram Identity]

    In an inner product space, $\norm{f+g}^2+\norm{f-g}^2 = 2\norm f^2+2\norm g^2$.

\eprop

\Proof trivial.\qed

Notice that $L^2(X,\mu)$ is a Hilbert space, whose inner product is given by $\iprod{f,g}=\int_X f\overline g\,d\mu$ (this integral exists by H\"older's inequality, since $p=q=2$).
It is easy enough to verify that this is an inner product, and it induces the $L^2(X,\mu)$-norm which is complete.

\bthrm

    Let ${\cal H}$ be a Hilbert space and $M\subseteq{\cal H}$ a closed subspace.
    If $x\in{\cal H}\setminus M$ then there exists a unique $y\in M$ such that $\norm{x-y}=d(x,M)=\inf_{z\in M}\norm{x-z}$.
    Furthermore, $x-y$ is orthogonal to $M$.

\ethrm

\Proof since $M$ is closed, $d(x,M)>0$ since $M$ contains all its limit points as a closed space.
So let $y_n$ be a sequence of points in $M$ such that $\lim_{n\to\infty}\norm{x-y_n}=d(x,M)$.
We will show that $\set{y_n}$ is Cauchy and since $M$ is a closed subspace of a complete space, it is also complete and so $y_n$ has a limit point $y\in M$.
Notice that
$$ \norm{y_n-y_m} = \norm{(x-y_m) - (x-y_n)} \leq \norm{x-y_m} + \norm{x-y_n} $$
for large enough $n,m$ the right-hand side is less than eny $\epsilon>0$ and so $\set{y_n}$ is indeed Cauchy.

Now, norms are continuous and so
$$ \norm{x-y} = \norm{\lim_{n\to\infty}x-y_n} = \lim_{n\to\infty}\norm{x-y_n} = d(x,M) $$
as required.
And if $\norm{x-w}=d(x,M)$ for some other $w\in M$ then we can show using the parallelogram identity,
$$ \norm{w-y}^2 = 2\norm{x-y}^2 + 2\norm{x-w}^2 - 4\norm{x-\frac{y+w}2}^2 $$
Let $d=d(x,M)$ and since $\frac12(y+w)\in M$ we have that this is bound by $\leq2d^2+2d^2-4d^2=0$.
So $w=y$, meaning $y$ is unique.

Now we must also show that $x-y$ is orthogonal to $M$, so let $z\in M$ be normalized.
Then since $\norm{x-y}$ is minimal
$$ \norm{x-y}^2 \leq \norm{x-(y+\alpha z)}^2 = \norm{x-y}^2 + \norm{\alpha z}^2 + 2\Re\norm{x-y,\alpha z} $$
So we have that $0=\norm{\alpha z}^2 + 2\Re\norm{x-y,\alpha z}$ for all $\alpha$, and thus since $\norm z=1$,
$$ 0=\abs\alpha^2 + 2\Re\bigl(\overline{\abs{\iprod{x-y,z}}}\bigr) $$
So let $\alpha=-\norm{x-y,z}$ and we get that
$$ 0 = \abs\alpha^2 - 2\abs\alpha^2 \implies \alpha = 0 $$
so $x-y$ is orthogonal to $z$, as required.
\qed

\bprop[title=Bessel's Inequality, name=besselineq]

    Let $\set{e_j}_{j=1}^N$ be a finite orthonormal set within a Hilbert space ${\cal H}$.
    Then for every $f\in{\cal H}$,
    $$ \norm f^2 \geq \sum_{j=1}^n\abs{\iprod{f,e_j}}^2 $$

\eprop

\Proof this is simply since
\multlines{
    0 \leq \norm{f-\sum_{j=1}^N\iprod{f,e_j}e_j}^2 = \norm f^2 - 2\sum_{j=1}^N\Re\iprod{f,\iprod{f,e_j}e_j} + \sum_{j=1}^N\abs{\iprod{f,e_j}}^2
    = \norm f^2 - 2\sum_{j=1}^n\abs{\iprod{f,e_j}}^2 + \sum_{j=1}^N\abs{\iprod{f,e_j}}^2\cr
    &= \norm f^2 - \sum_{j=1}^N\abs{\iprod{f,e_j}}^2
}
as required.
\qed

\bthrm[title=Parseval's Identity, name=parsevalid]

    Let ${\cal H}$ be a Hilbert space and $\set{e_j}_{j=1}^\infty$ an orthonormal set which spans a dense space in ${\cal H}$.
    Then
    $$ \norm f^2 = \sum_{j=1}^\infty\abs{\iprod{f,e_j}}^2 $$

\ethrm

\Proof by Bessel we have that $\norm f^2\geq\sum_{j=1}^N\abs{\iprod{f,e_j}}$ for every partial sum, and so by taking the limit we get $\norm f^2\geq\sum_{j=1}^\infty\abs{\iprod{f,e_j}}$.
Conversely since $\set{e_j}$ spans a dense space, let $g$ be in the span such that $\norm{f-g}<\epsilon$ and suppose $g=\sum_{j=1}^N\iprod{g,e_j}e_j$ (since spans are finite linear combinations).
Now recall that $\abs{z+w}\geq\abs{\abs z-\abs w}$ and so $\abs{z+w}^2\geq\abs z^2+\abs w^2-2\abs z\abs w$, so
$$
    \sum_{j=1}^\infty\abs{\iprod{f,e_j}}^2 \geq \sum_{j=1}^N\abs{\iprod{f,e_j}}^2 = \sum_{j=1}^N\abs{\iprod{g,e_j} + \iprod{f-g,e_j}}^2 =
    \sum_{j=1}^N\Bigl(\abs{\iprod{g,e_j}}^2 - 2\iprod{g,e_j}\iprod{f-g,e_j} + \abs{\iprod{f-g,e_j}}^2\Bigr)
$$
We know that $\sum_j\abs{\iprod{g,e_j}}^2=\norm g^2$ and so we get
$$ \geq \norm g^2 - 2\parens{\sum_{j=1}^N\abs{\iprod{g,e_j}}^2}^{1/2}\cdot\parens{\sum_{j=1}^N\abs{\iprod{f-g,e_j}}^2}^{1/2} $$
and so on (revisit this, I can't hear the audio).
\qed

\bthrm[title=Riesz Representation Theorem, name=riesz]

    Let ${\cal H}$ be a Hilbert space.
    For every $y\in{\cal H}$ define the linear transform $T_y\colon{\cal H}\longto{\bb C}$ by $T_yx=\iprod{x,y}$.
    Then every bound (equivalently continuous) linear functional $T\colon{\cal H}\longto{\bb C}$ is of the form $T_y$ for some $y\in{\cal H}$.

\ethrm

\Proof firstly it is obvious that $T_y$ is bound since
$$ \norm{T_y}_{\rm op} = \sup_{x\in{\cal H}}\frac{\abs{T_y(x)}}{\norm x} = \sup\frac{\abs{\iprod{x,y}}}{\norm x} \leq \norm y $$
And since $T_y(y)=\iprod{y,y}$ we have that $\norm{T_y}_{\rm op}=\norm y$.

The kernel of $T$ is a closed subspace of ${\cal H}$ since $T$ is continuous (so it contains all its limit points).
Let $x\in{\cal H}\setminus\ker T$, and so there exists a $u\in\ker T$ which is closest to $x$ within the kernel and furthermore $x-u$ is orthogonal to $\ker T$.
Define $z=\frac{x-u}{\norm{x-u}}$.
Notice that for every $v\in{\cal H}$, $T(v)z-T(z)v$ is in the kernel of $T$, and so
$$ 0 = \iprod{T(v)z-T(z)v,z} = T(v)\iprod{z,z} - T(z)\iprod{v,z} = T(v) - \iprod{v,\overline{T(z)}z} $$
so define $y=\overline{T(z)}z$ and we have that $T=T_y$.
\qed

Recall that if $(X,\Sigma,\mu)$ is a measure space and $f$ is non-negative then $\nu(A)=\int_Af\,d\mu$ is a measure on $(X,\Sigma)$.
It trivially satisfies the property that if $\mu(A)=0$ then $\nu(A)=0$.

\bdefn

    Let $\mu$ and $\nu$ be measures over the measurable space $(X,\Sigma)$ such that for all $A\in\Sigma$, if $\mu(A)=0$ then $\nu(A)=0$.
    Then $\nu$ is said to be {\emphcolor uniformly continuous} relative to $\mu$, and this is denoted $\nu\ll\mu$.

\edefn

So every measure of the form $\nu(A)=\int_Af\,d\mu$ is uniformly continuous relative to $\mu$, but it turns out the converse is true as well:

\bthrm[title=Radon-Nikodym, name=radonnikodym]

    Let $\nu\ll\mu$ be measures over $(X,\Sigma)$, such that the space is $\sigma$-finite relative to both measures.
    Then there exists an integrable $f\in L^1(X,\mu)$ such that $\nu(A)=\int_Af\,d\mu$ for every $A\in\Sigma$.
    Moreso $\int_Xg\,d\nu=\int_Xgf\,d\mu$.

\ethrm

\Proof for the sake of the proof, we will assume that $(X,\Sigma)$ is finite.
Define $\pi=\mu+\nu$ to be a new measure, and define
$$ Tg = \int_Xg\,d\nu $$
to be a linear functional over $L^2(X,\pi)$ and this is well-defined and bound since
$$ \abs{Tg} \leq \int_X\abs g\,d\nu = \int_X\abs{g\cdot1}\,d\nu \leq \norm{g}_{L^2(X,\nu)}\nu(X)^{1/2} \leq\norm g_{L^2(X,\pi)}\nu(X)^{1/2} $$
Thus by the Riesz representation theorem
$$ T(g)=\iprod{g,h}_{L^2(\pi)} = \int_Xgh\,d\pi $$
for some $h$.
So we have that
$$ \int_X\,d\nu = \int_Xgh\,d\pi = \int_Xgh\,d\nu + \int_Xgh\,d\mu $$
so
$$ \int_X g(1-h)\,d\nu = \int_Xgh\,d\mu $$
So if we define $f=\frac h{1-h}$ we get that
$$ \int_X g\,d\nu = \int_X \frac g{1-h}(1-h)\,d\nu = \int_X\frac g{1-h}h\,d\mu = \int_X fg\,d\mu $$
as required.
And this is sufficient since we just plug in $g=\chi_A$ and we obtain $\nu(A)=\int_Xf\,d\mu$.
\qed

\subsection{The Fundamental Theorem of Calculus}

\bdefn

    Let $(M_1,\rho_1)$ and $(M_2,\rho_2)$ be two metric spaces, then a function $f\colon M_1\longto M_2$ is {\emphcolor Lipschitz continuous} if there exists an $M>0$ such that for every $x,y\in M_1$,
    $\rho_2(f(x),f(y))\leq M\rho_1(x,y)$.

\edefn

\bnote

    We can construct the {\emphcolor Cantor function} ${\cal C}\colon[0,1]\longto[0,1]$ such that:
    \benum
        \item ${\cal C}$ is continuous,
        \item differentiable almost everywhere with derivative $0$,
        \item ${\cal C}(0)=0$ and ${\cal C}(1)=1$.
    \eenum
    So we have that
    $$ \int_0^1{\cal C}'(x)\,dx = 0 \neq 1 = {\cal C}(1) - {\cal C}(0) $$
    so the Cantor function does not satisfy the fundamental theorem of calculus.

\enote

\bdefn

    Let $(M_i,\rho_i)$ be metric spaces for $i=1,2$.
    Then a function $f\colon M_1\longto M_2$ is {\emphcolor uniformly continuous} if for every $\epsilon>0$ there exists a $\delta>0$ such that if $\rho_1(x,y)<\delta$ then $\rho_2(f(x),f(y))<\epsilon$.

\edefn

\bdefn

    A function $f\colon[a,b]\longto{\bb R}$ is {\emphcolor absolutely continuous} if for every $\epsilon>0$ there is a $\delta>0$ such that for every finite set of intervals $\set{(a_i,b_i)}_{i=1}^n$, if
    $\sum_{i=1}^n\abs{b_i-a_i}<\delta$ then $\sum_{i=1}^n\abs{f(b_i)-f(a_i)}<\epsilon$.

\edefn

Notice that if $f\colon[a,b]\longto{\bb R}$ is Lipschitz continuous then set $\delta=\frac\epsilon M$ so that if $\sum_{i=1}^n\abs{b_i-a_i}<\frac\epsilon M$ then
$$ \sum_{i=1}^n\abs{f(b_i)-f(a_i)} \leq \sum_{i=1}^n M\abs{b_i-a_i} = \epsilon $$
so $f$ is absolutely continuous.

Some results we will not be proving:
\benum
    \item {\bf Lebesgue's differentiation theorem}: every monotonically increasing function $f\colon[a,b]\longto{\bb R}$ is differentiable almost everywhere and $\int_a^b f'\leq f(b)-f(a)$.
    \item If $f\in L^1[a,b]$ then $F(x)=\int_a^xf\,dm$ is absolutely continuous and $F'(x)=f(x)$ almost everywhere.
    \item If $f\colon[a,b]\longto{\bb R}$ is absolutely continuous then $\int_a^bf\,dm=f(b)-f(a)$.
\eenum

\bdefn

    Let $P\colon a=x_0<x_1<\cdots<x_n=b$ be a partition of $[a,b]$.
    Then define $f$'s variation with respect to $P$ to be ${\rm var}_P(f)=\sum_{i=1}^n\abs{f(x_{i-1})-f(x_i)}$.
    Then define $f$'s {\emphcolor total variation} to be
    $$ T^b_a(f) = \supof{{\rm var}_P(f)}[\hbox{$P$ is a partition of $[a,b]$}] $$
    $f$ is said to have {\emphcolor bounded variation} if $T^b_a(f)<\infty$.

\edefn

\bthrm

    $f\colon[a,b]\longto{\bb R}$ has bounded variation if and only if it is the difference of two increasing functions.

\ethrm

\Proof define $G(x)=T^x_a(f)$.
This is obviously increasing, for $x>y$:
$$ G(x) - G(y) = T^x_a(f) - T^y_a(f) \geq T^y_x(f) \geq \abs{f(x) - f(y)} \geq 0 $$
and we see here that $G(x)-f(x)\geq G(y)-f(y)$ so defining $H(x)=G(x)-f(x)$ then we have that $H(x)\geq H(y)$ for $x>y$ so $G$ and $H$ are both increasing and $G(x)-H(x)=f(x)$.
\qed

\bthrm[title=Lebesgue's Differentiation Theorem, name=lebesguediff]

    If $f$ is monotonically increasing in $[a,b]$ then $f'$ exists almost everywhere in $[a,b]$ and $\int_a^b f'\leq f(b)-f(a)$.
    Specifically if $f$ has bounded variation then $f'$ exists almost everywhere and is $L^1$.

\ethrm

\bthrm

    If $f\colon[a,b]\longto{\bb R}$ is absolutely continuous, then it has bounded variation.

\ethrm

\Proof let $\delta>0$ be the appropriate value for $\epsilon=1$ for absolute continuity.
Meaning if $\sum_{i=1}^n\abs{b_i-a_i}<\delta$ then $\sum_{i=1}^n\abs{f(b_i)-f(a_i)}<1$.
In particular for every interval $(x,y)$ such that $y-x<\delta$ we have that $T^y_x(f)\leq1$ (since every partition is a finite set of intervals where the sum of the lengths is less than $\delta$).
So if we divide $(a,b)$ into subintervals each of length $\delta$, $I_1,\dots,I_m$, we have that
$$ T^b_a(f) \leq T_{I_1}(f) + \cdots + T_{I_m}(f) \leq m < \infty $$
so $f$ has bounded variation.

\bthrm

    Let $f\in L^1[a,b]$ then for every $\epsilon>0$ there exists a $\delta0$ such that for every set satisfying $m(E)<\delta$, $\int_E\abs f\,dm<\epsilon$.

\ethrm

\Proof define
$$ f_n(x) = \cases{f(x) & $f(x)\leq n$\cr n & $f(x)>n$} $$
$f_n(x)$ is obviously monotonically increasing to $f(x)$, and so $\int_a^bf_n\longto\int_a^bf$.
So for a large enough $N$, for every $n>N$, $\int_a^b(f-f_n)<\epsilon/2$.
And so we define $\delta=\frac\epsilon{2n}$ we get that if $mE<\delta$ then
$$ \int_Ef_n \leq \int_En = mE\cdot n = \frac\epsilon2 $$
Then
$$ \int_E f = \int_E(f-f_n) + \int_Ef_n \leq \frac\epsilon2 + \frac\epsilon2 = \epsilon $$
as required.
\qed

\bye

