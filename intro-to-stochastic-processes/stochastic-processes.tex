\input pdfToolbox

\setlayout{horizontal margin=1.5cm, vertical margin=1.5cm}
\parindent=0cm
\parskip=3pt plus 2pt minus 2pt

\input pdfmsym
\input preamble

\pdfmsymsetscalefactor{10}

\footline={}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pageborder{rgb{1 .5 .5}}{rgb{1 0 0}}{5}

\color rgb{1 0 0}

{\def\boxshadowcolor{rgb{.8 0 0}}
\bppbox{rgb{1 .7 .7}}{rgb{1 0 0}}{rgb{.8 0 0}}

    \centerline{\setfontandscale{bf}{20pt}Introduction to Stochastic Processes}
    \smallskip
    \centerline{\setfont{it}Dr. Naomi Feldheim, \setfont{tt}naomi.feldheim@biu.ac.il}
    \centerline{\setfont{it}Summary by Ari Feiglin}

\eppbox

\bigskip

\bppbox{rgb{1 .7 .7}}{rgb{1 0 0}}{rgb{.8 0 0}}
\section*{Contents}

\tableofcontents
\eppbox

}

\vfill\break

\color{black}

\pageborder{rgb{1 .5 .5}}{rgb{1 0 0}}{5}
\null
\vfill\break

\pageno=1
\newif\ifpageodd
\pageoddtrue
\headline={%
    \hbox to \hsize{\color{black}%
        \ifpageodd\hfil{\it\currsubsection\quad\bf\folio}\global\pageoddfalse%
        \else{\bf\folio\quad\it\currsubsection}\hfil\global\pageoddtrue\fi%
    }%
}

\section{Introduction}

This course will focus on tools which can be used to study random processes.
A random process is a sequence of random variables which represent measurements of the process.
Examples of random processes are random walks (these are commonly described as the path a drunk man would take while trying to get home), card shuffles (which can be viewed as choosing a card and placing
it randomly in the deck), and branching (for example the population of bunnies in a specific area: the random variable being the number of bunnies in each generation).

\subsection{Markov Chains}

\bdefn

    A {\emphcolor discrete-time Markov process}\addtoindex{markov process}[discrete-time] is a sequence of random variables $\set{X_n}_{n\geq0}$.
    This sequence is called a {\emphcolor Markov chain}\addtoindex{markov chain} on a set of states $S$ if:
    \benum
        \item For every $n$, $X_n\in S$ almost surely (meaning $\probof{X_n\in S}=1$),
        \item For every $n\geq0$ and for every $s_0,\dots,s_{n+1}\in S$,
        $$\probof{X_{n+1}=s_{n+1}}[X_0=s_0,\dots,X_n=s_n]=\probof{X_{n+1}=s_{n+1}}[X_n=s_n]$$
        ie. the probability of the next measurement being some arbitrary value is dependent only on the previous measurement.
        This is only necessary if $\probof{X_0=s_0,\dots,X_n=s_n}>0$.
    \eenum

\edefn

In this course $S$ will always be countable.
We can also write the second condition using distributive equivalence:
$$ X_{n+1}\vert X_0,\dots,X_n \deq X_{n+1}\vert X_n $$

Notice how the Markov property can be strengthened in various ways, for example if $n>m$ then

\medskip
{\tabskip=0pt
\openup1\jot\halign to\hsize{$\displaystyle#$\hfil\tabskip=0pt plus 1fil&$\displaystyle#$\hfil\tabskip=0pt\cr
    \omit\span\omit$\displaystyle\probof{X_n=s_n}[X_{n-1}=s_{n-1},\dots,X_m=s_m]$\cr
    &= \sum_{s_m,\dots,s_0}\probof{X_n=s_n}[X_{n-1}=s_{n-1},\dots,X_0=s_0]\cdot\probof{X_{m-1}=s_{m-1},\dots,X_0=s_0}[X_{n-1}=s_{n-1},\dots,X_m=s_m]\cr
    &= \probof{X_n=s_n}[X_{n-1}=s_{n-1}]\cdot\sum\probof{X_{m-1}=s_{m-1},\dots,X_0=s_0}[X_{n-1}=s_{n-1},\dots,X_m=s_m]\cr
    &= \probof{X_n=s_n}[X_{n-1}=s_{n-1}]\cr
}}
\medskip

This can be viewed as the base case for
$$ \probof{X_{n+k}=s_{n+k}}[X_n=s_n,\dots,X_m=s_m] = \probof{X_{n+k}=s_{n+k}}[X_n=s_n,\dots,X_{m'}=s_{m'}] $$
where $m'<m$.
This is since for $k=1$, both of these are equal to $\probof{X_{n+1}=s_{n+1}}[X_n=s_n]$.
The induction step follows by

\medskip
{\tabskip=0pt
\openup1\jot\halign to\hsize{$\displaystyle#$\hfil\tabskip=0pt plus 1fil&$\displaystyle#$\hfil\tabskip=0pt\cr
    \omit\span\omit$\displaystyle\probof{X_{n+k+1}=s_{n+k+1}}[X_n=s_n,\dots,X_m=s_m]$\cr
    &= \sum_{s_{n+1}}\probof{X_{n+k+1}=s_{n+k+1}}[X_{n+1}=s_{n+1},\dots,X_m=s_m]\cdot\probof{X_{n+1}=s_{n+1}}[X_n=s_n,\dots,X_m=s_m]\cr
    &= \sum_{s_{n+1}}\probof{X_{n+k+1}=s_{n+k+1}}[X_{n+1}=s_{n+1},\dots,X_{m'}=s_{m'}]\cdot\probof{X_{n+1}=s_{n+1}}[X_n=s_n,\dots,X_{m'}=s_{m'}]\cr
    &= \probof{X_{n+k+1}=s_{n+k+1}}[X_n=s_n,\dots,X_{m'}=s_{m'}]\cr
}}
\medskip

By taking $m'=0$ and $m=n$ we get $\probof{X_{n+k}=s_{n+k}}[X_n=s_n] = \probof{X_{n+k}=s_{n+k}}[X_n=s_n,\dots,X_0=s_0]$, or in other words for all $m<n$,
$$ \probof{X_n=s_n}[X_m=s_m,\dots,X_0=s_0] = \probof{X_n=s_n}[X_m=s_m] $$

This can be even further strengthened: let $\varnothing\neq B\subseteq\set{0,\dots,n-1}$ and $m=\max B$ then
$$ \probof{X_n=s_n}[\forall i\in B\colon X_i=s_i] = \probof{X_n=s_n}[X_m=s_m] $$
To prove this let $C=\set{0,\dots,m}\setminus B$ then
$$ \eqalign{
    \probof{X_n=s_n}[\forall i\in B\colon X_i=s_i] &= \sum_{(s_i)_{i\in C}\in S^C}\probof{X_n=s_n}[X_m=s_m,\dots,X_0=s_0]\cdot\probof{\forall i\in C\colon X_i=s_i}[\forall i\in B\colon X_i=s_i]\cr
    &= \probof{X_n=s_n}[X_m=s_m]\cdot\sum\probof{\forall i\in C\colon X_i=s_i}[\forall i\in B\colon X_i=s_i]\cr
    &= \probof{X_n=s_n}[X_m=s_m]\cr
} $$

A consequence of this is that if $\set{X_n}_{n\geq0}$ is a Markov chain and $\set{a_n}_{n\geq0}$ is strictly monotonic then $Y_n=X_{a_n}$ is also a Markov chain.
After all if we let $B=\set{a_{n-1},\dots,a_0}$ then $\max B=a_{n-1}$ and so
\multlines{
    \probof{Y_n=s_{a_n}}[Y_{n-1}=s_{a_{n-1}},\dots,Y_0=s_{a_0}] = \probof{X_{a_n}=s_{a_n}}[\forall i\in B\colon X_i=s_i] = \probof{X_{a_n}=s_{a_n}}[X_{a_{n-1}}=s_{a_{n-1}}]\cr
    &= \probof{Y_n=s_{a_n}}[Y_{n-1}=s_{a_{n-1}}]
}
as required.

\bdefn

    For a Markov chain $\set{X_n}_{n\geq0}$ on a finite set of states $S$, we define the {\emphcolor adjacency matrix} at the $n$th measurement by
    $$ P^{(n)}_{ij} = \probof{X_n=j}[X_{n-1}=i] $$
    for $i,j\in S$.
    This is also sometimes written as $P_n(i\to j)$ (the probability measuring $i$ on the $n-1$th measurement gives $j$ on the next).
    If $P^{(n)}$ is the same for all $n$, then we say that the chain is {\emphcolor homogeneus in time}, and we generally write $P$ in place of $P^{(n)}$.

\edefn

For example, suppose a frog is hopping between $N$ leaves.
The frog can hopping from every leaf to every other leaf, and it always chooses a leaf in an independent and uniform manner.
This defines a Markov chain where the states are the leaves, and $X_n$ is the leaf the frog is on after $n$ hops.
This Markov chain is even homogeneus since the frog makes its choices in a manner which does not take the current number of hops into account.
The adjacency matrix is defined by
$$ P_{ij} = \cases{\frac1{N-1} & $i\neq j$\cr 0 & $i=j$} $$
This is the simple random process on the complete graph of $N$ vertices, $K_N$.

Suppose $N=4$, and supppose that at the beginning the frog is on either the first or second leaf with equal probability.
What is the probability that after one hop the frog is on the fourth leaf?
The following notation will be used: $X\sim(a_0,\dots,a_n)$ will be used to mean $\probof{X=s_i}=a_i$, where $s_i$ is some understood ordering of the set of states $S$.
Then
$$ \probof{X_1=j}[X_0\sim\parens{\frac12,\frac12,0,0}] = \probof{X_1=j}[X_0=1]\cdot\frac12 + \probof{X_1=j}[X_0=2]\cdot\frac12 $$
as the rest of the terms are zero.
For $j=4$ we get that this is equal to $\frac13$.
Notice that we can generalize this and get
$$ \probof{X_{n+1}=j}[X_n\sim\vec v] = \sum_{i\in S}\probof{X_{n+1}=j}[X_n=i]\cdot\probof{X_n=i} = \sum_{i\in S}P^{(n+1)}_{ij}\vec v_i = (\vec v\cdot P^{(n+1)})_j $$
So we have proven the following:

\bprop

    If $X_n\sim\vec v$ then $X_{n+1}\vert X_n\sim\vec v\cdot P^{(n+1)}$, and so $X_n\vert X_0\sim\vec v\cdot P^{(n)}\cdots P^{(1)}$.
    In particular if the Markov chain is homogeneus, $X_n\vert X_0\sim\vec v\cdot P^n$.

\eprop

This simplifies dealing with Markov chains, especially homogeneus ones.

\bexam

    Suppose $\set{Y_n}_{n=1}^\infty$ is a sequence of random variables which have the distribution $Y_n\sim\Berof{\frac1n}$ (recall that $X\sim\Berof p$ means that $X$ is $1$ with probability $p$ and zero
    otherwise).
    And we define $X_n=\chi\set{(\exists m\leq n)\,Y_m=1}$, the indicator of the set of all values such that there is an index before $n$ where $Y_m=1$ ($\chi_S$ is the {\it indicator function} of the set
    $S$, defined by $\chi_S(x)=1$ for $x\in S$ and zero otherwise).
    We will prove $X_n$ is a Markov chain.
    Notice that
    $$ X_n = \chi\set{(\exists m\leq n)\,Y_m=1} = \chi\set{(\exists m\leq n-1)\,Y_m=1}\lor\chi\set{Y_n=1} = X_{n-1}\lor\chi\set{Y_n=1} $$
    $\lor$ is bitwise or, or equivalently the maximum.
    And therefore we get that $X_n=\bigvee_{i=1}^n\chi\set{Y_i=1}$.
    This means that if $X_{n-1}=1$ then $X_n=1$, and if $X_{n-1}=0$ then $X_n=1$ if and only if $Y_n=1$.
    And so $X_n$'s value depends only on $X_{n-1}$'s and not any previous $X_i$.
    So $\set{X_n}_{n=1}^\infty$ is indeed a Markov chain.

    Notice that
    $$ \displaylines{
        \probof{X_n=0}[X_{n-1}=0] = \probof{Y_n=0} = \frac{n-1}n,\quad \probof{X_n=1}[X_{n-1}=0] = \probof{Y_n=1} = \frac1n,\quad\cr
        \probof{X_n=0}[X_{n-1}=1] = 0,\quad \probof{X_n=1}[X_{n-1}=1] = 1
    } $$
    And so we get that
    $$ P^{(n)} = \pmat{\frac{n-1}n & \frac1n \cr 0 & 1} $$

\eexam

\bdefn

    A real $n\times n$ matrix $P$ such that $P_{ij}\geq0$ for every $i,j$, and for every row $i$ we have $\sum_{j=1}^n P_{ij}=1$ then $P$ is called an {\emphcolor stochastic matrix}.

\edefn

Notice that we can draw a diagram for every stochastic matrix and it will be the transition matrix of a Markov chain.
Meaning every stochastic matrix is the transition matrix of some Markov chain, and every transition matrix is stochastic.
Notice that the second condition for a matrix to be stochastic can be written as $P{\bf1}={\bf1}$ where ${\bf1}=(1,\dots,1)^\top$.

\bdefn

    Let $\set{X_n}_{n\geq0}$ be a Markov chain over a state space $S$, and let $A\subseteq S$.
    Then we define the {\emphcolor hitting time} to $A$ to be the random variable
    $$ T_A = \minof{t\geq1}[X_t\in A] $$
    Note that if $X_t$ is never in $A$ then $T_A$ can be $\infty$, and so $T_A$ is a function from the probability space to the extended reals: $\Omega\longto{\bb R}\cup\set\infty$.
    This means that $T_A^{-1}\set\infty$ must also be measurable (an event).

\edefn

In the case that $A$ is a singleton $A=\set a$ then we write $T_a$ in place of $T_A$.
Notice that $T_A$ measures starting from $t=1$, while it is possible that the initial condition is in $A$, ie. $X_0\in A$.
So in the case that $X_0\in A$, $T_A$ measures the {\it return time} to $A$, in particular if $X_0\sim\delta_a$ where $\delta_a=(0,\dots,1,\dots,0)$ ($1$ is at the index corresponding to the state $a$).
We also use the following notation
$$ \probof[V]E = \probof E[X_0\sim V],\qquad \probof[\delta_a]E = \probof[a]E = \probof{E}[X_0=a] $$

If $P$ is the transition matrix of a homogeneus Markov chain, then $P^n(a\to b)$ means $P^n_{ba}=\probof{X_n=b}[X_0=a]$.

\blemm

    If $\set{X_n}$ is a homogeneus Markov chain, then
    $$ P^n(a\to b)=\sum_{m=1}^n\probof[a]{T_b=m}P^{n-m}(b\to b) $$

\elemm

\multlines{%
    P^n(a\to b) = \probof[a]{X_n=b} = \probof{\bigdcup_{m=1}^n\set{T_b=m},X_n=b}[X_0=b] = \sum_{m=1}\probof{T_b=m,X_n=b}[X_0=b]\cr
    &= \sum_{m=1}^n\probof{X_n=b}[T_b=m,X_0=a]\cdot\probof{T_b=m}[X_0=a]\cr
}
Now, $\probof{X_n=b}[T_b=m,X_0=a]=\probof{X_n=b}[X_m=b,X_{m-1}\neq b,\dots,X_1\neq b,X_0=a]=\probof{X_n=b}[X_m=b]$ by the Markov property.
Since $\set{X_n}$ is homogeneus this is just equal to $P^{n-m}(b\to b)$.
Thus this formula is equal to
$$ \sum_{m=1}^b\probof{X_n=b}[X_m=b]\cdot\probof[a]{T_b=m} = \sum_{m=1}^b P^{n-m}(b\to b)\cdot\probof[a]{T_b=m} \qed $$

Let us introduce some more notation:
$$ f_{a\to b} = \probof{T_b<\infty}[X_0=a],\qquad f_{a\to a}=f_a=\probof{T_a<\infty}[X_0=a] $$
thus $f_{a\to b}$ is the probability that if we start at $a$, we eventually reach $b$.

\blemm

    $f_{a\to c}\geq f_{a\to b}\cdot f_{b\to c}$

\elemm

Notice that $\set{T_c<\infty}=\set{(\exists t>0)X_t=c}\supseteq\bigdcup_{k>0}\set{T_b=k,(\exists t>k)X_t=c}$.
Thus we get
\lmultlines{
    f_{a\to c} = \probof{T_c<\infty}[X_0=a] \geq \sum_{k=1}^\infty\probof{T_b=k,(\exists t>k)X_t=c}[X_0=a]\cr
    &= \sum_{k=1}^\infty\probof{T_b=k}[X_0=a]\cdot\probof{(\exists t>k)X_t=c}[T_b=k,X_0=a]\cr
    &= \sum_{k=1}^\infty\probof{T_b=k}[X_0=a]\cdot\probof{(\exists t>k)X_t=c}[X_k=b,X_{k-1}\neq b,\dots,X_1\neq b,X_0=a]\cr
    &\llap{(Markov property) }= \sum_{k=1}^\infty\probof{T_b=k}[X_0=a]\cdot\probof{(\exists t>k)X_t=c}[X_k=b]\cr
    &\llap{(homogeneity) }= \sum_{k=1}^\infty\probof{T_b=k}[X_0=a]\cdot\probof{(\exists t>0)X_t=c}[X_0=b]\cr
    &= \sum_{k=1}^\infty\probof{T_b=k}[X_0=a]\cdot f_{b\to c} = f_{a\to b}\cdot f_{b\to c}\hfill\mathchar"404\cr
}

In particular this means
$$ f_a\geq f_{a\to b}\cdot f_{b\to a} $$

For every $a\in S$ we define the random variable $N(a)=\sum_{n=1}^\infty\chi\set{X_n=a}$, which is the number of times the state $a$ is visited from time $1$ and onward.
When $X_0\sim V$ we write $N_V(a)$.
Notice then that $f_{a\to b}=\probof{N(b)\geq1}[X_0=a]$ and so $f_a=\probof{N(a)\geq1}[X_0=a]$.

\bprop

    $\probof{N(a)\geq k}[X_0=a]=f_a^k$

\eprop

We prove this by induction, for $k=1$ this is simply what we just said.
Now
\lmultlines{
    \probof{N(a)\geq k+1}[X_0=a] = \sum_{m=1}^\infty\probof{T_a=m,\abs{\set{j>m}[X_j=a]}\geq k}[X_0=a]\cr
    &\llap{(Markov property) }= \sum_{m=1}^\infty\probof{T_a=m}[X_0=a]\cdot\probof{\abs{\set{j>m}[X_j=a]}\geq k}[X_m=a]\cr
    &\llap{(homogeneity) }=\sum_{m=1}^\infty\probof{T_a=m}[X_0=a]\cdot\probof[a]{N(a)\geq k}\cr
    &\llap{(induction) }=f_a^k\sum_{m=1}^\infty\probof{T_a=m}[X_0=a] = f_a^{k+1}\hfill\mathchar"404\cr
}

Notice then that
$$ \probof{N(a)=k}[X_0=a] = \probof[a]{N(a)\geq k} - \probof[a]{N(a)\geq k+1} = f_a^k - f_a^{k+1} = f_a^k(1-f_a) $$
Thus $N_a(a)\sim\Geoof{1-f_a}-1$ (the $+1$ is since $X\sim\Geoof p$ means $\probof{X=k}=p(1-p)^{k-1}$).
Thus
$$ \expecof{N_a(a)} = \frac1{1-f_a} - 1 = \frac{f_a}{1-f_a} $$

\bdefn

    A state $b\in S$ is {\emphcolor recurrent} if $f_b=1$, equivalently if $\probof[b]{T_b<\infty}$ (the probability of returning to $b$ is $1$).
    A non-recurrent state is called {\emphcolor transient}.
    $b$ is {\emphcolor absorbing} if $P(b\to b)=1$.

\edefn

Notice that if $b$ is recurrent then if $f_b=1$, $N_b(b)\sim\Geoof{0}-1$, meaning $\probof[b]{N(b)=\infty}=1$.
And if $b$ is transient then $N_b(b)$ is a finite geometric variable and so $\probof[b]{N(b)<\infty}=1$.
And so
$$ \eqalign{
    \hbox{$b$ is recurrent} &\iff \probof{N(b)=\infty}[X_0=b] = 1,\cr
    \hbox{$b$ is transient} &\iff \probof{N(b)<\infty}[X_0=b] = 1 \iff \probof{N(b)<\infty}[X_0\sim v] = 1
} $$

\bdefn

    Let $a,b\in S$ be states.
    Then $b$ is {\emphcolor reachable} from $a$ if $f_{a\to b}\neq0$ or $a=b$, this is denoted $a\to b$.
    $a$ and $b$ are {\emphcolor connected} if both $a\to b$ and $b\to a$, this is denoted $a\oto b$.

\edefn

This means that $a\to b$ if and only if there exists some $n\geq0$ such that $P^n(a\to b)>0$.
Furthermore, connectivity is an equivalence relation: it is obviously reflexive and symmetric and if $a\to b$ and $b\to c$, since $f_{a\to c}\geq f_{a\to b}\cdot f_{b\to c}>0$, we get that reachability
and therefore connectivity is transitive.
Thus $S$ can be partitioned into {\it connectivity classes}.

\blemm

    If $a\to b$ and $a\neq b$ then $\probof{T_b<T_a}[X_0=a]>0$.

\elemm

Since $a\to b$, there exists a sequence of states $a=s_0,\dots,s_m=b$ such that $P_{s_is_{i+1}}>0$ for all $i$.
We can assume that for every $i>0$, $a\neq s_i$.
So we have a sequence whose probability is positive and where the hitting time of $b$ is before that of $a$, so the probability that $T_b<T_a$ must be positive.
\qed

\bdefn

    $A\subseteq S$ is {\emphcolor closed} if for every $a\in A$ and every $b\notin A$, $b$ is not reachable from $a$.
    $A$ is also called {\emphcolor irreducible} if it is closed and connected.

\edefn

\bthrm

    If $a$ is recurrent and $a\to b$, then also $b\to a$ and $b$ is recurrent.

\ethrm

We know
$$ f_{a\to b} = \probof[a]{T_a>T_b} + \probof[a]{T_a<T_b}\cdot\probof{T_b<\infty}[T_a<T_b] $$
by the above lemma $p=\probof[a]{T_b<T_a}>0$ and so by homogeneity
$$ = p + (1-p)\cdot\probof{T_b<\infty}[X_0=a] = p + (1-p)f_{a\to b} $$
Thus we get that $p\cdot f_{a\to b}=p$ and since $p\neq0$, $f_{a\to b}=1$.
Now
$$ f_{a\to b}(1-f_{b\to a}) = \probof{\hbox{$X_n$ hits $b$ and never returns to $a$}}[X_0=a] \leq \probof[a]{N(a)<\infty} = 0 $$
Thus $f_{b\to a}=1$.
Now $f_b\geq f_{b\to a}\cdot f_{a\to b}=1$ so $b$ is also recurrent.
\qed

So if $a\oto b$, then $a$ is recurrent if and only if $b$ is.
If $b$ is reachable from $a$ but $a$ is not reachable from $b$, then $a$ is transient.
And if $a$ is recurrent and $a\to b$ then $\probof[b]{N(a)=\infty}=1$.

\bthrm

    A finite closed set of states $A\subseteq S$ contains a recurrent state.

\ethrm

Suppose $A$ has only transient states.
This means that $\probof[v]{N(a)<\infty}=1$ for every $a\in A$, and so we get that $\probof[v]{(\forall a\in A)N(a)<\infty}=1$ (as the intersection of a countable number of events with probability one).
And this means $\probof[v]{\sum_{a\in A}N(a)<\infty}=1$ since $A$ is finite.
But since $A$ is closed, we can never leave $A$ and so if $v$'s support is in $A$ then $\sum_{a\in A}N_v(a)=\infty$.
\qed

In particular, since $S$ is closed, if $S$ is finite it contains a recurrent state.

\bthrm

    If $S$ is a finite state space, then it can be uniquely partitioned into
    $$ S = T\dcup C_1\dcup\cdots\dcup C_k $$
    where $T$ is the set of all transient states, and $C_i$ are all disjoint irreducible (closed and connected) sets.

\ethrm

So $T$ is the set of all transient states, and for every recurrent state $a\in S\setminus T$ let $C_a=\set{b}[a\to b]$.
By a previous theorem, for every $b\in C_a$, $b\to a$ so and if $b\to b'$ then $a\to b'$ meaning $b'\in C_a$, so $C_a$ is closed.
And if $b,b'\in C_a$ then $a\to b$ and $a\to b'\implies b'\to a$ and therefore $b'\to b$, so $C_a$ is connected and therefore irreducible.
By taking representatives of each $C_a$, let $C_i=C_{a_i}$, we get the partition.

This partition is unique: since if $C_1\dcup\cdots\dcup C_k=C'_1\dcup\cdots\dcup C'_m$ let $a\in C_1$ then $a\in C'_i$ for some $i$, without loss of generality assume $a\in C'_1$.
Then for every $b\in C_1$, since $C_1$ is connected $a\to b$ and so $b\in C'_1$ since $C'_1$ is closed, thus $C_1=C'_1$.
Continuing inductively we get $k=m$ and $C_i=C'_i$ as required.
\qed

\bye

