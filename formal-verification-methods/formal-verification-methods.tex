\input pdfToolbox

\setlayout{horizontal margin=2cm, vertical margin=2cm}
\parindent=0pt
\parskip=3pt plus 2pt minus 2pt

\input preamble

\footline={}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\headline={\pageborder{rgb{1 .7 .1}}{rgb{.6 .4 0}}{5}}

\color rgb{.8 .5 .1}

{\def\boxshadowcolor{rgb{.8 .6 0}}
\bppbox{rgb{1 .8 .1}}{rgb{.6 .4 0}}{rgb{.4 .2 0}}

    \centerline{\setfontandscale{bf}{20pt}Formal Verification Methods}
    \smallskip
    \centerline{\setfont{it}Lectures by Doron Peled}
    \centerline{\setfont{it}Summary by Ari Feiglin \setfont{rm}({\tt ari.feiglin@gmail.com})}

\eppbox

\bigskip

\bppbox{rgb{1 .8 .1}}{rgb{.6 .4 0}}{rgb{.4 .2 0}}
    \section*{Contents}
    
    \tableofcontents
\eppbox

}

\vfill\break

\color{black}

\pageno=1
\newif\ifpageodd
\pageoddtrue
\headline={%
    \hbox to \hsize{\color{black}%
        \ifpageodd\hfil{\it\currsubsection\quad\bf\folio}\global\pageoddfalse%
        \else{\bf\folio\quad\it\currsubsection}\hfil\global\pageoddtrue\fi%
    }%
}

\section{Transition Systems}

When modelling systems, one must take into consideration a variety of factors: for example, is the system sequential or concurrent? When investigating the transitions between states, how granular should they
be?
These questions are common questions in computer science, the terms may not be though.
A sequential system is a system with only one thread of execution, while a concurrent system may be multithreaded/multiprogrammed/multiprocessed.
The granularity of a transition refers to how detailed we view the transition: is the command $\tt x\coloneqq y$ atomic? Or do the variables first need to be loaded into memory?

We now begin to discuss how we model systems.

\bdefn

    A {\emphcolor transition system} over a first-order language ${\cal L}$ is a triplet $({\cal S},T,\Theta)$, where
    \benum
        \item ${\cal S}$ is a (potentially many-sorted) ${\cal L}$-structure.
            The symbols of ${\cal L}$ correspond to the symbols utilized within the program in question.
            For example, ${\cal L}$ may contain the $+$ operator, $<$ relation, etc.
            As opposed to general first-order logic, the set of variables $V$ is taken to be finite here.
            This set of variables correspond to precisely what you'd expect: the set of all variables in the program.
            This includes internal registers utilized by the program, called the {\it program counters}, for which there is one for each concurrent process, and they point to the location of the next
            instruction to be executed.
        \item $T$ is a {\it finite} set of {\emphcolor transitions}.
            Each transition $t\in T$ has the form (${\cal T}_{\cal L}$ is the set of ${\cal L}$-terms)
            $$ p\longto (v_1,\dots,v_n)\coloneqq(e_1,\dots,e_n) \qquad (v_1,\dots,v_n\in V,e_1,\dots,e_n\in{\cal T}_{\cal L}) $$
            $p$ is a quantifier-free formula in ${\cal L}$.
            Notice that even in concurrent systems, there is a single set of transitions, meaning all the transitions are grouped together.
        \item $\Theta$ is the {\it initial condition}, a quantifier-free formula in ${\cal L}$.
    \eenum

    In this model, a {\emphcolor state} is an assignment of the variables in $V$ to elements of the domain of ${\cal S}$.
    In other words, a state is a valuation $s\colon V\longto S$ ($S={\sl dom}{\cal S}$), so ${\cal S}$ together with a state form an ${\cal L}$-model.
    The {\emphcolor state space} is the set of all possible states, which can be taken to be $S^V$ or a subset of this (if for example, ${\cal S}$ contains all the naturals, but our computer's memory is
    bound in size).
\edefn

A transition of the form $p\longto(v_1,\dots,v_n)\coloneqq(e_1,\dots,e_n)$ intuitively can execute from any state which satisfies the condition $p$.
The condition $p$ is called the {\it enabledness condition} of the transition $t$, and if $p$ is satisfied by the state $s$, ie. ${\cal S},s\vDash p$ (recall that ${\cal S},s$ is simply an ${\cal L}$-model),
then $t$ is said to be {\it enabled} at $s$.
$t$ transitions from a state $s$ in which it is enabled to a state where the value of each $v_i$ is set to $e_i^{\cal S}$ for $1\leq i\leq n$, denoted $s'=t(s)=s[e_1/v_1,\dots,e_n/v_n]$.

Note that the assignment is simultaneous: $(x,y)\coloneqq(y,x)$ has the effect of swapping the values of $x$ and $y$.
Allowing for simultaneous assignments may seem contrary to the idea of having transitions be atomic.
But this again goes back to the notion of granularity: we decide what transitions are atomic, and it can be useful to view assignments, even simultaneous ones, as atomic.

\bdefn

    Given a system $({\cal S},T,\Theta)$, an {\emphcolor execution} is an infinite sequence of states $s_0,s_1,s_2,\dots$ such that ${\cal S},s_0\vDash\Theta$ (we will also use the notation
    $s_0\vDash^{\cal S}\Theta$), meaning the first state satisfies the initial condition, and for every $i\geq0$ one of the following holds:
    \benum
        \item There exists some transition $p\longto(v_1,\dots,v_n)\coloneqq(e_1,\dots,e_n)\in T$ that is enabled at $s_i$, ie. $s_i\vDash^{\cal S}p$, and $s_{i+1}$ is obtained by this assignment, meaning
        $s_{i+1}=s_i[e_1^{\cal S}/v_1,\dots,e_n^{\cal S}/v_n]$.
        \item There is no transition enabled at $s_i$, meaning for every transition $t\in T$ whose enabledness condition is $p$, $s_i\nvDash^{\cal S}p$.
            In this case, for every $j\geq i$ we set $s_j=s_i$.
            So in such a case, we manually extend the sequence if it can no longer be extended.
    \eenum

\edefn

Instead of the second condition, we could add a new transition to $T$ of the form $\neg(p_1\lor\cdots\lor p_n)\to(v\coloneqq v)$ where $p_1,\dots,p_n$ exhaust all the enabledness conditions of
transitions in $T$, and $v\in V$ is arbitrary.
Alternatively we could allow for finite sequences of states, provided the final state enables no transition.

A state which appears in some execution of a program (system) is called {\it reachable}.
Not every state needs to be reachable: consider a program that can hold (bounded) natural numbers with variables $y_1,y_2$ and the program is written in such a way that $y_1\geq y_2$ always.
But the state $s[y_1]=1$ and $s[y_2]=2$ is a valid, yet unreachable, state.

We can view the execution of a system as a {\it scheduler} which can generate interleaved sequences (sequences where a single transition is executed at a time)

\medskip
\algorithm
    \Function{Scheduler}{${\cal S},T,\Theta$}
        \State\textbf{choose} some initial state $s$ such that $s\vDash^{\cal S}\Theta$
        \While{$s$ has an enabled transition}
            \State\textbf{choose} a transition $t$ enabled by $s$
            \State $s\gets t(s)$
        \EndWhile
        \Comment Extend the sequence infinitely if the final state has no enabled transition\EndComment
        \State \textbf{repeat} $s$ forever
    \EndFunc
\ealgorithm
\medskip

This scheduler is non-deterministic as the choice for the initial state and the choices between transitions enabled at each state along the execution are made non-deterministically.

\bexam

    Let us give an example of {\it mutual exclusion}: we have two programs sharing a shared {\it critical section} (here the variable {\tt turn}):
    
    \medskip
    \hbox to \hsize{
        \hfil\vbox{\hsize=.4\hsize
        \algorithm
            \InnerText{\textbf{routine} {\tencsc Program1}}
                \While{{\sf true}}
                    \Comment wait until ${\tt turn}$ is zero\EndComment
                    \State {\sf wait}(${\tt turn}=0$)
                    \State ${\tt turn}\gets1$
                \nonum\EndWhile
            \InnerText{\textbf{end routine}}
        \ealgorithm
        }
        \hfil\vbox{\hsize=.4\hsize
        \algorithm
            \InnerText{\textbf{routine} {\tencsc Program2}}
                \While{{\sf true}}
                    \Comment wait until ${\tt turn}$ is one\EndComment
                    \State {\sf wait}(${\tt turn}=1$)
                    \State ${\tt turn}\gets0$
                \nonum\EndWhile
            \InnerText{\textbf{end routine}}
        \ealgorithm
        }
        \hfil
    }
    \medskip
    
    \def\turn{{\tt turn}}
    \def\pc{{\tt pc}}
    In this example, we have three variables: $\turn$, the first program counter $\pc_1$, and the second program counter $\pc_2$.
    The transitions are as follows:
    $$ \displaylines{
        t_0\colon \pc_1=1\longto\pc_1\coloneqq2,\ t_1\colon(\pc_1=2\land\turn=0)\longto \pc_1\coloneqq3,\ t_2\colon(\pc_1=3)\longto(\pc_1,\turn)\coloneqq(1,1)\cr
        t_3\colon \pc_2=1\longto\pc_2\coloneqq2,\ t_4\colon(\pc_2=2\land\turn=1)\longto \pc_2\coloneqq3,\ t_5\colon(\pc_2=3)\longto(\pc_2,\turn)\coloneqq(1,0)
    } $$
    Then the initial condition is
    $$ \Theta = \pc_1=1\land\pc_2=1 $$
    
    Viewing states as $(\turn,\pc_1,\pc_2)$, then we can draw the following diagram for the transition system, initial states are bold:
    
    \centerline{\drawdiagram{%
                 &$\bf(0,1,1)$&&$\bf(1,1,1)$\cr
        $(0,1,2)$&$(0,2,1)$&&$(1,1,2)$&$(1,2,1)$\cr
        $(0,2,2)$&$(0,3,1)$&&$(1,1,3)$&$(1,2,2)$\cr
                 &$(0,3,2)$&&$(1,2,3)$\cr
    }{%
        \diagarrow{from={1,2}, to={2,1}, color=rgb{.1 .65 .1}, text=$t_3$, x distance=-.4cm, slide=.4}%t3
        \diagarrow{from={1,2}, to={2,2}, color=rgb{.1 .65 .1}, text=$t_0$, x distance=-.25cm}%t0
        \diagarrow{from={2,1}, to={3,1}, color=rgb{.1 .65 .1}, text=$t_0$, x distance=-.25cm}%t0
        \diagarrow{from={2,2}, to={3,1}, color=rgb{.1 .65 .1}, text=$t_3$, x distance=-.4cm, slide=.4}%t3
        \diagarrow{from={2,2}, to={3,2}, color=rgb{.1 .65 .1}, text=$t_1$, x distance=-.25cm}%t1
        \diagarrow{from={3,1}, to={4,2}, color=rgb{.1 .65 .1}, text=$t_1$, x distance=-.4cm, slide=.6}%t1
        \diagarrow{from={3,2}, to={4,2}, color=rgb{.1 .65 .1}, text=$t_3$, x distance=-.25cm}%t3
        %                              , color=rgb{.1 .65 .1}}
        \diagarrow{from={1,4}, to={2,4}, color=rgb{.1 .65 .1}, text=$t_3$, x distance=.25cm}%t3
        \diagarrow{from={1,4}, to={2,5}, color=rgb{.1 .65 .1}, text=$t_0$, x distance=.4cm, slide=.4}%t0
        \diagarrow{from={2,5}, to={3,5}, color=rgb{.1 .65 .1}, text=$t_3$, x distance=.25cm}%t3
        \diagarrow{from={2,4}, to={3,5}, color=rgb{.1 .65 .1}, text=$t_0$, x distance=.4cm, slide=.4}%t0
        \diagarrow{from={2,4}, to={3,4}, color=rgb{.1 .65 .1}, text=$t_4$, x distance=.25cm}%t4
        \diagarrow{from={3,5}, to={4,4}, color=rgb{.1 .65 .1}, text=$t_4$, x distance=.5cm, slide=.6}%t4
        \diagarrow{from={3,4}, to={4,4}, color=rgb{.1 .65 .1}, text=$t_0$, x distance=.25cm}%t0
        %                              , color=rgb{.1 .65 .1}}
        \diagarrow{from={3,2}, to={1,4}, color=rgb{.1 .65 .1}, text=$t_2$, x distance=.4cm, slide=.6}%t2
        \diagarrow{from={3,4}, to={1,2}, color=rgb{.1 .65 .1}, text=$t_5$, x distance=-.4cm, slide=.6}%t2
        \diagarrow{from={4,2}, to={2,4}, color=rgb{.1 .65 .1}, text=$t_2$, x distance=-.4cm, slide=.4}%t2
        \diagarrow{from={4,4}, to={2,2}, color=rgb{.1 .65 .1}, text=$t_5$, x distance=.4cm, slide=.4}%t5
    }}
    
    Now notice that we do indeed have mutual exclusion, where formally this means always $\neg(\pc_1=3\land\pc_2=3)$.
    Furthermore we have that if $\turn=0$ then eventually $\turn=1$, to prove this we must go through every possible execution which starts with $\turn=0$ and to show that eventually $\turn=1$.

    Say instead of implementing {\sf wait} via a lock (eg. mutex), we utilize busy waiting, adding the following two transitions:
    $$ t_1'\colon(\pc_1=2\land\turn=1)\longto\pc_1\coloneqq2,\qquad t_4'\colon(\pc_2=2\land\turn=0)\longto\pc_2\coloneqq2 $$
    then we no longer have that if $\turn=0$ then eventually $\turn=1$.
    For example $(0,1,1)\to(0,1,2)$ and then $(0,1,2)$ is extended forever via $t_4'$.

\eexam

In the above example, the focus was more on the states and the possible transitions between them rather than the explicit content of each transition.
We can generalize this idea to the concept of {\it state spaces}:

\bdefn

    A {\emphcolor state space} is a triplet $(S,\Delta,I)$, where $S$ is a set of states, $\Delta\subseteq S\times S$ is the transition relations, and $I\subseteq S$ are the initial transitions.
    This defines a graph, called an {\emphcolor automaton}.
    A {\emphcolor run} of the automaton is a sequence $s_0s_1s_2\dots$ such that $s_0\in I$ is an initial state and for every $i\geq0$, $(s_i,s_{i+1})\in\Delta$.
    Such a run must be maximal, meaning it is either infinite or it reaches a state with no successor.

    Sometimes we give names to the transitions in $\Delta$ in which case our state space becomes $(S,\Delta,\Sigma,I)$ where $\Delta$ now is a subset of $S\times\Sigma\times S$.
    Every transition gets its own name, so if $(s,\alpha,s'),(r,\alpha,r')\in\Delta$ then $s=r$ and $s'=r'$.

\edefn

In particular, a transition system defines a state space where $S$ is the set of all states, which are valuations $V\longto{\cal S}$.
Then $(s,s')\in\Delta$ if and only if there is a transition $t$ enabled at $s$ such that $s'=t(s)$.
And $I$ is the set of states which satisfy the initial condition, $I=\set{s\in S}[s\vDash\Theta]$.

Suppose we have $n$ concurrent processes, each with a variable $v_i$ and the transitions
$$ t^i_1\colon v_i=1\longto v_i\coloneqq2,\quad t^i_2\colon v_i=2\longto v_i\coloneqq3,\quad t^i_3\colon v_i=3\longto v_i\coloneqq1 $$
in other words, if $v_i$ is $1$, then it is $2$, then it is $3$, then it is $1$.
Since this is a concurrent system, we must combine these states together, and then we get that the number of global states becomes $3^n$ (each state is $(v_1,\dots,v_n)$ and each $v_i$ can take on three
values).
This is called {\it combinatorial explosion}: a relatively simple transition system becomes exponentially larger with the growth of concurrent processes.

Let us examine this above example more closely: notice how we took multiple transition systems and combined them into one.
We will define this notion formally: suppose we have a transition system whose transitions $T$ is constructed from {\it local} components $T_1,\dots,T_n$.
Here, each $T_i$ refers to a local component of the system, be it a concurrent process, a variable, or whatever.
For each $T_i$ we also have a set of {\it transition names} $\Sigma_i$ and a {\it labelling function} which is a bijection $L_i\colon T_i\longto\Sigma_i$.
Importantly while the $T_i$s are disjoint, $\Sigma_i$ need not be.

If two transitions have the same name, then we execute them together.
Formally, from each global state $s$, we can execute all the transitions with the name $d$ (meaning $L_i(t)=d$) provided {\it all of them} are enabled at $s$.
So suppose we have the transitions $t_i\colon p_i\longto(v_1^i,\dots,v_{n_i}^i)\coloneqq(e_1^i,\dots,e_{n_i}^i)$ for $1\leq i\leq k$ such that $L_i(t_i)=d$ for all $1\leq i\leq k$.
Then the resulting transition is
$$ \bigl(p_1\land\cdots\land p_k\bigr)\longto(v_1^1,\dots,v_{n_1}^1,\dots,v_1^k,\dots,v_{n_k}^k)\coloneqq(e_1^1,\dots,e_{n_1}^1,\dots,e_1^k,\dots,e_{n_k}^k) $$

Now suppose that each local component can be represented as a local state space $G_i=(S_i,\Sigma_i,\Delta_i,I_i)$ which corresponds to the local component $T_i$.
We assume that the set of local states $S_i$ are disjoint, but $\Sigma_i$ need not be.
If the label $\alpha$ appears in both $\Sigma_i$ and $\Sigma_j$, then $G_i$ and $G_j$ must be synchronized to perform $\alpha$ at the same time.

We define the operator $\circ$ to combine two state spaces $G_1$ and $G_2$ as follows: let $G_1\circ G_2=(S,\Sigma,\Delta,I)$ as follows:
\benum
    \item $S=S_1\times S_2$, each state is a pair of a state from $G_1$ and $G_2$,
    \item $\Sigma=\Sigma_1\cup\Sigma_2$, the transition names include all the names in both $G_1$ and $G_2$,
    \item The set of transitions $\Delta$ is the union of the following three sets:
        \benum
            \item $\set{\bigl((s,r),\alpha,(s',r)\bigr)}[(s,\alpha,s')\in\Delta_1,\,\alpha\in\Sigma_1\setminus\Sigma_2,\,r\in S_2]$.
                In this case, we have a transition $(s,\alpha,s')$ in $G_1$ with no transition of the same name in $\Sigma_2$, so we transition from $(s,r)$ to $(s',r)$, leaving the state in $G_2$
                unchanged.
            \item $\set{\bigl((s,r),\beta,(s,r')\bigr)}[(r,\beta,r')\in\Delta_2,\,\beta\in\Sigma_2\setminus\Sigma_1,\,s\in S_1]$.
                This is similar to the previous set, but for $G_2$ instead of $G_1$.
            \item $\set{\bigl((s,r),\gamma,(s',r')\bigr)}[(s,\gamma,s')\in\Delta_1,\,\gamma\in\Sigma_1\cap\Sigma_2,\,(r,r')\in\Delta_2]$.
                Here, we have a transition in both $G_1$ and $G_2$, so the transition is done simultaneously.
        \eenum
\eenum

So for example, the following two state spaces combine together to give

\medskip
\hbox to\hsize{\hfil
    \drawdiagram{%
        $\bf s_1$\cr
        \cr
        $s_2$\cr
    }{%
        \diagarrow{from={1,1}, to={3,1}, x off=-.25cm, text=$\alpha$, x distance=-.5cm}
        \diagarrow{from={3,1}, to={1,1}, x off=.25cm, text=$\beta$, x distance=.5cm}
    }\kern.75cm$\circ$\kern.75cm
    \drawdiagram{%
        $\bf r_1$\cr
        \cr
        $r_2$\cr
    }{%
        \diagarrow{from={1,1}, to={3,1}, x off=-.25cm, text=$\beta$, x distance=-.5cm}
        \diagarrow{from={3,1}, to={1,1}, x off=.25cm, text=$\gamma$, x distance=.5cm}
    }\kern1cm$=$\kern.5cm
    \drawdiagram{%
        &$\bf(s_1,r_1)$\cr
        $(s_1,r_2)$&&$(s_2,r_1)$\cr
        &$(s_2,r_2)$\cr
    }{
        \diagarrow{from={1,2}, to={2,3}, text=$\alpha$, slide=.4, x distance=.4cm}
        \diagarrow{from={2,1}, to={1,2}, text=$\gamma$, slide=.6, x distance=-.4cm}
        \diagarrow{from={2,3}, to={2,1}, text=$\beta$, y distance=.25cm}
        \diagarrow{from={2,1}, to={3,2}, text=$\alpha$, slide=.6, x distance=-.4cm}
        \diagarrow{from={3,2}, to={2,3}, text=$\gamma$, slide=.3, x distance=.5cm}
    }\hfil
}

\vfill\break

\section{Specification Formalisms}

We now introduce language which allows us to formally discuss properties of systems and their executions.
By doing so, we can prove these properties formally and without room for interpretative error.

Let ${\cal L}$ be a set logic (either propositional or first-order),
${\cal S}$ will be an ${\cal L}$-structure, but in general we will refrain from mentioning it instead; we will write $\vDash$ in place of $\vDash^{\cal S}$.

\bdefn

    {\emphcolor Linear temporal logic} (abbreviated LTL) is an instance of modal logic.
    It is defined over ${\cal L}$ recursively as follows:
    \benum
        \item Every formula of ${\cal L}$ is also a formula of LTL,
        \item if $\phi$ and $\psi$ are LTL formulas, so too are $\neg\phi,(\phi\land\psi),\bigcirc\phi,\diamond\phi,\square\phi,\phi\U\psi,\phi\V\psi$.
    \eenum
    An LTL formula is interpreted over an infinite sequence of states $\xi=x_0x_1x_2\dots$.
    Let us write $\xi^k$ for the suffix $\xi^k\coloneqq x_kx_{k+1}\dots$, then we define
    \benum
        \item if $\phi\in{\cal L}$ then $\xi^k\vDash\phi$ if $x_k\vDash\phi$ in ${\cal L}$,
        \item $\xi^k\vDash\neg\phi$ if $\xi^k\nvDash\phi$,
        \item $\xi^k\vDash\phi\land\psi$ if $\xi^k\vDash\phi$ and $\xi^k\vDash\psi$,
        \item $\xi^k\vDash\bigcirc\phi$ if $\xi^{k+1}\vDash\phi$,
        \item $\xi^k\vDash\diamond\phi$ if there is an $i\geq k$ such that $\xi^i\vDash\psi$,
        \item $\xi^k\vDash\square\phi$ if $\xi^i\vDash\psi$ for every $i\geq k$,
        \item $\xi^k\vDash\phi\U\psi$ if there is an $i\geq k$ such that $\xi^i\vDash\psi$ and for all $k\leq j<i$, $\xi^j\vDash\psi$,
        \item $\xi^k\vDash\phi\V\psi$ if for every $i\geq k$, $\xi^i\vDash\psi$; or for some $i\geq k$, $\xi^i\vDash\phi$ and for every $k\leq j\leq i$, $\xi^j\vDash\psi$.
    \eenum

\edefn

\def\sqwd{.5cm}
\def\sqht{.5cm}
\def\sqstroke{.3pt}
\def\sq{\hbox{$\vcenter to\sqht{\hrule height\sqstroke\hbox to\sqwd{\vrule width\sqstroke height\dimexpr\sqht-\sqstroke * 2\relax\hfil\vrule width\sqstroke}\hrule height\sqstroke}$}}
\def\tosq#1{\hbox to\sqwd{\hss#1\hss}}

Intuitively we can explain the new operators as follows:
\benum
    \global\enumcount=3
    \item $\bigcirc$ is the {\it nexttime} operator: $\bigcirc\phi$ holds in the sequence $x_kx_{k+1}\dots$ if $\phi$ holds starting from the next state $x_{k+1}$.
        Visually we can view it like so:

        \medskip
        \moveright\leftskip\hbox to\dimexpr\hsize-\leftskip\relax{\rlap{\kern\sqwd\tosq{$\phi$}}\leaders\sq\hfill\null}
    \item $\diamond$ is the {\it eventually} operator: $\diamond\phi$ holds in the sequence $\xi$ provided there exists a suffix in which $\phi$ holds.
        Visually:

        \medskip
        \moveright\leftskip\hbox to\dimexpr\hsize-\leftskip\relax{\rlap{\kern\dimexpr\sqwd * 10\relax\tosq{$\phi$}}\leaders\sq\hfill\null}
    \item $\square$ is the {\it always} operator: $\square\phi$ holds in the sequence $\xi$ provided it holds in every suffix of $\xi$.
        Visually:

        \medskip
        \moveright\leftskip\hbox to\dimexpr\hsize-\leftskip\relax{\leaders\tosq{$\phi$}\hfill\kern-\dimexpr\hsize-\leftskip\relax\leaders\sq\hfill\null}
    \item $\U$ is the {\it until} operator: $\phi\U\psi$ holds in the sequence $\xi$ if $\psi$ holds eventually and $\phi$ holds up until then:

        \medskip
        \moveright\leftskip\hbox to\dimexpr\hsize-\leftskip\relax{\leaders\tosq{$\phi$}\hskip\dimexpr\sqwd * 20\relax\tosq{$\psi$}\kern-\dimexpr\sqwd * 21\relax\leaders\sq\hfill\null}
    \item $\V$ is the {\it release} operator: $\phi\V\psi$ holds if $\psi$ either holds forever, or up until some point when both $\phi$ and $\psi$ hold.
        The reasoning for the name is that $\phi$ ``releases'' $\psi$ from having to hold for forever.

        \medskip
        \moveright\leftskip\hbox to\dimexpr\hsize-\leftskip\relax{\leaders\tosq{$\psi$}\hfill\kern-\dimexpr\hsize-\leftskip\relax\leaders\sq\hfill\null}
        \medskip

        \centerline{Or:}
        \medskip
        \moveright\leftskip\hbox to\dimexpr\hsize-\leftskip\relax{%
            \def\sqht{1cm}\leaders\tosq{$\psi$}\hskip\dimexpr\sqwd * 20\relax\tosq{$\stackmath{\psi\cr\noalign{\kern.2cm}\phi}$}\kern-\dimexpr\sqwd * 21\relax\leaders\sq\hfill\null}
\eenum

Notice that $\diamond$ is a special case of $\U$: $\diamond\phi\equiv\true\U\phi$.
And $\square$ is a special case of $\V$: $\square\phi\equiv\false\V\phi$ (since $\false$ can never relase $\phi$).
$\square$ and diamond are also related through $\neg\square\phi\equiv\diamond\neg\phi$.

We can also relate $\U$ and $\V$ by $\neg(\phi\V\psi)\equiv(\neg\phi)\U(\neg\psi)$.
We will prove this directly from definition:
$$ \xi^k\vDash\phi\V\psi \iff \bigl((\forall i\geq k)\xi^i\vDash\psi\bigr)\lor\bigl((\exists j\geq k)(\forall k\leq i<j)\xi^i\vDash\psi\land\psi^j\vDash\phi\bigr) $$
and so
$$ \xi^k\vDash\neg(\phi\V\psi) \iff \bigl((\exists i\geq k)\xi^i\vDash\neg\psi\bigr)\land\bigl((\forall j\geq k)(\exists k\leq i<j)\xi^i\vDash\neg\psi\lor\psi^j\vDash\neg\phi\bigr) $$
So at every $j\geq k$, either $\neg\phi$ or $\neg\psi$ holds, and eventually $\neg\psi$ holds.
This just means that $\neg\phi$ holds until $\neg\psi$ holds, ie. $(\neg\phi)\U(\neg\psi)$.

Thus, we could've defined LTL with only the operators $\neg,\land,\bigcirc,\U$ (in other words, these form a {\it complete bundle}).

We can combine operators: for example $\square\diamond\phi$ means that always, $\phi$ eventually happens; or equivalently $\phi$ happens infinitely many times.
$\diamond\square\phi$ means that at some point, $\phi$ will hold forever.
$\bigcirc\bigcirc\phi$ means that $\phi$ holds after two steps.
Notice that $\xi\vDash\diamond\phi$ if and only if there exists some $n$ such that $\xi\vDash\bigcirc^n\phi$ ($\bigcirc^n$ meaning $\bigcirc\cdots\bigcirc$ $n$ times).

Let $P$ be a system which has multiple executions, then we write $P\vDash\phi$ if $\xi\vDash\phi$ for all executions $\xi$ of $P$.
Importantlu $P\nvDash\phi$ does not imply $P\vDash\neg\phi$, since one execution not satisfying $\phi$ does not mean all executions don't satisfy $\phi$.

\bexam

    \def\mal{{\it malfunctioned}}\def\ext{{\it extended}}
    Let us consider a simple model of a spring.
    The spring can be in one of the following three states: $\set{{\it initial},{\it extended},{\it extended\ and\ malfunctioned}}$ which we denote $s_1,s_2,s_3$ respectively.
    So our propositional variables are $\PV=\set{\ext,\mal}$.
    Since $s_1$ is neither extended nor malfunctioned, $s_1\vDash\neg\ext\land\neg\mal$, $s_2\vDash\ext\land\neg\mal$, $s_3\vDash\ext\land\mal$.

    We can transition from $s_1$ to $s_2$ via pulling the spring, and releasing the spring can either transition to $s_1$ or to $s_3$.
    From $s_3$ we transition only to $s_3$.

    This system has an infinite number of executions, for example
    $$ \eqalign{
        \xi_0 &= s_1s_2s_1s_2s_3s_3s_3s_3\cdots\cr
        \xi_1 &= s_1s_2s_3s_3s_3s_3s_3s_3\cdots\cr
        \xi_2 &= s_1s_2s_1s_2s_1s_2s_1s_2\cdots\cr
    } $$
    Let us investigate $\xi_0$:
    \benum
        \item $\xi_0\nvDash\ext$ since $\ext$ is a formula of the underlying logic of the LTL and so $\xi_0$ satisfies $\ext$ if and only if its first state, $s_1$, does.
            It does not.
        \item $\xi_0\vDash\bigcirc\ext$ (``nexttime extended'') since $\xi_0\vDash\bigcirc\ext\iff\xi_0^1\vDash\ext\iff s_2\vDash\ext$ which it does.
        \item $\xi_0\nvDash\bigcirc\bigcirc\ext$ (``nexttime nexttime extended'') since $\xi_0^2$ begins with $s_1$ which does not satisfy $\ext$.
        \item $\xi_0\vDash\diamond\ext$ (``eventually extended'') since eventually the spring is extended (this is since $\xi_0\vDash\bigcirc\ext$).
        \item $\xi_0\nvDash\square\ext$ (``always extended'') since the spring is not always extended.
        \item $\xi_0\vDash\diamond\square\ext$ (``eventually always extended'') since eventually the spring remains in $s_3$ where it is extended.
        \item $\xi_0\nvDash(\neg\ext)\U\mal$ (``not extended until malfunctioned'') since the spring is not extended, then extended and not malfunctioned.
    \eenum

    Let us now investigate the system $P$ as a whole:
    \benum
        \item $P\vDash\diamond\ext$ since for the spring to not extend, it would need to forever remain in $s_1$, which is impossible.
        \item $P\vDash\square(\neg\ext\to\bigcirc\ext)$ which means that always, if the spring is not extended then the next time it is.
            This is since in order for the spring to not be extended, it must be in $s_1$, which means that the next time it is in $s_2$, extended.
        \item $P\nvDash\diamond\square\ext$, since $\xi_2$ is a counterexample: here we have that we never are only extended, in other words $\xi_2\vDash\square\diamond\neg\ext$.
        \item $P\nvDash\neg\diamond\square\ext$, since $\xi_0$ is a counterexample: here we have that eventually we are only extended.
        \item $P\nvDash\square(\ext\to\bigcirc\neg\ext)$ since it is possible to go from extended to extended ($s_2$ to $s_3$).
            The only sequence in which this is true is $\xi_2$.
    \eenum

\eexam

We can form a Hilbert calculus to axiomatize LTL with respect to a system $P$.
To form it we adjoin to the Hilbert calculus of ${\cal L}$ (which is either first-order or propositional, usually propositional. But importantly these axioms now range over all LTL formulas, not just
formulas in ${\cal L}$) the following eight axioms:

\medskip
{\tabskip=0pt plus 1fil
\halign to\hsize{(#)\hfil\tabskip=.25cm&$#$\hfil\tabskip=.5cm&(#)\hfil\tabskip=.25cm&$#$\hfil\tabskip=.5cm&(#)\hfil\tabskip=.25cm&$#$\hfil\tabskip=0pt plus 1fil\cr
    A1&\neg\diamond\phi\oto\square\neg\phi&A2&\square(\phi\to\psi)\to(\square\phi\to\square\psi)&A3&\square\phi\to(\phi\land\bigcirc\square\phi)\cr
    A4&\bigcirc\neg\phi\oto\neg\bigcirc\phi&A5&\bigcirc(\phi\to\psi)\to(\bigcirc\phi\to\bigcirc\psi)&A6&\square(\phi\to\bigcirc\phi)\to(\phi\to\square\phi)\cr
    A7&(\phi\U\psi)\oto\bigl(\psi\lor(\phi\land\bigcirc(\phi\U\psi))\bigr)&A8&(\phi\U\psi)\to\diamond\psi\cr
}}
\medskip

Here we take $\V$ as defined by $(\phi\V\psi)\coloneqq\neg((\neg\phi)\V(\neg\psi))$.
We use the following rule of reference (temporal generalization) as well as MP
$$ \vbox{\halign{\hfil$#$\hfil\cr\phi\cr\noalign{\kern2pt\hrule\kern2pt}\ \square\phi\ \cr}} $$
meaning that if $\phi$ then $\square\phi$ (notice that here we do not have an initial state, and hence we obtain the soundness of generalization).

\bexam

    Let us look at a model of a traffic light, which can transition between colors as follows:

    \def\gr{{\it green}}\def\ye{{\it yellow}}\def\re{{\it red}}
    \medskip
    \centerline{\drawdiagram{
        $\gr$&$\ye$&$\re$&\cr
    }{%
        \diagarrow{from={1,1}, to={1,2}, color=rgb{.1 .65 .1}}
        \diagarrow{from={1,2}, to={1,3}, color=rgb{.1 .65 .1}}
        \diagarrow{from={1,3}, to={1,1}, curve=1cm, origin orient={xcenter, bottom}, dest orient={xcenter, bottom}, color=rgb{.1 .65 .1}}
    }}
    \kern.5cm

    The traffic light is only ever in one color, which can be expressed in LTL as:
    $$ \square\bigl(\neg(\gr\land\ye)\land\neg(\ye\land\re)\land\neg(\re\land\gr)\land(\gr\lor\ye\lor\re)\bigr) $$
    Specifying the transition of colors can be done via
    $$ \square\bigl((\gr\U\ye)\lor(\ye\U\re)\lor(\re\U\gr)\bigr) $$
    Now suppose we alter the state graph to be

    \medskip
    \centerline{\drawdiagram{
        $\gr$&$\ye$&$\re$&$\ye$&\cr
    }{%
        \diagarrow{from={1,1}, to={1,2}, color=rgb{.1 .65 .1}}
        \diagarrow{from={1,2}, to={1,3}, color=rgb{.1 .65 .1}}
        \diagarrow{from={1,3}, to={1,4}, color=rgb{.1 .65 .1}}
        \diagarrow{from={1,4}, to={1,1}, curve=1cm, origin orient={xcenter, bottom}, dest orient={xcenter, bottom}, color=rgb{.1 .65 .1}}
    }}
    \kern.5cm

    Specifying the colors is now harder, since $\square(\ye\to\ye\U\re)$ is no longer necessarily true.
    We could attemp $\square\bigl(((\gr\lor\re)\U\ye)\lor(\ye\U(\gr\lor\re))\bigr)$, but $(\gr\lor\re)\U\ye$ allows the light to switch between $\gr$ and $\re$ before turning $\ye$.
    A correct specification would be

    \medskip
    \centerline{\vbox{\halign{$#$\hfil&\hfil$#$&$#$\hfil\cr
        \square\bigl(&(\gr\to&(\gr\U(\ye\land(\ye\U\re))))\cr
        \land        &(\re\to&(\re\U(\ye\land(\ye\U\gr))))\cr
        \land        &(\ye\to&(\ye\U(\re\U\gr)))\bigr)\cr
    }}}
    \medskip

    The first line allows $\gr\to\ye\to\re$, the second allows $\re\to\ye\to\gr$.
    These two lines deal only with the case that the light begins on $\gr$ or $\re$, the third line deals with the case when it starts on $\ye$.

\eexam

\subsection{Automata on Infinite Words}

A {\it B\"uchi Automata} is a tuple ${\cal A}=(\Sigma,S,\Delta,I,L,F)$ where
\benum
    \item $\Sigma$ is the finite alphabet,
    \item $S$ is a finite set of states,
    \item $\Delta\subseteq S\times S$ is the transition relation,
    \item $I\subseteq S$ is the set of initial states,
    \item $L\colon S\longto\Sigma$ is a labeling of the states,
    \item $F\subseteq S$ is the set of accepting states.
\eenum
A {\it run} of ${\cal A}$ on a word $v\in\Sigma^\omega$ (the set of all infinite words over $\Sigma$) is a sequence $\rho\colon{\bb N}\longto S$ such that
\benum
    \item $\rho(0)\in I$, the first state is an initial state,
    \item for all $i\geq0$, $(\rho(i),\rho(i+1))\in\Delta$, meaning the transition from $\rho(i)$ to $\rho(i+1)$ is a transition recognized by $\Delta$,
    \item for all $i\geq0$, $v(i)=L(\rho(i))$, meaning the $i$th state has the same label as the $i$th letter in $v$.
\eenum
Let us define
$$ \infof\rho \coloneqq \set{s\in S}[\hbox{there exist infinitely many $i$ such that $\rho(i)=s$}] $$
A run $\rho$ of ${\cal A}$ is {\it accepting} if an accepting state appears infinitely many times in $\rho$, meaning $\infof\rho\cap F\neq\varnothing$.
If $\rho$ is a run of the word $v$, then we say that $v$ is {\it accepted} by ${\cal A}$.
The language of ${\cal A}$, denoted ${\cal L}({\cal A})\subseteq\Sigma^\omega$, is the set of all words accepted by ${\cal A}$.

For the visual representation of B\"uchi automata, we circle accepting states and bold initial states.
So for example

\bigskip
\centerline{\drawdiagram{
    \circleit{$\bf s_1$}&&$\bf s_2$\cr
}{
    \diagarrow{from={1,1}, to={1,3}, curve=.4cm, text=$\alpha$, slide=0, y distance=.4cm, y off=.15cm}
    \diagarrow{from={1,3}, to={1,1}, curve=.4cm, text=$\beta$, slide=0, y distance=.4cm, y off=-.15cm}
    \diagarrow{from={1,1}, to={1,1}, origin orient={right, bottom}, dest orient={left, bottom}, curve=1cm, y off=-.1cm}
    \diagarrow{from={1,3}, to={1,3}, dest orient={right, bottom}, origin orient={left, bottom}, curve=-1cm}
}}
\bigskip

Here the initial states are $s_1$ and $s_2$, and the single accepting state is $s_1$.
${\cal L}({\cal A})$ contains letters with infinitely many $\alpha$s, or as a regular expression $(\beta^*\alpha)^\omega$.
This describes an infinite concatenation of words of the form $\beta^*\alpha$ which is formed by an arbitrary number of $\beta$s and then an $\alpha$.

We can alter the definition of a B\"uchi automaton for a transition system ${\cal A}$ as follows:
\benum
    \item $\Sigma$ becomes the set of states of ${\cal A}$ (which are valuations of ${\cal A}$, not to be confused with the states in $S$),
    \item $L$ now becomes a labeling function from $S\to{\cal L}$ the set of (propositional) formulas over ${\cal A}$,
    \item A run $\phi$ of $v$ now must satisfy instead of $v(i)\in L(\rho(i))$ instead that $v(i)\vDash L(\rho(i))$.
\eenum

We will show that a LTL specification $\phi$ can be represented as a B\"uchi automata ${\cal B}$.
Then a state space ${\cal A}$ satisfies the specification if ${\cal L}({\cal A})\subseteq{\cal L}({\cal B})$, meaning every sequence of states valid in ${\cal A}$ are valid in ${\cal B}$ (meaning they
satisfy $\phi$).

\vfill\break
\section{Automatic Verification}

Suppose we have a finite state (transition) system with a set of initial set of states $I$.
We below define an algorithm which searches the state space for every state reachable from the set of initial states.

\algorithm
    \InnerText{\textbf{routine} {\tencsc Search}}
    \State {\bf let} {\it new} contain the set of initial states $I$, and {\it old} be empty
    \While{{\it new} is not empty}
        \State {\bf choose} $s$ from {\it new}
        \State {\bf remove} $s$ from {\it new}
        \State {\bf add} $s$ to {\it old}
        \For{$t$ transition enabled at $s$}
            \State $s'\gets t(s)$
            \lIf{$s'$ is not in {\it new} or {\it old}} {\bf add} $s'$ to {\it new}
        \EndFor
    \EndWhile
\ealgorithm

Here we do not specify how to choose $s$ from {\it new} or how to store elements in {\it new}.
One could use a queue for {\it new}, forming the breadth-first-search (BFS) search algorithm.
Or one could use a stack, defining depth-first-search (DFS).

We can add a conditional check to this algorithm to check that every state added to {\it new} satisfies some property $\phi$ (a propositional or first order formula).
In this way we can check whether or not $\phi$ is an invariant: meaning $\square\phi$ holds.
Similarly we can check for deadlocks by checking if we visit a state with no successors.

Notice though that this algorithm works only for finite state systems, as there needs to be a finite number of states in order for the algorithm to check every one.
So this algorithm cannot work for programs which utilize unbounded integers for example, and larger programs are prone to combinatorial explosion.

\subsection{Closure of B\"uchi Automata}

Suppose we have B\"uchi automata over the same alphabet ${\cal A}_i=(\Sigma,S_i,\Delta_i,I_i,L_i,F_i)$ for $i=1,2$.
We want to define a new B\"uchi automaton ${\cal A}=(\Sigma,S,\Delta,I,L,F)$ such that ${\cal L}({\cal A})={\cal L}({\cal A}_1)\cup{\cal L}({\cal A}_2)$.
This can be done with relative ease, as we can assume without loss of generality that $S_1$ and $S_2$ are disjoint, so define
$$ S = S_1\dcup S_2,\quad \Delta=\Delta_1\dcup\Delta_2,\quad I=I_1\dcup I_2,\quad L=L_1\dcup L_2,\quad F=F_1\dcup F_2 $$
where $L=L_1\dcup L_2$ means $L(r)=L_1(r)$ for $r\in S_1$ and $L_2(r)$ for $r\in S_2$.
Then a run of ${\cal A}$ begins with either $I_1$ or $I_2$, and then proceeds as it would with ${\cal A}_1$ or ${\cal A}_2$ respectively.

To define ${\cal A}$ for $\Lof{\cal A}=\Lof{\cal A_1}\cap\Lof{\cal A_2}$, we must somehow run both automata in parallel.
We attempt a definition as follows:
\benum
    \item $S=S_1\times S_2$,
    \item $((r_1,r_2),(s_1,s_2))\in\Delta$ if and only if $(r_1,s_1)\in\Delta_1$ and $(r_2,s_2)\in\Delta_2$,
    \item $I=I_1\times I_2$
    \item $L(r,s)=L_1(r)\land L_2(s)$ as these are formulas, if $L(r,s)\equiv\false$ then we can remove $(r,s)$ and all its outgoing and ingoing edges,
\eenum
Now all that remains is to define $F$, the set of accepting states.
Here we must be careful: as a first attempt we may define $F=F_1\times F_2$, but then suppose ${\cal A}_1$ and ${\cal A}_2$ are never simultaneously on an accepting state.
Then even though they may both accept the word, since they are never on an accepting state at the same time, this automaton will never be in $F$.
So maybe we try $F=(F_1\times S_2)\cup(S_1\times F_2)$?
But then if ${\cal A}_1$ accepts the word and ${\cal A}_2$ doesn't, the automaton would still accept the word.

So let us first define what a {\it generalized B\"uchi automaton} is to make this proof easier.

\bdefn

    A {\emphcolor generalized B\"uchi automaton} is a tuple ${\cal A}=(\Sigma,S,\Delta,I,L,F)$ where all the components are the same as for normal B\"uchi automaton except for $F$.
    $F$ is now a set $\set{f_1,\dots,f_m}$ for $m\geq0$ where $f_i\subseteq S$.
    A run $\rho$ is accepted ${\cal A}$ if and only if $\infof\rho\cap f_i\neq\varnothing$ for all $f_i\in F$.

\edefn

Now if ${\cal A}_1$ and ${\cal A}_2$ are two B\"uchi automaton, we can define their intersection to be a generalized B\"uchi automaton whose components are defined as above and
$F=\set{F_1\times S_2,S_1\times F_1}$, so an accepted run must pass through both $F_1$ and $F_2$ an infinite number of times.

We now demonstrate how to convert a generalized B\"uchi automaton into a normal one.
Suppose ${\cal A}=(\Sigma,S,\Delta,I,L,F)$ is a generalized B\"uchi automaton with $F=\set{f_1,\dots,f_m}$, then define $S'=\bigdcup_{i=1}^mS_i$ where $S_i=S\times\set i$ so that all $S_i$ are disjoint.
$S'=\bigdcup_{i=1}^mS_i$ where $S_i=S\times\set i$ so that all $S_i$ are disjoint.
We define $\Delta'\subseteq S'\times S'$ as follows:
\benum
   \item for $(r,s)\in\Delta$, add $\bigl((r,i),(s,i)\bigr)$ to $\Delta'$ for all $1\leq i\leq m$ for which $r\notin f_i$.
   \item if $r\in f_i$ then add $\bigl((r,i),(s,i+1)\bigr)$ to $\Delta'$ where addition is cyclic: $m+1=1$.
\eenum
Define $I'=I\times\set1$, and $L'(s,i)=L(s)$.
Then choose $1\leq i\leq m$ arbitrarily and set $F'=f_i\times\set i$.

To get to a set in $f_i$, one must first progress through a sequence of sets in $f_1,\dots,f_{i-1}$ since the only way to go between levels ($S_i$s) in $S$ is to reach an accepting state in $f_i$.
Then once one reaches $f_i$, one must go to the next level $S_{i+1}$, so to get to $f_i$ again one must progress through $f_{i+1},\dots,f_m$ and back to $f_1,\dots,f_i$.
So to visit $f_i$ an infinite number of times, a run must visit all $f_j$ an infinite number of times.

So a complete construction of ${\cal A}_1\cap{\cal A}_2$ is as $(\Sigma,S_1\times S_2\times\set{1,2},\Delta,I,L,F)$ where
\benum
    \item for $(r_1,s_1)\in\Delta_1$ and $(r_2,s_2)\in\Delta_2$ if $r_1\notin F_1$ and $r_2\notin F_2$ then $\bigl((r_1,r_2,i),(s_1,s_2,i)\bigr)\in\Delta$ for $i=1,2$,
    \item if $r_1\in F_1$ and $r_2\notin F_2$ then $\bigl((r_1,r_2,1),(s_1,s_2,2)\bigr),\bigl((r_1,r_2,2),(s_1,s_2,2)\bigr)\in\Delta$
    \item if $r_1\notin F_1$ and $r_2\in F_2$ then $\bigl((r_1,r_2,1),(s_1,s_2,1)\bigr),\bigl((r_1,r_2,2),(s_1,s_2,1)\bigr)\in\Delta$
    \item if $r_1\in F_1$ and $r_2\in F_2$ then $\bigl((r_1,r_2,1),(s_1,s_2,2)\bigr),\bigl((r_1,r_2,2),(s_1,s_2,1)\bigr)\in\Delta$
\eenum
and $L(r,s,i)=L_1(r)\land L_2(s)$ where we remove states if this is equivalent to $\false$.
And $I=I_1\times I_2\times\set 1$, $F=F_1\times S_2\times\set1$.

So for example, if we have

\kern.75cm
\centerline{
\drawdiagram{
    \circleit{$\bf q_0$}&&$\bf q_1$\cr
}{
    \diagarrow{from={1,1}, to={1,3}, y off=.25cm, slide=0, text={$A\land\neg B$}, x distance=-1cm}
    \diagarrow{from={1,3}, to={1,1}, y off=-.25cm, slide=0, text={$\neg A$}, x distance=.5cm}
    \diagarrow{from={1,1}, to={1,1}, curve=-1cm, origin orient={right, top}, dest orient={left, top}}
    \diagarrow{from={1,3}, to={1,3}, curve=1cm, dest orient={right, top}, origin orient={left, top}}
}\kern5cm
\drawdiagram{
    \circleit{$\bf q_2$}&&$q_3$\cr
}{
    \diagarrow{from={1,1}, to={1,3}, y off=.25cm, slide=0, text={$\neg A\land B$}, x distance=-1cm}
    \diagarrow{from={1,3}, to={1,1}, y off=-.25cm, slide=0, text={$A\lor\neg B$}, x distance=1cm}
}
}

Notice that $(q_0,q_2)$ can be removed as the conjunction of their labels is $\false$.
The intersection then is

\kern.5cm
\centerline{
\drawdiagram{
    $\underline{q_0,q_3,1}$&&$\bf q_1,q_2,1$&&$q_1,q_3,1$\cr
    \cr
    $q_0,q_3,2$&&$q_1,q_2,2$&&$q_1,q_3,2$\cr
}{
    \diagarrow{from={1,3}, to={1,1}, text=$A\land\neg B$, slide=1, y distance=.4cm}
    \diagarrow{from={1,3}, to={1,5}, y off=.15cm, text=$\neg A\land B$, slide=0, y distance=.4cm}
    \diagarrow{from={1,5}, to={1,3}, y off=-.15cm, text=$\neg A\land\neg B$, slide=0, y distance=.4cm}
    \diagarrow{from={1,1}, to={3,3}, x off=-.2cm}
    \diagarrow{from={3,3}, to={1,1}, x off=.2cm, text=$\neg A\land B$, slide=0, y distance=-.4cm}
    \diagarrow{from={3,1}, to={3,3}, text=$A\land\neg B$, slide=0, y distance=-.4cm}
    \diagarrow{from={3,5}, to={3,3}, text=$\neg A\land\neg B$, slide=0, y distance=-.4cm}
}
}
\bigskip

A more complicated construction is the proof that the complement of a B\"uchi automaton is also a B\"uchi automaton.

Recall that to check if ${\cal B}$ is a specification for ${\cal A}$, we need that $\Lof{\cal A}\cap\Lof{\cal B}^c$ is empty.
How do we check if an automaton's language is empty, meaning it has no accepting runs?
Suppose ${\cal A}=(\Sigma,S,\Delta,I,L,F)$ is a B\"uchi automaton and $\rho$ is an accepting run of ${\cal A}$.
Then $\rho$ contains infinitely many states in $F$, and since $S$ is finite there must exist a suffix $\rho'$ where every state in it occurs infinitely often.
This means the states of $\rho'$ comprise of a strongly connected component in the graph $(S,\Delta)$: all states are reachable from all the other states in $\rho'$.
Conversely, a strongly connected component reachable from an initial state and which contains an accepting state generates an accepting run: take $\rho$ to first consist of a path from an initial state to
the strongly connected component at vertex $v$, then suppose $a\in F$ is also in the strongly connected component, so $v$ and $a$ are connected, so have the rest of $\rho$ comprise of the path $v$ to $a$
composed with the path from $a$ to $v$.

So $\Lof{\cal A}$ being nonempty is equivalent to it having a strongly connected component reachable from an initial state containing an accepting state.
So to find if $\phi$ is a specification of ${\cal A}$, we can utilize the following algorithm:
\benum
    \item construct $\overline{\cal B}$ representing the negation of the specification $\phi$,
    \item construct the intersection ${\cal C}={\cal A}\cap\overline{\cal B}$,
    \item use Tarjan's algorithm to find strongly connected components of ${\cal C}$ reachable from initial states,
    \item if none of the components contain an accepting state, then $\phi$ is a specification.\
    \item otherwise let $S$ be a reachable strongly connected component.
        Construct a path $\sigma_1$ from an initial state to some state accepting state $q$ in the component, and construct a cycle $\sigma_2$ from $q$ back to itself.
        This exists since $S$ is strongly connected, and so $\sigma_1\sigma_2^\omega$ is a counterexample (it satisfies ${\cal A}$ but not ${\cal B}$/$\phi$).
\eenum

\subsection{Translating LTL Formulas into Automata}

We will now provide an algorithm for translating propositional LTL formulas into equivalent automata.
Suppose $\phi$ is an LTL formula, then it is equivalent to a {\it negation normal form} where negation is applied only on propositional variables.
This is due to the following equivalences:
$$ \neg\bigcirc\mu \equiv \bigcirc\neg\mu,\quad\neg(\mu\lor\eta)\equiv\neg\mu\land\neg\eta,\quad\neg(\mu\land\eta)\equiv\neg\mu\lor\neg\eta,\quad\neg\neg\mu\equiv\mu,\quad
\neg(\mu\U\eta)\equiv\neg\mu\V\neg\eta,\quad\neg(\mu\V\eta)\equiv\neg\mu\U\neg\eta $$
We also use the equivalences $\diamond\mu\equiv\true\U\mu$ and $\square\mu\equiv\false\V\mu$.

The idea is to decompose the formula into a boolean structure, then split the formula into what has to be true in this state and what has to be true in the next state onward.
For example, $\phi\U\psi$ is equivalent to $\psi\lor(\phi\land\bigcirc(\phi\U\psi))$, so either $\psi$ holds now, or $\phi$ holds now and $\phi\U\psi$ holds from the next state.
Similarly $\phi\V\psi$ is equivalent to $(\phi\land\psi)\lor(\psi\land\bigcirc(\phi\V\psi))$, so either both $\phi$ and $\psi$ hold now, or $\psi$ holds now and $\phi\V\psi$ holds from the next state.
So let us define the functions $\now_1,\next,\now_2$ to encode this information, defined as in the table below:

\centerline{
    \vbox{\everycr={\noalign{\hrule}}\halign{\vrule\strut\kern.25cm$#$\hfil\kern.25cm\vrule&&\kern.25cm\hfil$#$\hfil\kern.25cm\vrule\cr
    \eta&\now_1(\eta)&\next_1(\eta)&\now_2(\eta)\cr
    \phi\U\psi&\set\phi&\set{\phi\U\psi}&\set\psi\cr
    \phi\V\psi&\set\psi&\set{\phi\V\psi}&\set{\phi,\psi}\cr
    \phi\lor\psi&\set\phi&\varnothing&\set\psi\cr
    \phi\land\psi&\set{\phi,\psi}&\varnothing&-\cr
    \bigcirc\phi&\varnothing&\set\phi&-\cr
}}}

The meaning being that for $\eta$ to hold, either everything in $\now_1(\eta)$ holds in this state and $\next_1(\eta)$ holds in the next state, or $\now_2(\eta)$ holds in this state.
When the set is $\varnothing$ then it holds vaccuously, and if the set is $-$ then it does not hold.

Our algorithm will utilize {\it graph nodes} to represent LTL formulas.
Each graph node will have the following fields:
\benum
    \item {\it Name}: a unique identifier for the node,
    \item {\it Incoming}: a list of identifiers (names) for nodes whith edges outgoing into the graph node,
    \item {\it Now, Old, Next}: each of these represent LTL formulas.
        {\it Now} represents the LTL formula which must be satisfied by the current state, {\it Old} represents the LTL formula which must've been satisfied by the previous state, and {\it Next} represents
        the formula satisfied by the next state.
\eenum

When translating an LTL formula in negation normal form $\phi$, the algorithm begins with a single graph node ${\sf init}$ with fields $\now=\set\phi$, $\next=\old=\varnothing$.
When recursing on the current node $s$, the algorithm checks if there are any formulas in the $\now$ field.
If not, then the processing on the current node is complete and now the node must be added to a set of nodes {\it Node\_Set}.
If there already exists a node $r$ in {\it Node\_Set} with the same $\next$ and $\old$ fields (since $\now$ is empty), then there is no need to add $s$ to the set.
Instead add the incoming edges of $s$ to the incoming edges of $r$.

Otherwise, add $s$ to {\it Node\_set} and create a {\it successor node} $s'$ defined so that $s'$'s $\now$ field is $s$'s $\next$ field.
$s'$'s $\old$ and $\next$ are set to be empty.
Now recurse on $s'$.

If $s$'s $\now$ field is non-empty, select a formula $\eta$.
$\eta$ is either a proposition, a boolean constant, or the negation of a proposition, or of the form $\neg\mu,\mu\lor\psi$, $\mu\land\psi$, $\bigcirc\mu$, $\mu\U\psi$, or $\mu\V\psi$.
So we split into cases:
\benum
    \item $\eta$ is a proposition, boolean constant, or negation of a proposition.
        If $\eta$ is $\false$ or $\neg\eta$ is in $\old$ then discard $s$: it contains a contradiction.
        Otherwise have $s$ {\it evolve} into $s'$ which is obtained by moving $\eta$ from $\now$ to $\old$.
    \item If $\eta=\mu\U\psi$ then {\it split} $s$ into two new nodes $s_1$ and $s_2$.
        For $s_1$, $\mu$ is added to $\now$ and $\mu\U\psi$ to $\next$.
        For $s_2$, $\psi$ is added to $\now$.
        $s_1$ and $s_2$ get the incoming nodes of $s$.
        This is due to the fact that $\mu\U\psi$ is equivalent to $\psi\lor(\mu\land\bigcirc(\mu\U\psi))$, so for $\mu\U\psi$ we can either go to $\psi$ ($s_2$) or $\mu$ with the next state $\mu\U\psi$
        ($s_1$).
    \item If $\eta=\mu\V\psi$ then {\it split} $s$ into $s_1$ and $s_2$ where $\now(s_1)=\set{\psi,\mu}$, $\now(s_2)=\set\psi$, and $\next(s_2)=\set{\mu\V\psi}$.
    \item If $\eta=\mu\lor\psi$ then split to $s_1$, $s_2$ where $\now(s_1)=\set\mu$, $\now(s_2)=\set\psi$.
    \item If $\eta=\mu\land\psi$ then evolve to $s'$ where $\now(s')=\set{\mu,\psi}$.
    \item If $\eta=\bigcirc\mu$ then evolve to $s'$ where $\next(s')=\set\mu$.
\eenum

The algorithm then recurses on $s'$.
Once finished recursing, the algorithm has constructed a set of graph nodes {\it Node\_Set}, which it will use to construct a generalized B\"uchi automaton $B=(\Sigma,S,\Delta,I,L,F)$ defined by
\benum
    \item $\Sigma$ is the alphabet which consists of all Boolean combinations of propositional variables found in $\phi$.
    \item $S$ is the set of states consisting of nodes in {\it Node\_Set}.
    \item $(s,s')\in\Delta$ if and only if $s$ is in $\incom(s)$.
    \item $s\in I$ if and only if ${\sf init}\in\incom(s)$.
    \item $L(s)$ is the conjunction of the literals (negated and non-negated propositions) in $\old(s)$.
    \item For every subformula of $\phi$ of the form $\mu\U\psi$ form a set $f\in F$ which contains all the states $s$ such tha $\psi\in\old(s)$ or $\mu\U\psi\notin\old(s)$.
\eenum

\algorithm
    \Function{expand}{$s$, ${\it Node\_Set}$}
        \If{$\now(s)=\varnothing$}
            \If{$\exists r\in{\it Node\_Set}$ such that $\old(r)=\old(s)$ and $\next(r)=\next(s)$}
                \State $\incom(r)\gets\incom(r)\cup\incom(s)$
                \State\Return ${\it Node\_Set}$
            \Else
                \State ${\it Node\_Set}\gets{\it Node\_Set}\cup\set s$
                \State $\now(s'),\next(s')\gets\varnothing$
                \State $\old(s')\gets\now(s)$
                \State $\incom(s')\gets\set s$
                \State \Return {\tencsc expand}$(s,{\it Node\_Set})$
            \EndIf
        \EndIf
        \State \textbf{choose} $\eta\in\now(s)$
        \State $\now(s)\gets\now(s)\setminus\set\eta$
        \lIf{$\eta=\false$ \textbf{or} $\neg\eta\in\old(s)$} \Return ${\it Node\_Set}$
        \State $\old(s_1),\old(s_2)\gets\old(s)\cup\set\eta$
        \State $\now(s_1)\gets\now_1(\eta)\cup\now(s)$
        \State $\now(s_2)\gets\now_2(\eta)\cup\now(s)$
        \State $\next(s_1)\gets\next_1(\eta)\cup\next(s)$
        \State $\next(s_2)\gets\next(s)$
        \State \Return {\tencsc epxand}$(s_2,\hbox{\tencsc expand}(s_1,{\it Node\_Set}))$
    \EndFunc
\ealgorithm

On line $19$, in the case that $\now_2(\eta)$ is $-$ then skip the line (and return {\tencsc expand}$(s_1,{\it Node\_Set})$).

\vfill\break

\section{Fairness}

\subsection{Dekker's Algorithm}

Let us look at a program called {\it Dekker's algorithm} for mutual exclusion:

\def\wte{{\sf wants\_to\_enter}}
\medskip
\hbox to \hsize{
    \hfil\vbox{\hsize=.4\hsize
    \algorithm
        \InnerText{\textbf{routine} $P_1$}
            \While{{\sf true}}
                \Comment non-critical section \EndComment
                \State $\wte_1\gets\true$
                \While{$\wte_2$}
                    \If{${\sf turn}=2$}
                        \State $\wte_1\gets\false$
                        \State \textbf{wait} until ${\sf turn}=1$
                    \EndIf
                \EndWhile
                \Comment critical section \EndComment
                \State ${\sf turn}\gets2$
                \State $\wte_1\gets\false$
            \EndWhile
        \InnerText{\textbf{end routine}}
    \ealgorithm
    }
    \hfil\vbox{\hsize=.4\hsize
    \algorithm
        \InnerText{\textbf{routine} $P_2$}
            \While{{\sf true}}
                \Comment non-critical section \EndComment
                \State $\wte_2\gets\true$
                \While{$\wte_1$}
                    \If{${\sf turn}=1$}
                        \State $\wte_2\gets\false$
                        \State \textbf{wait} until ${\sf turn}=2$
                    \EndIf
                \EndWhile
                \Comment critical section \EndComment
                \State ${\sf turn}\gets1$
                \State $\wte_2\gets\false$
            \EndWhile
        \InnerText{\textbf{end routine}}
    \ealgorithm
    }
    \hfil
}
\medskip

Here we initialize $\wte_1$ and $\wte_2$ to $\false$, and ${\sf turn}$ to $1$.
Recall that in our model, a transition is picked at random and executed.
So the following is a valid execution:
\benum
    \item Have both programs progress to line $2$ (inclusive).
        Now $\wte_1=\wte_2=\true$, and ${\sf turn}=1$.
    \item Now have $P_1$ execute indefinitely, so that it forever executes the while loop on lines $3-8$.
\eenum
In such an execution, neither process will progress.
What we want is for $P_2$ to eventually execute and progress to line line $5$ and set $\wte_2$ to $\false$, thus letting $P_1$ progress and eventually let $P_2$ progress.

The issue is in our interleaving model, a transition is chosen at random and so here the scheduling was {\it unfair} to $P_2$: it never executed a transition of $P_2$.

\subsection{Fairness Conditions}

We define some notions of fairness:

\benum
    \item {\it Weak transition fairness}: if in an execution from some state $s$ and onward a transition is enabled, then it must be executed some time after $s$.
    \item {\it Weak process fairness}: if in an execution from some state $s$ and onward there is at least one transition of process $P_i$ enabled, then some transition of $P_i$ must be eventually executed
        after $s$.
    \item {\it Strong transition fairness}: if a transition is enabled infinitely many times, it is executed infinitely many times.
    \item {\it Strong process fairness}: if some transition of $P_i$ is enabled infinitely many times (not necessarily always the same transition) then a transition of $P_i$ (again, not necessarily the same
        one each time) is executed infinitely many times.
\eenum

Let us define the proposition $\exec_\alpha$ to mean that the transition $\alpha$ is executed and $\en_\alpha$ to mean it is enabled.
Then define
$$ \exec_{P_i} \coloneqq \bigvee_{\alpha\in P_i}\exec_\alpha,\qquad \en_{P_i} \coloneqq \bigvee_{\alpha\in P_i}\en_\alpha $$
so $\exec_{P_i}$ means that some transition of $P_i$ is executed, and $\en_{P_i}$ means that some transition of $P_i$ is enabled.
So we can use LTL formulas to define fairness:

\benum
    \item {\it Weak transition fairness}: $\bigwedge_{\alpha\in T}\bigl(\diamond\square\en_\alpha\to\square\diamond\exec_\alpha\bigr)$.
    \item {\it Weak process fairnes}: $\bigwedge_{P_i}\bigl(\diamond\square\en_{P_i}\to\square\diamond\exec_{P_i}\bigr)$.
    \item {\it Strong transition fairness}: $\bigwedge_{\alpha\in T}\bigl(\square\diamond\en_\alpha\to\square\diamond\exec_\alpha\bigr)$.
    \item {\it Strong process fairness}: $\bigwedge_{P_i}\bigl(\square\diamond\en_{P_i}\to\square\diamond\exec_{P_i}\bigr)$.

\eenum

For example, consider the following two processes, where $x$ is a global variable shared between both processes and $y$ is a variable local to $P_2$ initialized to zero.

\medskip
\hbox to \hsize{
    \hfil\vtop{\hsize=.4\hsize
    \algorithm
        \InnerText{\textbf{routine} $P_1$}
            \State $x\gets1$
        \InnerText{\textbf{end routine}}
    \ealgorithm
    }
    \hfil\vtop{\hsize=.4\hsize
    \algorithm
        \InnerText{\textbf{routine} $P_2$}
            \While{$y=0$}
                \Choose
                    \Comment {\sf nop} means ``no operation''\EndComment
                    \Choice {\sf nop}
                    \Choice {\bf if} ($x=1$) $y\gets1$
                \EndChoose
            \EndWhile
        \InnerText{\textbf{end routine}}
    \ealgorithm
    }
    \hfil
}
\medskip

The transitions then are

\def\pc{{\it pc}}
\medskip
\centerline{\vbox{\halign{\hfil$#$\tabskip=.1cm&$\hfil\longto$#\hfil\tabskip=.1cm&$#$\hfil\tabskip=2cm&\hfil$#$\tabskip=.1cm&$\hfil\longto$#\hfil\tabskip=.1cm&$#$\hfil\cr
    t_0\colon\ \pc_1=1 && (\pc_1,x)\coloneqq(2,1) & t_1\colon\ \pc_2=1\land y=0 && \pc_2\coloneqq2\cr
    t_2\colon\ \pc_2=2 && \pc_2\coloneqq1 & t_3\colon\ \pc_2=2\land x=1 && (\pc_2,y)\coloneqq(1,1)\cr
}}}
The initial condition is $\Theta\colon\ x=0\land y=0\land\pc_1=1\land\pc_2=1$.

Weak transition and weak process fairness do not guarantee termination.
This is since in order for termination to occur, $t_3$ must be executed.
But $t_3$ isn't necessarily enabled from a state onward, in fact every time $t_2$ is executed $t_3$ stops being enabled.
So we can use the transitions $t_0,t_2,t_2,\dots$ and the induced execution is allowed by weak fairness.
This is also allowed by strong process fairness.

Under strong transition fairness, the program will indeed terminate.
This is since $t_3$ is enabled an infinite number of times, since it is enabled after every execution of $t_1$ (and $t_0$ which must also be executed).
Thus it must be eventually executed, terminating the process.

\bdefn

    Let $\phi$ and $\psi$ be fairness conditions, we say that $\phi$ is {\emphcolor weaker} than $\psi$ (and $\psi$ is {\emphcolor stronger} than $\phi$) if $\vdash\psi\to\phi$.
    Meaning if $\xi$ is an execution, $\xi\vDash\psi$ implies $\xi\vDash\phi$, so $\phi$ allows for more executions than $\psi$.

\edefn

Then we have the following hierarchy of fairness conditions:

\medskip
\centerline{\drawdiagram{
    &\wdbox{3cm}{Strong transition fairness}\cr
    \wdbox{3cm}{Strong process fairness}&&\wdbox{3cm}{Weak transition fairness}\cr
    \wdbox{3cm}{Weak process fairness}\cr
}{
    \diagarrow{from={1,2}, to={2,1}}
    \diagarrow{from={1,2}, to={2,3}}
    \diagarrow{from={2,1}, to={3,1}}
}}

\bye

