Lambda calculus is a way of formalizing computations, it generalizes the concept of functions.
A function in lambda calculus has the form $\lambda x.t$ and should be thought of a function $x\mapsto t(x)$, in a language like OCaml, this corresponds to a function definition of the form
${\tt fun}\,x\to t$.
It is built from syntax, and we then utilize semantics to give this syntax meaning.

\bdefn

    Let $V$ be an infinite set of variable symbols, then terms in lambda calculus are constructed recursively as follows:
    \benum
        \item every variable is an term,
        \item if $x\in V$ is a variable and $t$ is an term, then $\lambda x.t$ is an term,
        \item if $t_1$ and $t_2$ are terms, then so is $t_1t_2$.
    \eenum

\edefn

Notice that lambda calculus terms have the {\it unique reconstruction property}: every term $t$ has one of the above forms, and such a form is {\it unique}.
We can then construct functions on lambda terms via term recursion, as given by the following examples.

\bdefn

    Given an term of the form $\lambda x.t$, every instance of $x$ in the term $t$ is called {\emphcolor bound}, and all other instances are {\emphcolor free}.
    Formally we can define the set of free variables in an term recursively as follows:
    \benum
        \item for an term of the form $x$ for a variable $x$, $\varof x=\set x$, $\freeof x=\set x$, $\bndof x=\varnothing$,
        \item for an term of the form $\lambda x.t$, $\varof{\lambda x.t}=\varof t\cup\set x$, $\freeof{\lambda x.t}=\freeof t\setminus\set x$, and $\bndof{\lambda x.t}=\bndof t\cup\set x$,
        \item for an term of the form $t_1t_2$, $\varof{t_1t_2}=\varof{t_1}\cup\varof{t_2}$, $\freeof{t_1t_2}=\freeof{t_1}\cup\freeof{t_2}$ and $\bndof{t_1t_2}=\bndof{t_1}\cup\bndof{t_2}$.
    \eenum

    Alternatively, a {\emphcolor bound occurrence} of a variable $x$ in $t$ is an occurrence which occurs in $t'$ where $\lambda x.t'$ is a subterm of $t$.
    A {\emphcolor free occurrence} is an occurrence which is not bound.
    Then $\freeof t$ is the set of all variables which occur free in $t$, $\bnd t$ is the set of all variables which occur bound in $t$.

\edefn

So for example, let $t=(\lambda x.\lambda y.x)x\,z$, then $\varof t=\set{x,y,z}$, $\freeof t=\set{x,z}$, $\bndof t=\set{x,y}$.
Here the $x$ and $y$ in $\lambda x.\lambda y.x$ are bound occurrences, and the $x$ and $z$ following it (in $x\,z$) are free.
Notice that always $\varof t=\freeof t\cup\bndof t$, but as the above example shows, these two sets are not always disjoint.
A proof of this union is done via term induction: prove it for $t=x$, then for $t=\lambda x.t'$, then finally for $t=t_1t_2$.
\benum
    \item for $t=x$, $\varof t=\set x$, $\freeof t=\set x$, and $\bndof t=\varnothing$, so the union holds.
    \item for $t=\lambda x.t'$, $\varof t=\varof{t'}\cup\set x$ which by induction is equal to $\freeof{t'}\cup\bndof{t'}\cup\set x$.
        Now $\freeof t=\freeof{t'}\setminus\set x$, $\bndof t=\bndof{t'}\cup\set x$ and so we see that $\freeof t\cup\bndof t=\varof t$ as required.
    \item for $t=t_1t_2$, $\varof t=\varof{t_1}\cup\varof{t_2}$ which by induction is $\freeof{t_1}\cup\freeof{t_2}\cup\bndof{t_1}\cup\bndof{t_2}=\freeof t\cup\bndof t$.
\eenum

\bdefn

    An term without free variables is called a {\emphcolor combinator}.
    The {\emphcolor identity combinator} is the combinator ${\sf id}=\lambda x.x$.

\edefn

Suppose we'd like to take a term $t$ and substitute $x$ with another term $t'$.
For example, suppose $t'$ is the variable $z$, then \lcalc{\lambda y.x} should become \lcalc{\lambda y.z}.
But then what should \lcalc{\lambda x.x} become?
Surely not \lcalc{\lambda x.z}, as that alters the entire interpretation of the function.
So variables should be substituted only at free occurrences.
But what about if $t'$ were $x$ and $t$ was \lcalc{\lambda x.y}, then substituting at $y$ gives \lcalc{\lambda x.x}, which once again changes the meaning of the function.
So we should only substitute at free occurrences, if the $\lambda$-variable is not free in the term being substituted.

\bdefn

    Let $t,t'$ be terms and $x$ a variable.
    Then $t[x\mapsto t']$ is the term obtained by substituting $x$ with $t'$ according to the following rules:
    \benum
        \item $x[x\mapsto t']=t'$,
        \item $y[x\mapsto t']=y$ if $y$ is a variable distinct from $x$,
        \item $(\lambda x.t)[x\mapsto t']=\lambda x.t$,
        \item $(\lambda y.t)[x\mapsto t']=\lambda y.(t[x\mapsto t'])$ if $y\neq x$ and $y\notin\freeof{t'}$,
        \item $(t_1\,t_2)[x\mapsto t']=t_1[x\mapsto t']\,t_2[x\mapsto t']$.
    \eenum

\edefn

But then what would the substitution $(\lambda y.x\,y)[x\mapsto y\,z]$ look like?
Well $y$ is free in the substituted term, so it doesn't match any of the above conditions.
In such a case we take upon ourselves the following convention:

\bppbox{rgb{.8 1 .8}}{rgb{0 .4 0}}{rgb{0 .4 0}}
\hbox to\hsize{\setfont{bf}Convention ($\boldsymbol\alpha$-equivalence)\hfil}
\medskip

    Terms that differ only in the named of bound variables are equivalent.

\eppbox

This means that we can view $\lambda y.x\,y$ as $\lambda w.x\,w$ and so the substitution becomes $\lambda w.y\,z\,w$.
The rules for $\alpha$-equivalence is that if $\lambda x.t$ is equivalent to $\lambda y.t[x\mapsto y]$ if $y\notin\var t$. 

\bdefn

    A term of the form $(\lambda x.t)t'$ is called a {\emphcolor redex}.
    A term of the form $\lambda x.t$ is called a {\emphcolor abstraction}.
    We define the {\emphcolor $\beta$ reduction} on terms which maps redexes to terms by $(\lambda x.t)t'\xvarrightarrow{\,\beta\,}t[x\mapsto t']$ where $t[x\mapsto t']$ is the term
    obtained by substituting $t'$ at all the free occurrences of $x$.
    A {\emphcolor value} is an abstraction or variable.

\edefn

For example, $(\lambda x.x)y\to y$, and
$$ \bigl(\lambda x.(\lambda x.x)x\bigr)(u\,r) \to (\lambda x.x)(u\,r) = u\,r $$

When performing a $\beta$-reduction, we need to consider the order with which we perform the reduction.
There are $4$ ways:
\def\id{{\sf id}}
\benum
    \item {\it Full $\beta$-reduction}, in which any redex can be reduced at any time.
        So at each step, we can arbitrarily choose a redex and reduce it.
        For example, take

        \centerline{\tt (\lambda x.x) ((\lambda x.x) (\lambda z.(\lambda x.x) z))}

        which is just \id(\id(\lambda z.\id z)).
        This term contains three redexes:

        \centerline{\tt\underline{\id(\id(\lambda z.\id\ z))},\quad \id(\underline{\id(\lambda z.\id\ z)}),\quad \id(\id(\lambda z.\underline{\id\ z}))}

        So we can choose for example to begin from the innermost redex and move outward:

        \expansion{
            &\id(\id(\lambda z.\underline{\id z}))\cr
            \to&\id(\underline{\id(\lambda z.z)})\cr
            \to&\underline{\id(\lambda z.z)}\cr
            \to&\lambda z.z
        }

        which cannot be reduced any more.

    \item {\it Normal order}, in which the leftmost outermost redex is reduced first.
        So using the same example as above:

        \expansion{
            &\underline{\id(\id(\lambda z.\id z))}\cr
            \to&\underline{\id(\lambda z.\id z)}\cr
            \to&\lambda z.\underline{\id z}\cr
            \to&\lambda z.z
        }

        The rules for normal order reduction are as follows:
        $$ \syntaxtree{
            {\lcalc{(\lambda x.t)s \to\ t[x\mapsto s]}}{{\vphantom t}\noc}
        },\quad
        \syntaxtree{
            {\lcalc{ts \to\ t's}}[if {\tt t} is not a value]{{\lcalc{t\to t'}}\noc}
        },\quad
        \syntaxtree{
            {\lcalc{\lambda x.t\to\lambda x.t'}}[if {\tt t} is not a value]{{\lcalc{t\to t'}}\noc}
        }
        $$

    \item {\it Call-by-name}, which is similar to normal order but it performs no reductions inside abstractions.
        Using the same example:

        \expansion{
            &\underline{\id(\id(\lambda z.\id z))}\cr
            \to&\underline{\id(\lambda z.\id z)}\cr
            \to&\lambda z.\id z
        }

        The rules for call-by-name reduction are as follows:
        $$ \syntaxtree{
            {\lcalc{(\lambda x.t)s \to\ t[x\mapsto s]}}{{\vphantom t}\noc}
        },\qquad
        \syntaxtree{
            {\lcalc{ts \to\ t's}}[if {\tt t} is not a value]{{\lcalc{t\to t'}}\noc}
        } $$

    \item {\it Call-by-value}, which is the most commonly used in programming languages, like call-by-name, but a redex is reduced only when its right-hand side has already been
        reduced to a {\it value} (a term which cannot be reduced further, in this lambda calculus these are only abstractions).

        \expansion{
            &\id(\underline{\id(\lambda z.\id z)})\cr
            \to&\underline{\id(\lambda z.\id z)}\cr
            \to&\lambda z.\id z
        }

        The rules for call-by-value reduction are
        $$ \syntaxtree{
            {\lcalc{(\lambda x.t)v \to\ t[x\mapsto v]}}[if {\tt v} is a value]{{\vphantom t}\noc}
        },\qquad
        \syntaxtree{
            {\lcalc{(\lambda x.t)s \to\ (\lambda x.t)s'}}[if {\tt s} is not a value]{{\lcalc{s\to s'}}\noc}
        },$$
        $$
        \syntaxtree{
            {\lcalc{ts \to\ t's}}[if {\tt t} is not a value]{{\lcalc{t\to t'}}\noc}
        }
        $$
\eenum

In this course we use call-by-value, since it is the most commonly used evaluation strategy.

Notice that in lambda calculus, all functions accept a single parameter as input.
As in OCaml, to write a function which accepts multiple functions, we write one which accepts a single input and returns a function which also accepts a single input.
So for example $f=\lambda x.\lambda y.x$ can then be called like $f\,u\,r$ and will return $u$ after two $\beta$-reductions.

We now define booleans in lambda calculus (called Church booleans):
$$ \tru=\lambda t.\lambda f.t,\qquad \fls=\lambda t.\lambda f.f $$
So $\tru$ accepts two arguments and returns the first, $\fls$ accepts two and returns the second.
We now define
$$ \test=\lambda b.\lambda m.\lambda n.\,b\,m\,n $$
So $\test$ accepts three arguments, the first $b$ is a boolean (either $\tru$ or $\fls$), and it applies it to the other two arguments.
So for example
$$ \test\,\tru\,v\,w = (\lambda b.\lambda m.\lambda n.\,b\,m\,n)\tru\,v\,w \to (\lambda m.\lambda n.\tru\,m\,n)v\,w \to (\lambda n.\tru\,v\,n)w\to \tru\,v\,w \to v $$
This doesn't do much, it just returns the first argument (after the boolean) if the boolean is true, and the second if it is false.

We can define a more interesting combinator
$$ \and = \lambda b.\lambda c.b\,c\,\fls $$
Here $b,c$ are booleans.
Then if $b$ is $\tru$, $\and\,b\,c\to c$ after a $\beta$-reduction, and otherwise it will reduce to $c$.
So if $c$ is false, then $\and\,b\,c\to c=\fls$ and if $c$ is true then it reduces to $c=\tru$, and if $b$ is false then $\and\,b\,c\to b\,c\,\fls\to\fls$.
So $\and$ functions as one would expect it to.

Utilizing booleans, we can encode pairs of values as terms:
$$ \eqalign{
    \pair &= \tt\lambda f.\lambda s.\lambda b.b\,f\,s\cr
    \fst &= \tt\lambda p.p\,\tru\cr
    \snd &= \tt\lambda p.p\,\fls\cr
} $$
Notice then that
\expansion{
    &\fst(\pair\ v w)\cr
    =&\fst(\underline{(\lambda f.\lambda s.\lambda b.b f s)} v w)& by definition\cr
    \to&\fst(\underline{(\lambda s.\lambda b.b v s)} w)& $\beta$-reduction on underlined redex\cr
    \to&\fst(\underline{\lambda b.b v w})& $\beta$-reduction on underlined redex\cr
    =&\underline{(\lambda p.p \tru)(\lambda b.b v w)}& by definition\cr
    \to&\underline{(\lambda b.b v w)\tru}& $\beta$-reduction on underlined redex\cr
    \to&\tru\ v w& $\beta$-reduction on underlined redex\cr
    \to&v& by definition of \tru
}
In a similar manner we can show that {\tt \snd(\pair\ v w)\to w}.

We now demonstrate how we can represent numbers in lambda calculus, via Church numerals:

\medskip
\centerline{\vbox{\ialign{\hfil$#{}$\tabskip=.25cm&\tt#\hfil\tabskip=\z@\cr
    \cn0=&\lambda s.\lambda z.z\cr
    \cn1=&\lambda s.\lambda z.s z\cr
    \cn2=&\lambda s.\lambda z.s(s z)\cr
    \cn3=&\lambda s.\lambda z.s(s(s z))\cr
    \multispan2\relax etc.\hfil\cr
}}}
\medskip

In general if we write ${\tt s}^n\ \tt z$ for {\tt s(s($\cdots$s z$\cdots$))} ($n$ times), then $\cn n=${\tt\lambda s.\lambda z.${\tt s}^n$ z}.
So each number $n$ is represented by the combinator $\cn n$ which accepts {\tt s,z} and applies {\tt s} $n$ times to {\tt z}.
Notice that $\cn0=\fls$, which is reminiscent of the fact that false and zero mean the same thing in many compiled languages.

Let us define

\centerline{\tt \scc = \lambda n.\lambda s.\lambda z.s(n s z)}

We see then that

\centerline{\tt\scc\ \cn n s z = \lambda s.\lambda z.s(\cn n s z) s z = s(${\tt s}^n$ z) = ${\tt s}^{n+1}$ z = \cn{n+1} z s}
so \lcalc{\scc\ \cn n} and \cn{n+1} are equivalent in the sense that they operate the same on the same input.
But bare in mind: \lcalc{\scc\ \cn n = \lambda s.\lambda z.s(\cn n s z)} which is not {\it equal} to \lcalc{\cn{n+1}}.

Similarly we can define

\centerline{\tt \plus = \lambda n.\lambda m.\lambda s.\lambda z.m s (n s z)}

so that \lcalc{\plus n m s z} will apply {\tt s} \lcalc{n s z} $m$ times, resulting in ${\tt s}^m{\tt s}^n{\tt z}={\tt s}^{n+m}{\tt z}$ as desired.
Similarly we define

\smallskip
\centerline{\tt times = \lambda n.\lambda m.m (\plus\ n) \cn0}

so that \lcalc{times n m} will apply \lcalc{\plus n} $m$ times to \cn0, resulting in $n+n+\cdots+n+0=n\cdot m$.
In a similar vein, we can define \lcalc{pow = \lambda n.\lambda m.m (times\ n) \cn1}, so that \lcalc{pow \cn n \cn m} is equal to \cn{n^m}.

To test if a numeral is zero, we'd like to find a functions {\tt ss} and {\tt zz} such that applying {\tt ss} one or more times to {\tt zz} yields false, while not applying it at all yields true.
That way when we do \lcalc{\cn n ss zz}, it will result in \tru{} only if {\tt ss} was never applied, meaning $n=0$.
Necessarily then {\tt zz} must be \tru, and have {\tt ss} be the function which maps every input to $\fls$.
So we define

\smallskip
\centerline{\tt\iszro = \lambda n.n (\lambda x.\fls) \tru}

To define the predecessor combinator, we must be a bit more clever than with the successor.
One implementation is

\smallskip
\centerline{\vbox{\ialign{\hfil$\lcalc{#}={}$\tabskip=.25cm&\lcalc{#}\hfil\tabskip=\z@\cr
    zz&\pair\ \cn0 \cn0\cr
    ss&\lambda p.\pair(\snd\ p)(\plus\ \c1 (\snd\ p))\cr
    \prd&\lambda m.\fst(m ss zz)\cr
}}}

The idea here is that applying {\tt ss} to a $(n,m)$ will result in $(m,m+1)$.
So starting from $(0,0)$, you get $(0,1)$ then $(1,2)$ then $(2,3)$ and so on.
In general ${\tt ss}^n{\tt z}=(n-1,n)$ for $n\geq1$ and so the predecessor is just the first value.

Using the predecessor combinator we can define a subtraction combinator similar to addition:

\smallskip
\centerline{\tt sub= \lambda m.\lambda n.m \prd n}

Notice though that {\tt sub} cannot give negative numbers, after all we didn't define negative numbers, so if $n\leq m$ then \lcalc{\cn n-\cn m} is just \cn0.
Thus we can define

\smallskip
\eqdef{
    leq&\lambda m.\lambda n.\iszro(sub m n)\cr
    equal&\lambda m.\lambda n.\and(leq n m) (leq m n)
}

\bdefn

    A term without a redex is called a {\emphcolor normal form}.
    The normal form of a term $t$ is the normal form obtained through $\beta$ reduction.
    A term without a normal form is called {\emphcolor divergent}.

\edefn

For example, the normal form of \lcalc{(\lambda x.\lambda y.x)y} can be reduced to \lcalc{\lambda y.y} which is its normal form.
One example of a divergent combinator is

\smallskip
\centerline{\tt omega= (\lambda x.x x)(\lambda x.x x)}

Since a single $\beta$ reduction gives you back {\tt omega}, which gives what is essentially an infinite loop.
We can also define the following combinator

\smallskip
\centerline{\tt fix= \lambda f.(\lambda x. f(\lambda y. x x y)) (\lambda x. f(\lambda y. x x y))}

Suppose we'd like to write a function to compute factorials, which can be written as

\begincode
if n=0 then 1
else n * factorial(n-1)
/endcode

The idea is to unravel the function definition, to get something of the form

\begincode
if n=0 then 1
else n * (if n-1=0 then 1
          else (n-1) * (if n-2=0 then 1
                        else (n-2) * ...))
/endcode

Using Church numerals, we get

\begincode
test (equal n /cn0) 
    /cn1
    times n (test (equal (prd n) /cn0)
            /cn1
            times (prd n) (test (equal (prd (prd n)) /cn0)
                           /cn1
                           times (prd (prd n)) (...)))
/endcode

Then we define

\eqdef{
    g&\lambda fct.\lambda n. test (equal n \cn0) \cn1 (times n (fct (prd n)))\cr
    factorial&fix g
}

Let us give an example run of \lcalc{factorial \cn3}:

\medskip
\expansion{
    &factorial \cn3\cr
    =&fix g \cn3\cr
    \to&h h \cn3& where \lcalc{h=\lambda x.g(\lambda y.x x y)}\cr
    \to&g fct \cn3& where \lcalc{fct=\lambda y. h h y}\cr
    \to&$\bigl($\lambda n. test(equal n \cn0) \cn1 (times n (fct (prd n)))$\bigr)$\cn3\span\cr
    \to&test(equal \cn3 \cn0) \cn1 (times \cn3 (fct (prd \cn3)))\span\cr
    \to&times \cn3 (fct (prd \cn3))\cr
    \to&times \cn3 (fct \cn2)\cr
    \to&times \cn3 (h h \cn2)\cr
    \to&times \cn3 (g fct \cn2)& similar to how \lcalc{h h \cn3} can be reduced to \lcalc{g fct \cn3}\cr
    \to&times \cn3 (times \cn2 (g fct \cn1))& by the same process that we did for \cn3\cr
    \to&times \cn3 (times \cn2 (times \cn1 (g fct \cn0)))\span\cr
    \to&times \cn3 (times \cn2 (times \cn1 (test (equal \cn0 \cn0) \cn1 ...)))\span\cr
    \to&times \cn3 (times \cn2 (times \cn1 \cn1))\cr
    \to&\cn6\cr
}

\def\recur#1{$\gen{\hbox{#1}}$}
Let us prove that this works.
Suppose we have a recurrence \lcalc{r=\lambda x.\recur{code with r}}, let us use the notation \lcalc{\recur{r c}} to mean that within the recurrence, {\tt r} is called on the value {\tt c}.
Let us define \lcalc{g=\lambda r.\lambda x.\recur{code with r}}, which is like {\tt r} but it accepts the function it should run on.
So if we were to define {\tt r}, then {\tt r} and \lcalc{g r} would be functionally the same.
We claim then that \lcalc{r=fix g} is a term which is equivalent to {\tt r} (does the same thing).
Let us reduce it a bit on some term {\tt c}

\medskip
\expansion{
    &r c\cr
    =&fix g c\cr
    \to&h h c&where \lcalc{h=\lambda x.g(\lambda y.x x y)}\cr
    \to&g r' c&where \lcalc{r'=\lambda y.h h y}\cr
}

Now we claim that \lcalc{g r' c} gives the same result as \lcalc{r c}, which we will prove on the number of recursive calls that \lcalc{r c} makes.
If we were to reduce this one more time, we'd get \lcalc{\recur{code with r'} c}, but since {\tt r} makes no recursive calls on the input {\tt c}, this functions the same as \lcalc{\recur{code with r} c},
which is \lcalc{r c}.
Now, suppose that on the first recursive call, the program calls {\tt r' c'}, meaning for {\tt r} it would call {\tt r c'}.
Now \lcalc{r' c' = h h c' = g r' c'}, and by our inductive hypothesis \lcalc{g r' c' = r c'}, so the code performs the same.

We can also define the {\it Y-combinator}:

\medskip
\centerline{\tt\Y\ = \lambda f.(\lambda x.f(x x))(\lambda x.f(x x))}

Which can similarly perform recursion.
Like \lcalc{fix}, it is a {\it fixed-point} combinator, which is a combinator {\sf fix} such that $f({\sf fix}f)={\sf fix}f$.
Indeed:

\medskip
\expansion{
    &\Y\ g\cr
    =&(\lambda f.(\lambda x.f(x x))(\lambda x.f(x x))) g&by definition\cr
    \to&(\lambda x.g(x x))(\lambda x.g(x x))&by $\beta$-reduction\cr
    \to&g((\lambda x.g(x x)) (\lambda x.g(x x)))&by $\beta$-reduction\cr
    =&g(\Y\ g)&by the second equality
}

Though the final equality is only true up to $\beta$-reduction, meaning that \lcalc{\Y\ g} and \lcalc{g(\Y\ g)} both reduce to a similar term, not to one another.
This is the trait which allows for recursion.

